Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_1[0][0]              
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_3[0][0]              
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_5[0][0]              
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_7[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_8[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_7[0][0]              
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_9 (LeakyReLU)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_9[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_10[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_10 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_10[0][0]             
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_9[0][0]              
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_11 (LeakyReLU)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_11[0][0]             
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_12 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_12[0][0]             
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_13[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_11[0][0]             
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_13 (LeakyReLU)      (None, 32, 32, 16)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_13[0][0]             
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_14 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_14[0][0]             
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_13[0][0]             
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_15 (LeakyReLU)      (None, 32, 32, 16)   0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_15[0][0]             
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_16 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_16[0][0]             
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_15[0][0]             
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_17 (LeakyReLU)      (None, 32, 32, 16)   0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_17[0][0]             
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_18 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_18[0][0]             
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_17[0][0]             
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_19 (LeakyReLU)      (None, 32, 32, 16)   0           add_9[0][0]                      
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_19[0][0]             
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_20[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_20 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_20[0][0]             
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]                  
__________________________________________________________________________________________________
add_10 (Add)                    (None, 32, 32, 16)   0           leaky_re_lu_19[0][0]             
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_21 (LeakyReLU)      (None, 32, 32, 16)   0           add_10[0][0]                     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 16, 16, 32)   4640        leaky_re_lu_21[0][0]             
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_22[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_22 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_22[0][0]             
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 16, 16, 32)   544         leaky_re_lu_21[0][0]             
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         conv2d_23[0][0]                  
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 32)   0           conv2d_24[0][0]                  
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_23 (LeakyReLU)      (None, 16, 16, 32)   0           add_11[0][0]                     
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_23[0][0]             
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_24 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_24[0][0]             
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_23[0][0]             
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_25 (LeakyReLU)      (None, 16, 16, 32)   0           add_12[0][0]                     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_25[0][0]             
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_26 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_26[0][0]             
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_25[0][0]             
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_27 (LeakyReLU)      (None, 16, 16, 32)   0           add_13[0][0]                     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_27[0][0]             
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_29[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_28 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_28[0][0]             
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]                  
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_27[0][0]             
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_29 (LeakyReLU)      (None, 16, 16, 32)   0           add_14[0][0]                     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_29[0][0]             
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_31[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_30 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_30[0][0]             
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_29[0][0]             
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_31 (LeakyReLU)      (None, 16, 16, 32)   0           add_15[0][0]                     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_31[0][0]             
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_32 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_32[0][0]             
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  
__________________________________________________________________________________________________
add_16 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_31[0][0]             
                                                                 batch_normalization_33[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_33 (LeakyReLU)      (None, 16, 16, 32)   0           add_16[0][0]                     
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_33[0][0]             
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 16, 16, 32)   128         conv2d_35[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_34 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_34[0][0]             
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         conv2d_36[0][0]                  
__________________________________________________________________________________________________
add_17 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_33[0][0]             
                                                                 batch_normalization_35[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_35 (LeakyReLU)      (None, 16, 16, 32)   0           add_17[0][0]                     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_35[0][0]             
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         conv2d_37[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_36 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_36[0][0]             
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 16, 16, 32)   128         conv2d_38[0][0]                  
__________________________________________________________________________________________________
add_18 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_35[0][0]             
                                                                 batch_normalization_37[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_37 (LeakyReLU)      (None, 16, 16, 32)   0           add_18[0][0]                     
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_37[0][0]             
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 16, 16, 32)   128         conv2d_39[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_38 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_38[0][0]             
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 16, 16, 32)   128         conv2d_40[0][0]                  
__________________________________________________________________________________________________
add_19 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_37[0][0]             
                                                                 batch_normalization_39[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_39 (LeakyReLU)      (None, 16, 16, 32)   0           add_19[0][0]                     
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_39[0][0]             
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 16, 16, 32)   128         conv2d_41[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_40 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_40[0][0]             
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 16, 16, 32)   128         conv2d_42[0][0]                  
__________________________________________________________________________________________________
add_20 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_39[0][0]             
                                                                 batch_normalization_41[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_41 (LeakyReLU)      (None, 16, 16, 32)   0           add_20[0][0]                     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 8, 8, 64)     18496       leaky_re_lu_41[0][0]             
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         conv2d_43[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_42 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_42[0][0]             
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 8, 8, 64)     2112        leaky_re_lu_41[0][0]             
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         conv2d_44[0][0]                  
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 8, 64)     0           conv2d_45[0][0]                  
                                                                 batch_normalization_43[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_43 (LeakyReLU)      (None, 8, 8, 64)     0           add_21[0][0]                     
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_43[0][0]             
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         conv2d_46[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_44 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_44[0][0]             
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv2d_47[0][0]                  
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_43[0][0]             
                                                                 batch_normalization_45[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_45 (LeakyReLU)      (None, 8, 8, 64)     0           add_22[0][0]                     
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_45[0][0]             
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         conv2d_48[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_46 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_46[0][0]             
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         conv2d_49[0][0]                  
__________________________________________________________________________________________________
add_23 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_45[0][0]             
                                                                 batch_normalization_47[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_47 (LeakyReLU)      (None, 8, 8, 64)     0           add_23[0][0]                     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_47[0][0]             
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 8, 8, 64)     256         conv2d_50[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_48 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_48[0][0]             
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  
__________________________________________________________________________________________________
add_24 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_47[0][0]             
                                                                 batch_normalization_49[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_49 (LeakyReLU)      (None, 8, 8, 64)     0           add_24[0][0]                     
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_49[0][0]             
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 8, 8, 64)     256         conv2d_52[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_50 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_50[0][0]             
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         conv2d_53[0][0]                  
__________________________________________________________________________________________________
add_25 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_49[0][0]             
                                                                 batch_normalization_51[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_51 (LeakyReLU)      (None, 8, 8, 64)     0           add_25[0][0]                     
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_51[0][0]             
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_54[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_52 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_52[0][0]             
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_55[0][0]                  
__________________________________________________________________________________________________
add_26 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_51[0][0]             
                                                                 batch_normalization_53[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_53 (LeakyReLU)      (None, 8, 8, 64)     0           add_26[0][0]                     
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_53[0][0]             
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         conv2d_56[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_54 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_54[0][0]             
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         conv2d_57[0][0]                  
__________________________________________________________________________________________________
add_27 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_53[0][0]             
                                                                 batch_normalization_55[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_55 (LeakyReLU)      (None, 8, 8, 64)     0           add_27[0][0]                     
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_55[0][0]             
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 8, 8, 64)     256         conv2d_58[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_56 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_56[0][0]             
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 8, 8, 64)     256         conv2d_59[0][0]                  
__________________________________________________________________________________________________
add_28 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_55[0][0]             
                                                                 batch_normalization_57[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_57 (LeakyReLU)      (None, 8, 8, 64)     0           add_28[0][0]                     
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_57[0][0]             
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 8, 8, 64)     256         conv2d_60[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_58 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_58[0][0]             
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 8, 8, 64)     256         conv2d_61[0][0]                  
__________________________________________________________________________________________________
add_29 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_57[0][0]             
                                                                 batch_normalization_59[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_59 (LeakyReLU)      (None, 8, 8, 64)     0           add_29[0][0]                     
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_59[0][0]             
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 8, 8, 64)     256         conv2d_62[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_60 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_60[0][0]             
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 8, 8, 64)     256         conv2d_63[0][0]                  
__________________________________________________________________________________________________
add_30 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_59[0][0]             
                                                                 batch_normalization_61[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_61 (LeakyReLU)      (None, 8, 8, 64)     0           add_30[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           leaky_re_lu_61[0][0]             
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 959,658
Trainable params: 955,146
Non-trainable params: 4,512
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.51560, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 122s - loss: 1.7925 - acc: 0.4867 - val_loss: 2.0986 - val_acc: 0.5156
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.51560 to 0.60920, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 46s - loss: 1.3242 - acc: 0.6496 - val_loss: 1.5104 - val_acc: 0.6092
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc improved from 0.60920 to 0.62940, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 46s - loss: 1.1290 - acc: 0.7176 - val_loss: 1.4609 - val_acc: 0.6294
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.62940 to 0.73340, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 46s - loss: 1.0166 - acc: 0.7509 - val_loss: 1.0919 - val_acc: 0.7334
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc improved from 0.73340 to 0.73360, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 46s - loss: 0.9234 - acc: 0.7787 - val_loss: 1.0967 - val_acc: 0.7336
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc improved from 0.73360 to 0.75140, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 46s - loss: 0.8533 - acc: 0.8007 - val_loss: 1.0425 - val_acc: 0.7514
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc did not improve
 - 44s - loss: 0.7961 - acc: 0.8169 - val_loss: 1.3344 - val_acc: 0.6700
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc did not improve
 - 45s - loss: 0.7535 - acc: 0.8313 - val_loss: 1.5307 - val_acc: 0.6354
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc improved from 0.75140 to 0.75780, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.7113 - acc: 0.8442 - val_loss: 1.0530 - val_acc: 0.7578
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 45s - loss: 0.6805 - acc: 0.8535 - val_loss: 1.2961 - val_acc: 0.7050
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc improved from 0.75780 to 0.76340, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.6447 - acc: 0.8656 - val_loss: 1.0208 - val_acc: 0.7634
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc improved from 0.76340 to 0.77620, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.6269 - acc: 0.8717 - val_loss: 1.0101 - val_acc: 0.7762
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc did not improve
 - 45s - loss: 0.5873 - acc: 0.8859 - val_loss: 1.0595 - val_acc: 0.7638
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 45s - loss: 0.5769 - acc: 0.8880 - val_loss: 1.2796 - val_acc: 0.7258
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc did not improve
 - 45s - loss: 0.5539 - acc: 0.8963 - val_loss: 1.2609 - val_acc: 0.7244
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 45s - loss: 0.5326 - acc: 0.9059 - val_loss: 1.3307 - val_acc: 0.7118
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 45s - loss: 0.5204 - acc: 0.9094 - val_loss: 1.3720 - val_acc: 0.7166
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 45s - loss: 0.4980 - acc: 0.9189 - val_loss: 1.0545 - val_acc: 0.7750
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 45s - loss: 0.4952 - acc: 0.9192 - val_loss: 1.6625 - val_acc: 0.7068
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc improved from 0.77620 to 0.77780, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.4792 - acc: 0.9256 - val_loss: 1.1110 - val_acc: 0.7778
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 45s - loss: 0.4615 - acc: 0.9336 - val_loss: 1.1237 - val_acc: 0.7708
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 44s - loss: 0.4668 - acc: 0.9303 - val_loss: 1.1651 - val_acc: 0.7634
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 45s - loss: 0.4492 - acc: 0.9381 - val_loss: 1.8204 - val_acc: 0.6758
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 45s - loss: 0.4429 - acc: 0.9388 - val_loss: 1.3124 - val_acc: 0.7494
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 45s - loss: 0.4377 - acc: 0.9408 - val_loss: 1.4986 - val_acc: 0.7318
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 45s - loss: 0.4333 - acc: 0.9429 - val_loss: 1.3049 - val_acc: 0.7660
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 45s - loss: 0.4278 - acc: 0.9445 - val_loss: 1.5656 - val_acc: 0.7192
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 45s - loss: 0.4218 - acc: 0.9461 - val_loss: 1.2248 - val_acc: 0.7764
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 45s - loss: 0.4212 - acc: 0.9472 - val_loss: 1.3110 - val_acc: 0.7572
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 45s - loss: 0.4066 - acc: 0.9516 - val_loss: 1.4130 - val_acc: 0.7518
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 45s - loss: 0.4146 - acc: 0.9492 - val_loss: 1.3346 - val_acc: 0.7516
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 45s - loss: 0.4061 - acc: 0.9523 - val_loss: 1.3812 - val_acc: 0.7458
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 45s - loss: 0.4048 - acc: 0.9523 - val_loss: 1.2591 - val_acc: 0.7680
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 45s - loss: 0.3991 - acc: 0.9539 - val_loss: 1.9630 - val_acc: 0.6838
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 45s - loss: 0.4043 - acc: 0.9528 - val_loss: 1.6420 - val_acc: 0.7264
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 45s - loss: 0.3932 - acc: 0.9557 - val_loss: 1.4583 - val_acc: 0.7478
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 45s - loss: 0.3921 - acc: 0.9560 - val_loss: 1.4051 - val_acc: 0.7560
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 45s - loss: 0.3922 - acc: 0.9552 - val_loss: 1.4895 - val_acc: 0.7386
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 45s - loss: 0.3838 - acc: 0.9589 - val_loss: 1.2734 - val_acc: 0.7678
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc improved from 0.77780 to 0.79980, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.3904 - acc: 0.9548 - val_loss: 1.1250 - val_acc: 0.7998
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 45s - loss: 0.3907 - acc: 0.9554 - val_loss: 1.7259 - val_acc: 0.7032
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 44s - loss: 0.3713 - acc: 0.9622 - val_loss: 1.3811 - val_acc: 0.7520
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 45s - loss: 0.3862 - acc: 0.9566 - val_loss: 1.2895 - val_acc: 0.7610
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 45s - loss: 0.3687 - acc: 0.9620 - val_loss: 1.4279 - val_acc: 0.7660
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 45s - loss: 0.3803 - acc: 0.9574 - val_loss: 1.3373 - val_acc: 0.7470
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 45s - loss: 0.3700 - acc: 0.9608 - val_loss: 1.5982 - val_acc: 0.7308
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 45s - loss: 0.3705 - acc: 0.9612 - val_loss: 1.3686 - val_acc: 0.7738
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 44s - loss: 0.3570 - acc: 0.9651 - val_loss: 1.4216 - val_acc: 0.7554
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 45s - loss: 0.3698 - acc: 0.9605 - val_loss: 1.4118 - val_acc: 0.7600
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 45s - loss: 0.3649 - acc: 0.9610 - val_loss: 1.3479 - val_acc: 0.7664
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 45s - loss: 0.3615 - acc: 0.9617 - val_loss: 1.7545 - val_acc: 0.7110
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 45s - loss: 0.3527 - acc: 0.9646 - val_loss: 1.4233 - val_acc: 0.7682
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 45s - loss: 0.3619 - acc: 0.9621 - val_loss: 1.4466 - val_acc: 0.7618
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 45s - loss: 0.3494 - acc: 0.9658 - val_loss: 1.5110 - val_acc: 0.7498
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 45s - loss: 0.3540 - acc: 0.9635 - val_loss: 1.3639 - val_acc: 0.7648
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 45s - loss: 0.3560 - acc: 0.9626 - val_loss: 1.1978 - val_acc: 0.7816
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 45s - loss: 0.3444 - acc: 0.9663 - val_loss: 1.1301 - val_acc: 0.7934
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 45s - loss: 0.3368 - acc: 0.9688 - val_loss: 1.4831 - val_acc: 0.7656
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 45s - loss: 0.3550 - acc: 0.9619 - val_loss: 1.2400 - val_acc: 0.7808
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 45s - loss: 0.3404 - acc: 0.9660 - val_loss: 1.2477 - val_acc: 0.7772
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 45s - loss: 0.3386 - acc: 0.9677 - val_loss: 1.1552 - val_acc: 0.7920
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 45s - loss: 0.3333 - acc: 0.9689 - val_loss: 1.4286 - val_acc: 0.7602
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 45s - loss: 0.3381 - acc: 0.9659 - val_loss: 1.4581 - val_acc: 0.7550
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 45s - loss: 0.3405 - acc: 0.9651 - val_loss: 1.2723 - val_acc: 0.7782
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 45s - loss: 0.3293 - acc: 0.9693 - val_loss: 1.4341 - val_acc: 0.7512
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 45s - loss: 0.3311 - acc: 0.9672 - val_loss: 1.4746 - val_acc: 0.7680
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 45s - loss: 0.3306 - acc: 0.9674 - val_loss: 1.3263 - val_acc: 0.7730
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 45s - loss: 0.3251 - acc: 0.9682 - val_loss: 1.2845 - val_acc: 0.7838
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 45s - loss: 0.3295 - acc: 0.9680 - val_loss: 1.5407 - val_acc: 0.7476
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 45s - loss: 0.3250 - acc: 0.9675 - val_loss: 1.4753 - val_acc: 0.7588
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 45s - loss: 0.3335 - acc: 0.9653 - val_loss: 1.1628 - val_acc: 0.7918
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 45s - loss: 0.3140 - acc: 0.9721 - val_loss: 1.2991 - val_acc: 0.7778
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 45s - loss: 0.3213 - acc: 0.9680 - val_loss: 1.2237 - val_acc: 0.7884
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 45s - loss: 0.3170 - acc: 0.9694 - val_loss: 1.1341 - val_acc: 0.7928
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 45s - loss: 0.3162 - acc: 0.9705 - val_loss: 1.2530 - val_acc: 0.7834
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 45s - loss: 0.3144 - acc: 0.9712 - val_loss: 1.2421 - val_acc: 0.7934
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 45s - loss: 0.3129 - acc: 0.9708 - val_loss: 1.2849 - val_acc: 0.7898
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 45s - loss: 0.3208 - acc: 0.9677 - val_loss: 2.0176 - val_acc: 0.7052
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 45s - loss: 0.3096 - acc: 0.9716 - val_loss: 1.3038 - val_acc: 0.7800
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 45s - loss: 0.3165 - acc: 0.9683 - val_loss: 1.5050 - val_acc: 0.7438
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 45s - loss: 0.3061 - acc: 0.9728 - val_loss: 1.3698 - val_acc: 0.7682
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.79980 to 0.83100, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.2549 - acc: 0.9915 - val_loss: 0.9961 - val_acc: 0.8310
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.83100 to 0.83160, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.2322 - acc: 0.9990 - val_loss: 1.0114 - val_acc: 0.8316
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc did not improve
 - 45s - loss: 0.2264 - acc: 0.9999 - val_loss: 1.0218 - val_acc: 0.8312
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc improved from 0.83160 to 0.83360, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.2221 - acc: 1.0000 - val_loss: 1.0299 - val_acc: 0.8336
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 45s - loss: 0.2181 - acc: 0.9999 - val_loss: 1.0441 - val_acc: 0.8324
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc improved from 0.83360 to 0.83420, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.2138 - acc: 1.0000 - val_loss: 1.0584 - val_acc: 0.8342
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 45s - loss: 0.2091 - acc: 0.9999 - val_loss: 1.0745 - val_acc: 0.8324
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 45s - loss: 0.2038 - acc: 1.0000 - val_loss: 1.0762 - val_acc: 0.8328
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 45s - loss: 0.1980 - acc: 1.0000 - val_loss: 1.0924 - val_acc: 0.8320
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc improved from 0.83420 to 0.83440, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.1915 - acc: 1.0000 - val_loss: 1.0921 - val_acc: 0.8344
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 45s - loss: 0.1843 - acc: 1.0000 - val_loss: 1.1016 - val_acc: 0.8316
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 45s - loss: 0.1764 - acc: 1.0000 - val_loss: 1.0953 - val_acc: 0.8310
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 45s - loss: 0.1677 - acc: 1.0000 - val_loss: 1.1070 - val_acc: 0.8292
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 44s - loss: 0.1584 - acc: 1.0000 - val_loss: 1.1112 - val_acc: 0.8302
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 45s - loss: 0.1491 - acc: 1.0000 - val_loss: 1.1203 - val_acc: 0.8328
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 45s - loss: 0.1412 - acc: 0.9994 - val_loss: 1.5130 - val_acc: 0.7880
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 45s - loss: 0.1444 - acc: 0.9971 - val_loss: 1.1678 - val_acc: 0.8202
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 45s - loss: 0.1345 - acc: 0.9997 - val_loss: 1.1157 - val_acc: 0.8306
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 45s - loss: 0.1307 - acc: 0.9999 - val_loss: 1.1261 - val_acc: 0.8312
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 45s - loss: 0.1275 - acc: 1.0000 - val_loss: 1.1343 - val_acc: 0.8342
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 45s - loss: 0.1243 - acc: 1.0000 - val_loss: 1.1442 - val_acc: 0.8296
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 45s - loss: 0.1206 - acc: 0.9999 - val_loss: 1.1489 - val_acc: 0.8264
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 45s - loss: 0.1239 - acc: 0.9978 - val_loss: 1.2251 - val_acc: 0.8140
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 44s - loss: 0.1180 - acc: 0.9994 - val_loss: 1.1534 - val_acc: 0.8258
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 45s - loss: 0.1145 - acc: 0.9998 - val_loss: 1.1585 - val_acc: 0.8270
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 45s - loss: 0.1123 - acc: 0.9999 - val_loss: 1.1733 - val_acc: 0.8306
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc improved from 0.83440 to 0.83460, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.1096 - acc: 1.0000 - val_loss: 1.1437 - val_acc: 0.8346
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 44s - loss: 0.1069 - acc: 0.9999 - val_loss: 1.1696 - val_acc: 0.8298
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 45s - loss: 0.1057 - acc: 0.9994 - val_loss: 1.2734 - val_acc: 0.8044
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 45s - loss: 0.1088 - acc: 0.9982 - val_loss: 1.2331 - val_acc: 0.8186
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 45s - loss: 0.1039 - acc: 0.9991 - val_loss: 1.2304 - val_acc: 0.8198
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 45s - loss: 0.1006 - acc: 0.9999 - val_loss: 1.1836 - val_acc: 0.8278
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 45s - loss: 0.0988 - acc: 0.9999 - val_loss: 1.1919 - val_acc: 0.8252
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 45s - loss: 0.0973 - acc: 0.9999 - val_loss: 1.2178 - val_acc: 0.8250
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 45s - loss: 0.0949 - acc: 1.0000 - val_loss: 1.1857 - val_acc: 0.8330
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 45s - loss: 0.0925 - acc: 1.0000 - val_loss: 1.1612 - val_acc: 0.8326
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 45s - loss: 0.0900 - acc: 1.0000 - val_loss: 1.1891 - val_acc: 0.8302
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 45s - loss: 0.0873 - acc: 1.0000 - val_loss: 1.1625 - val_acc: 0.8310
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 45s - loss: 0.0858 - acc: 0.9994 - val_loss: 1.5081 - val_acc: 0.7924
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 45s - loss: 0.1024 - acc: 0.9938 - val_loss: 1.1705 - val_acc: 0.8232
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc did not improve
 - 45s - loss: 0.0857 - acc: 0.9993 - val_loss: 1.1198 - val_acc: 0.8320
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 45s - loss: 0.0843 - acc: 0.9999 - val_loss: 1.1174 - val_acc: 0.8340
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 45s - loss: 0.0840 - acc: 0.9999 - val_loss: 1.1150 - val_acc: 0.8328
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 45s - loss: 0.0837 - acc: 0.9999 - val_loss: 1.1210 - val_acc: 0.8336
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 45s - loss: 0.0834 - acc: 1.0000 - val_loss: 1.1217 - val_acc: 0.8330
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 45s - loss: 0.0831 - acc: 1.0000 - val_loss: 1.1222 - val_acc: 0.8346
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 45s - loss: 0.0829 - acc: 1.0000 - val_loss: 1.1240 - val_acc: 0.8342
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc improved from 0.83460 to 0.83620, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.0826 - acc: 1.0000 - val_loss: 1.1252 - val_acc: 0.8362
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 45s - loss: 0.0823 - acc: 1.0000 - val_loss: 1.1269 - val_acc: 0.8350
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc improved from 0.83620 to 0.83640, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 47s - loss: 0.0821 - acc: 1.0000 - val_loss: 1.1289 - val_acc: 0.8364
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc improved from 0.83640 to 0.83680, saving model to ./weights/CIFAR-10_float_4b_4b_1_64_1_128_1_256.hdf5
 - 46s - loss: 0.0817 - acc: 1.0000 - val_loss: 1.1327 - val_acc: 0.8368
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 45s - loss: 0.0814 - acc: 1.0000 - val_loss: 1.1382 - val_acc: 0.8346
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 45s - loss: 0.0810 - acc: 1.0000 - val_loss: 1.1426 - val_acc: 0.8344
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 44s - loss: 0.0805 - acc: 1.0000 - val_loss: 1.1429 - val_acc: 0.8356
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 45s - loss: 0.0801 - acc: 1.0000 - val_loss: 1.1478 - val_acc: 0.8348
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 44s - loss: 0.0795 - acc: 1.0000 - val_loss: 1.1530 - val_acc: 0.8346
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 45s - loss: 0.0790 - acc: 1.0000 - val_loss: 1.1539 - val_acc: 0.8344
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 45s - loss: 0.0783 - acc: 1.0000 - val_loss: 1.1532 - val_acc: 0.8354
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 44s - loss: 0.0777 - acc: 1.0000 - val_loss: 1.1548 - val_acc: 0.8356
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 45s - loss: 0.0770 - acc: 1.0000 - val_loss: 1.1614 - val_acc: 0.8328
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 44s - loss: 0.0763 - acc: 1.0000 - val_loss: 1.1595 - val_acc: 0.8362
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 45s - loss: 0.0756 - acc: 1.0000 - val_loss: 1.1603 - val_acc: 0.8346
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 45s - loss: 0.0748 - acc: 1.0000 - val_loss: 1.1588 - val_acc: 0.8344
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 45s - loss: 0.0739 - acc: 1.0000 - val_loss: 1.1590 - val_acc: 0.8356
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 44s - loss: 0.0730 - acc: 1.0000 - val_loss: 1.1544 - val_acc: 0.8334
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 45s - loss: 0.0720 - acc: 1.0000 - val_loss: 1.1655 - val_acc: 0.8338
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 45s - loss: 0.0710 - acc: 1.0000 - val_loss: 1.1654 - val_acc: 0.8338
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 45s - loss: 0.0699 - acc: 1.0000 - val_loss: 1.1644 - val_acc: 0.8342
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 45s - loss: 0.0687 - acc: 1.0000 - val_loss: 1.1629 - val_acc: 0.8352
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 44s - loss: 0.0674 - acc: 1.0000 - val_loss: 1.1659 - val_acc: 0.8348
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 45s - loss: 0.0661 - acc: 1.0000 - val_loss: 1.1733 - val_acc: 0.8328
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 45s - loss: 0.0650 - acc: 1.0000 - val_loss: 1.1742 - val_acc: 0.8310
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 45s - loss: 0.0638 - acc: 1.0000 - val_loss: 1.1697 - val_acc: 0.8308
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 45s - loss: 0.0628 - acc: 1.0000 - val_loss: 1.1842 - val_acc: 0.8310
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 45s - loss: 0.0617 - acc: 1.0000 - val_loss: 1.1874 - val_acc: 0.8310
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 45s - loss: 0.0606 - acc: 1.0000 - val_loss: 1.1727 - val_acc: 0.8326
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 45s - loss: 0.0596 - acc: 1.0000 - val_loss: 1.1776 - val_acc: 0.8328
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 45s - loss: 0.0585 - acc: 1.0000 - val_loss: 1.1796 - val_acc: 0.8316
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 45s - loss: 0.0573 - acc: 1.0000 - val_loss: 1.1821 - val_acc: 0.8328
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 44s - loss: 0.0562 - acc: 1.0000 - val_loss: 1.1891 - val_acc: 0.8310
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 44s - loss: 0.0556 - acc: 1.0000 - val_loss: 1.1998 - val_acc: 0.8308
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 45s - loss: 0.0555 - acc: 1.0000 - val_loss: 1.2022 - val_acc: 0.8312
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 44s - loss: 0.0554 - acc: 1.0000 - val_loss: 1.2001 - val_acc: 0.8326
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 45s - loss: 0.0553 - acc: 1.0000 - val_loss: 1.1986 - val_acc: 0.8324
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 45s - loss: 0.0551 - acc: 1.0000 - val_loss: 1.2004 - val_acc: 0.8320
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 45s - loss: 0.0550 - acc: 1.0000 - val_loss: 1.1974 - val_acc: 0.8316
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 45s - loss: 0.0549 - acc: 1.0000 - val_loss: 1.1957 - val_acc: 0.8330
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 45s - loss: 0.0548 - acc: 1.0000 - val_loss: 1.1967 - val_acc: 0.8330
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 45s - loss: 0.0546 - acc: 1.0000 - val_loss: 1.1978 - val_acc: 0.8318
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 45s - loss: 0.0545 - acc: 1.0000 - val_loss: 1.1946 - val_acc: 0.8320
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 45s - loss: 0.0543 - acc: 1.0000 - val_loss: 1.1958 - val_acc: 0.8318
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 44s - loss: 0.0542 - acc: 1.0000 - val_loss: 1.1958 - val_acc: 0.8324
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 45s - loss: 0.0541 - acc: 1.0000 - val_loss: 1.1958 - val_acc: 0.8310
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 45s - loss: 0.0540 - acc: 1.0000 - val_loss: 1.1963 - val_acc: 0.8328
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 45s - loss: 0.0539 - acc: 1.0000 - val_loss: 1.1945 - val_acc: 0.8328
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 45s - loss: 0.0537 - acc: 1.0000 - val_loss: 1.1958 - val_acc: 0.8330
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 45s - loss: 0.0536 - acc: 1.0000 - val_loss: 1.1931 - val_acc: 0.8320
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 45s - loss: 0.0535 - acc: 1.0000 - val_loss: 1.1943 - val_acc: 0.8332
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 44s - loss: 0.0534 - acc: 1.0000 - val_loss: 1.1940 - val_acc: 0.8320
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 45s - loss: 0.0532 - acc: 1.0000 - val_loss: 1.1953 - val_acc: 0.8322
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 45s - loss: 0.0531 - acc: 1.0000 - val_loss: 1.1957 - val_acc: 0.8326
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 45s - loss: 0.0530 - acc: 1.0000 - val_loss: 1.1966 - val_acc: 0.8322
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 45s - loss: 0.0529 - acc: 1.0000 - val_loss: 1.1971 - val_acc: 0.8318
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 45s - loss: 0.0528 - acc: 1.0000 - val_loss: 1.1978 - val_acc: 0.8322
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 45s - loss: 0.0528 - acc: 1.0000 - val_loss: 1.1976 - val_acc: 0.8324
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 45s - loss: 0.0527 - acc: 1.0000 - val_loss: 1.1975 - val_acc: 0.8326
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 45s - loss: 0.0526 - acc: 1.0000 - val_loss: 1.1967 - val_acc: 0.8328
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 45s - loss: 0.0525 - acc: 1.0000 - val_loss: 1.1981 - val_acc: 0.8320
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 44s - loss: 0.0524 - acc: 1.0000 - val_loss: 1.1975 - val_acc: 0.8328
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 45s - loss: 0.0524 - acc: 1.0000 - val_loss: 1.1959 - val_acc: 0.8330
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 45s - loss: 0.0523 - acc: 1.0000 - val_loss: 1.1974 - val_acc: 0.8324
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 45s - loss: 0.0523 - acc: 1.0000 - val_loss: 1.1961 - val_acc: 0.8324
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 45s - loss: 0.0522 - acc: 1.0000 - val_loss: 1.1978 - val_acc: 0.8326
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 45s - loss: 0.0521 - acc: 1.0000 - val_loss: 1.1959 - val_acc: 0.8322
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 45s - loss: 0.0520 - acc: 1.0000 - val_loss: 1.1970 - val_acc: 0.8324
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 45s - loss: 0.0520 - acc: 1.0000 - val_loss: 1.1979 - val_acc: 0.8324
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 45s - loss: 0.0519 - acc: 1.0000 - val_loss: 1.1966 - val_acc: 0.8322
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 45s - loss: 0.0518 - acc: 1.0000 - val_loss: 1.1969 - val_acc: 0.8326
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 45s - loss: 0.0518 - acc: 1.0000 - val_loss: 1.1962 - val_acc: 0.8328
Done

