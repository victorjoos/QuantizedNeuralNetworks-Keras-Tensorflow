Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
ternary_conv2d_1 (TernaryConv2D (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_1[0][0]           
__________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_2 (TernaryConv2D (None, 32, 32, 16)   2320        leaky_re_lu_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_2[0][0]           
__________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_3 (TernaryConv2D (None, 32, 32, 16)   2320        leaky_re_lu_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_3[0][0]           
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_1[0][0]              
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_4 (TernaryConv2D (None, 32, 32, 16)   2320        leaky_re_lu_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_4[0][0]           
__________________________________________________________________________________________________
leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_5 (TernaryConv2D (None, 32, 32, 16)   2320        leaky_re_lu_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_5[0][0]           
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_3[0][0]              
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_6 (TernaryConv2D (None, 32, 32, 16)   2320        leaky_re_lu_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_6[0][0]           
__________________________________________________________________________________________________
leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_7 (TernaryConv2D (None, 32, 32, 16)   2320        leaky_re_lu_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_7[0][0]           
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_5[0][0]              
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_8 (TernaryConv2D (None, 32, 32, 16)   2320        leaky_re_lu_7[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_8[0][0]           
__________________________________________________________________________________________________
leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_9 (TernaryConv2D (None, 32, 32, 16)   2320        leaky_re_lu_8[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_9[0][0]           
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_7[0][0]              
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_9 (LeakyReLU)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_10 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_9[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_10[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_10 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_11 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_10[0][0]             
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_11[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_9[0][0]              
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_11 (LeakyReLU)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_12 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_11[0][0]             
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_12[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_12 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_13 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_12[0][0]             
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_13[0][0]          
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_11[0][0]             
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_13 (LeakyReLU)      (None, 32, 32, 16)   0           add_6[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_14 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_13[0][0]             
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_14[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_14 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_15 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_14[0][0]             
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_15[0][0]          
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_13[0][0]             
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_15 (LeakyReLU)      (None, 32, 32, 16)   0           add_7[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_16 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_15[0][0]             
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_16[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_16 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_17 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_16[0][0]             
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_17[0][0]          
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_15[0][0]             
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_17 (LeakyReLU)      (None, 32, 32, 16)   0           add_8[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_18 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_17[0][0]             
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_18[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_18 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_19 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_18[0][0]             
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_19[0][0]          
__________________________________________________________________________________________________
add_9 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_17[0][0]             
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_19 (LeakyReLU)      (None, 32, 32, 16)   0           add_9[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_20 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_19[0][0]             
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_20[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_20 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_21 (TernaryConv2 (None, 32, 32, 16)   2320        leaky_re_lu_20[0][0]             
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_21[0][0]          
__________________________________________________________________________________________________
add_10 (Add)                    (None, 32, 32, 16)   0           leaky_re_lu_19[0][0]             
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_21 (LeakyReLU)      (None, 32, 32, 16)   0           add_10[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_22 (TernaryConv2 (None, 16, 16, 32)   4640        leaky_re_lu_21[0][0]             
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_22[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_22 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_23 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_22[0][0]             
__________________________________________________________________________________________________
ternary_conv2d_24 (TernaryConv2 (None, 16, 16, 32)   544         leaky_re_lu_21[0][0]             
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_23[0][0]          
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 32)   0           ternary_conv2d_24[0][0]          
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_23 (LeakyReLU)      (None, 16, 16, 32)   0           add_11[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_25 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_23[0][0]             
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_25[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_24 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_26 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_24[0][0]             
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_26[0][0]          
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_23[0][0]             
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_25 (LeakyReLU)      (None, 16, 16, 32)   0           add_12[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_27 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_25[0][0]             
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_27[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_26 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_28 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_26[0][0]             
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_28[0][0]          
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_25[0][0]             
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_27 (LeakyReLU)      (None, 16, 16, 32)   0           add_13[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_29 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_27[0][0]             
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_29[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_28 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_30 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_28[0][0]             
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_30[0][0]          
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_27[0][0]             
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_29 (LeakyReLU)      (None, 16, 16, 32)   0           add_14[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_31 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_29[0][0]             
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_31[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_30 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_32 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_30[0][0]             
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_32[0][0]          
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_29[0][0]             
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_31 (LeakyReLU)      (None, 16, 16, 32)   0           add_15[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_33 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_31[0][0]             
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_33[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_32 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_34 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_32[0][0]             
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_34[0][0]          
__________________________________________________________________________________________________
add_16 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_31[0][0]             
                                                                 batch_normalization_33[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_33 (LeakyReLU)      (None, 16, 16, 32)   0           add_16[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_35 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_33[0][0]             
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_35[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_34 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_36 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_34[0][0]             
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_36[0][0]          
__________________________________________________________________________________________________
add_17 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_33[0][0]             
                                                                 batch_normalization_35[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_35 (LeakyReLU)      (None, 16, 16, 32)   0           add_17[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_37 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_35[0][0]             
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_37[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_36 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_38 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_36[0][0]             
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_38[0][0]          
__________________________________________________________________________________________________
add_18 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_35[0][0]             
                                                                 batch_normalization_37[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_37 (LeakyReLU)      (None, 16, 16, 32)   0           add_18[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_39 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_37[0][0]             
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_39[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_38 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_40 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_38[0][0]             
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_40[0][0]          
__________________________________________________________________________________________________
add_19 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_37[0][0]             
                                                                 batch_normalization_39[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_39 (LeakyReLU)      (None, 16, 16, 32)   0           add_19[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_41 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_39[0][0]             
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_41[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_40 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_42 (TernaryConv2 (None, 16, 16, 32)   9248        leaky_re_lu_40[0][0]             
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_42[0][0]          
__________________________________________________________________________________________________
add_20 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_39[0][0]             
                                                                 batch_normalization_41[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_41 (LeakyReLU)      (None, 16, 16, 32)   0           add_20[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_43 (TernaryConv2 (None, 8, 8, 64)     18496       leaky_re_lu_41[0][0]             
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_43[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_42 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_44 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_42[0][0]             
__________________________________________________________________________________________________
ternary_conv2d_45 (TernaryConv2 (None, 8, 8, 64)     2112        leaky_re_lu_41[0][0]             
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_44[0][0]          
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 8, 64)     0           ternary_conv2d_45[0][0]          
                                                                 batch_normalization_43[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_43 (LeakyReLU)      (None, 8, 8, 64)     0           add_21[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_46 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_43[0][0]             
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_46[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_44 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_47 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_44[0][0]             
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_47[0][0]          
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_43[0][0]             
                                                                 batch_normalization_45[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_45 (LeakyReLU)      (None, 8, 8, 64)     0           add_22[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_48 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_45[0][0]             
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_48[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_46 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_49 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_46[0][0]             
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_49[0][0]          
__________________________________________________________________________________________________
add_23 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_45[0][0]             
                                                                 batch_normalization_47[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_47 (LeakyReLU)      (None, 8, 8, 64)     0           add_23[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_50 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_47[0][0]             
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_50[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_48 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_51 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_48[0][0]             
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_51[0][0]          
__________________________________________________________________________________________________
add_24 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_47[0][0]             
                                                                 batch_normalization_49[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_49 (LeakyReLU)      (None, 8, 8, 64)     0           add_24[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_52 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_49[0][0]             
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_52[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_50 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_53 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_50[0][0]             
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_53[0][0]          
__________________________________________________________________________________________________
add_25 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_49[0][0]             
                                                                 batch_normalization_51[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_51 (LeakyReLU)      (None, 8, 8, 64)     0           add_25[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_54 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_51[0][0]             
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_54[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_52 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_55 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_52[0][0]             
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_55[0][0]          
__________________________________________________________________________________________________
add_26 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_51[0][0]             
                                                                 batch_normalization_53[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_53 (LeakyReLU)      (None, 8, 8, 64)     0           add_26[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_56 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_53[0][0]             
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_56[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_54 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_57 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_54[0][0]             
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_57[0][0]          
__________________________________________________________________________________________________
add_27 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_53[0][0]             
                                                                 batch_normalization_55[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_55 (LeakyReLU)      (None, 8, 8, 64)     0           add_27[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_58 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_55[0][0]             
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_58[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_56 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_59 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_56[0][0]             
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_59[0][0]          
__________________________________________________________________________________________________
add_28 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_55[0][0]             
                                                                 batch_normalization_57[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_57 (LeakyReLU)      (None, 8, 8, 64)     0           add_28[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_60 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_57[0][0]             
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_60[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_58 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_61 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_58[0][0]             
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_61[0][0]          
__________________________________________________________________________________________________
add_29 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_57[0][0]             
                                                                 batch_normalization_59[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_59 (LeakyReLU)      (None, 8, 8, 64)     0           add_29[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_62 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_59[0][0]             
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_62[0][0]          
__________________________________________________________________________________________________
leaky_re_lu_60 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_63 (TernaryConv2 (None, 8, 8, 64)     36928       leaky_re_lu_60[0][0]             
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_63[0][0]          
__________________________________________________________________________________________________
add_30 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_59[0][0]             
                                                                 batch_normalization_61[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_61 (LeakyReLU)      (None, 8, 8, 64)     0           add_30[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           leaky_re_lu_61[0][0]             
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
ternary_dense_1 (TernaryDense)  (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 959,658
Trainable params: 955,146
Non-trainable params: 4,512
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.24420, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 124s - loss: 35.1319 - acc: 0.2373 - val_loss: 29.7038 - val_acc: 0.2442
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.24420 to 0.29740, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 48s - loss: 25.7283 - acc: 0.3125 - val_loss: 23.0358 - val_acc: 0.2974
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc did not improve
 - 47s - loss: 21.0429 - acc: 0.3415 - val_loss: 19.5105 - val_acc: 0.2790
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.29740 to 0.31640, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 17.7993 - acc: 0.3679 - val_loss: 16.7505 - val_acc: 0.3164
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc improved from 0.31640 to 0.33220, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 15.4797 - acc: 0.3910 - val_loss: 14.9198 - val_acc: 0.3322
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc improved from 0.33220 to 0.36180, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 13.7936 - acc: 0.4034 - val_loss: 13.2685 - val_acc: 0.3618
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc did not improve
 - 47s - loss: 12.4972 - acc: 0.4186 - val_loss: 12.2917 - val_acc: 0.3362
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc did not improve
 - 48s - loss: 11.5164 - acc: 0.4223 - val_loss: 11.3081 - val_acc: 0.3496
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 47s - loss: 10.7159 - acc: 0.4347 - val_loss: 10.7939 - val_acc: 0.3434
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 47s - loss: 10.0625 - acc: 0.4436 - val_loss: 10.7869 - val_acc: 0.2512
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 48s - loss: 9.4900 - acc: 0.4581 - val_loss: 9.7576 - val_acc: 0.3408
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 47s - loss: 9.0078 - acc: 0.4678 - val_loss: 10.0075 - val_acc: 0.2658
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc did not improve
 - 47s - loss: 8.6104 - acc: 0.4702 - val_loss: 9.0102 - val_acc: 0.3584
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 47s - loss: 8.2781 - acc: 0.4722 - val_loss: 8.5733 - val_acc: 0.3610
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc did not improve
 - 47s - loss: 7.9513 - acc: 0.4806 - val_loss: 8.4206 - val_acc: 0.3560
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 47s - loss: 7.6760 - acc: 0.4851 - val_loss: 9.1088 - val_acc: 0.2296
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 48s - loss: 7.4456 - acc: 0.4863 - val_loss: 8.6265 - val_acc: 0.2658
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc improved from 0.36180 to 0.45380, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 5.3350 - acc: 0.5006 - val_loss: 4.8727 - val_acc: 0.4538
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 47s - loss: 4.2390 - acc: 0.5479 - val_loss: 4.8679 - val_acc: 0.4174
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 47s - loss: 4.0851 - acc: 0.5495 - val_loss: 5.2962 - val_acc: 0.3940
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 47s - loss: 3.7929 - acc: 0.5630 - val_loss: 4.3594 - val_acc: 0.3610
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc improved from 0.45380 to 0.52940, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 2.3210 - acc: 0.6114 - val_loss: 2.6238 - val_acc: 0.5294
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 47s - loss: 2.1510 - acc: 0.6332 - val_loss: 4.2026 - val_acc: 0.2676
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc improved from 0.52940 to 0.54840, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 2.0257 - acc: 0.6422 - val_loss: 2.5690 - val_acc: 0.5484
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 47s - loss: 1.8932 - acc: 0.6548 - val_loss: 2.5348 - val_acc: 0.5308
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 47s - loss: 1.7967 - acc: 0.6590 - val_loss: 2.5305 - val_acc: 0.5256
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 49s - loss: 1.7008 - acc: 0.6707 - val_loss: 2.3079 - val_acc: 0.5464
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 48s - loss: 1.6051 - acc: 0.6803 - val_loss: 2.4172 - val_acc: 0.4978
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc improved from 0.54840 to 0.57640, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 1.5164 - acc: 0.6855 - val_loss: 1.8357 - val_acc: 0.5764
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 47s - loss: 1.4618 - acc: 0.6863 - val_loss: 2.1158 - val_acc: 0.5316
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc improved from 0.57640 to 0.58460, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 50s - loss: 1.3913 - acc: 0.6924 - val_loss: 1.7117 - val_acc: 0.5846
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc improved from 0.58460 to 0.58680, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 1.3237 - acc: 0.6991 - val_loss: 1.6422 - val_acc: 0.5868
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 47s - loss: 1.2836 - acc: 0.6965 - val_loss: 2.8946 - val_acc: 0.3876
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 48s - loss: 1.2226 - acc: 0.7064 - val_loss: 2.1063 - val_acc: 0.4824
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 47s - loss: 1.1668 - acc: 0.7136 - val_loss: 1.6699 - val_acc: 0.5792
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc improved from 0.58680 to 0.68760, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 1.1356 - acc: 0.7130 - val_loss: 1.2116 - val_acc: 0.6876
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 47s - loss: 1.0909 - acc: 0.7191 - val_loss: 1.3788 - val_acc: 0.6342
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 48s - loss: 1.0598 - acc: 0.7206 - val_loss: 2.3321 - val_acc: 0.4426
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc improved from 0.68760 to 0.69360, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 1.0352 - acc: 0.7217 - val_loss: 1.1210 - val_acc: 0.6936
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 47s - loss: 1.0061 - acc: 0.7259 - val_loss: 1.6958 - val_acc: 0.5366
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 47s - loss: 0.9794 - acc: 0.7277 - val_loss: 1.2839 - val_acc: 0.6406
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 47s - loss: 0.9526 - acc: 0.7317 - val_loss: 1.4640 - val_acc: 0.5800
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 47s - loss: 0.9365 - acc: 0.7327 - val_loss: 1.6459 - val_acc: 0.5520
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 47s - loss: 0.9224 - acc: 0.7336 - val_loss: 1.0497 - val_acc: 0.6822
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 47s - loss: 0.8990 - acc: 0.7334 - val_loss: 1.1968 - val_acc: 0.6306
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 47s - loss: 0.8901 - acc: 0.7368 - val_loss: 1.2726 - val_acc: 0.6332
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 47s - loss: 0.8673 - acc: 0.7390 - val_loss: 1.3228 - val_acc: 0.6270
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 48s - loss: 0.8545 - acc: 0.7435 - val_loss: 1.2118 - val_acc: 0.6248
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 47s - loss: 0.8478 - acc: 0.7418 - val_loss: 1.2670 - val_acc: 0.6262
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 47s - loss: 0.8289 - acc: 0.7446 - val_loss: 1.6028 - val_acc: 0.5488
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 47s - loss: 0.8168 - acc: 0.7470 - val_loss: 1.2282 - val_acc: 0.6180
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 47s - loss: 0.8184 - acc: 0.7436 - val_loss: 1.6328 - val_acc: 0.5760
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 47s - loss: 0.7968 - acc: 0.7508 - val_loss: 1.3508 - val_acc: 0.5774
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 47s - loss: 0.7837 - acc: 0.7530 - val_loss: 1.1789 - val_acc: 0.6298
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 47s - loss: 0.7761 - acc: 0.7549 - val_loss: 1.2026 - val_acc: 0.6354
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 47s - loss: 0.7750 - acc: 0.7541 - val_loss: 1.3146 - val_acc: 0.6070
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 47s - loss: 0.7711 - acc: 0.7535 - val_loss: 1.2550 - val_acc: 0.6062
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 47s - loss: 0.7554 - acc: 0.7579 - val_loss: 1.6808 - val_acc: 0.5440
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc improved from 0.69360 to 0.72400, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 0.7491 - acc: 0.7569 - val_loss: 0.8938 - val_acc: 0.7240
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 47s - loss: 0.7433 - acc: 0.7600 - val_loss: 1.2438 - val_acc: 0.6362
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 47s - loss: 0.7449 - acc: 0.7616 - val_loss: 1.2307 - val_acc: 0.6238
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 47s - loss: 0.7416 - acc: 0.7613 - val_loss: 1.0251 - val_acc: 0.6788
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 47s - loss: 0.7361 - acc: 0.7617 - val_loss: 0.9424 - val_acc: 0.6974
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 48s - loss: 0.7227 - acc: 0.7650 - val_loss: 1.0939 - val_acc: 0.6488
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 47s - loss: 0.7280 - acc: 0.7621 - val_loss: 0.9145 - val_acc: 0.7050
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 47s - loss: 0.7150 - acc: 0.7666 - val_loss: 1.0400 - val_acc: 0.6800
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 47s - loss: 0.7173 - acc: 0.7665 - val_loss: 1.2267 - val_acc: 0.6246
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 47s - loss: 0.7094 - acc: 0.7681 - val_loss: 0.9315 - val_acc: 0.7018
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 47s - loss: 0.6919 - acc: 0.7722 - val_loss: 1.3217 - val_acc: 0.6058
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 47s - loss: 0.6936 - acc: 0.7735 - val_loss: 1.2702 - val_acc: 0.6192
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 47s - loss: 0.6974 - acc: 0.7709 - val_loss: 1.0607 - val_acc: 0.6846
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 47s - loss: 0.6862 - acc: 0.7760 - val_loss: 0.9978 - val_acc: 0.6906
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 47s - loss: 0.6915 - acc: 0.7740 - val_loss: 0.8814 - val_acc: 0.7074
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 47s - loss: 0.6884 - acc: 0.7742 - val_loss: 0.9585 - val_acc: 0.6850
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 47s - loss: 0.6911 - acc: 0.7726 - val_loss: 1.0564 - val_acc: 0.6358
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 47s - loss: 0.6767 - acc: 0.7758 - val_loss: 0.9742 - val_acc: 0.6886
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 47s - loss: 0.6779 - acc: 0.7766 - val_loss: 0.9170 - val_acc: 0.6882
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 47s - loss: 0.6729 - acc: 0.7785 - val_loss: 1.6314 - val_acc: 0.5042
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 47s - loss: 0.6738 - acc: 0.7783 - val_loss: 1.0802 - val_acc: 0.6410
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 47s - loss: 0.6652 - acc: 0.7785 - val_loss: 1.1496 - val_acc: 0.6386
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 47s - loss: 0.6640 - acc: 0.7808 - val_loss: 0.8491 - val_acc: 0.7232
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.72400 to 0.80800, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 0.4770 - acc: 0.8478 - val_loss: 0.5883 - val_acc: 0.8080
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.80800 to 0.82300, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 0.4289 - acc: 0.8639 - val_loss: 0.5595 - val_acc: 0.8230
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc did not improve
 - 47s - loss: 0.4107 - acc: 0.8690 - val_loss: 0.5917 - val_acc: 0.8088
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc improved from 0.82300 to 0.82520, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 0.3974 - acc: 0.8730 - val_loss: 0.5517 - val_acc: 0.8252
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 47s - loss: 0.3893 - acc: 0.8762 - val_loss: 0.5625 - val_acc: 0.8236
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 47s - loss: 0.3810 - acc: 0.8782 - val_loss: 0.6154 - val_acc: 0.8050
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 47s - loss: 0.3752 - acc: 0.8806 - val_loss: 0.5772 - val_acc: 0.8162
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 47s - loss: 0.3711 - acc: 0.8821 - val_loss: 0.6570 - val_acc: 0.7914
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 47s - loss: 0.3608 - acc: 0.8844 - val_loss: 0.6005 - val_acc: 0.8150
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 47s - loss: 0.3594 - acc: 0.8845 - val_loss: 0.6560 - val_acc: 0.7994
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 47s - loss: 0.3487 - acc: 0.8867 - val_loss: 0.6236 - val_acc: 0.8068
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 47s - loss: 0.3489 - acc: 0.8877 - val_loss: 0.6822 - val_acc: 0.7982
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 47s - loss: 0.3445 - acc: 0.8904 - val_loss: 0.6031 - val_acc: 0.8088
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 47s - loss: 0.3385 - acc: 0.8917 - val_loss: 0.6894 - val_acc: 0.7896
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 47s - loss: 0.3357 - acc: 0.8925 - val_loss: 0.6506 - val_acc: 0.8078
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 48s - loss: 0.3294 - acc: 0.8932 - val_loss: 0.6515 - val_acc: 0.7970
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 47s - loss: 0.3303 - acc: 0.8938 - val_loss: 0.6031 - val_acc: 0.8170
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 47s - loss: 0.3316 - acc: 0.8938 - val_loss: 0.6040 - val_acc: 0.8146
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 47s - loss: 0.3246 - acc: 0.8943 - val_loss: 0.6028 - val_acc: 0.8218
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 48s - loss: 0.3197 - acc: 0.8974 - val_loss: 0.6401 - val_acc: 0.8024
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 48s - loss: 0.3247 - acc: 0.8946 - val_loss: 0.6518 - val_acc: 0.7998
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 47s - loss: 0.3204 - acc: 0.8976 - val_loss: 0.7064 - val_acc: 0.7836
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 47s - loss: 0.3204 - acc: 0.8957 - val_loss: 0.6298 - val_acc: 0.8092
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 47s - loss: 0.3148 - acc: 0.8965 - val_loss: 0.6821 - val_acc: 0.8030
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 48s - loss: 0.3126 - acc: 0.8982 - val_loss: 0.7096 - val_acc: 0.7828
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 47s - loss: 0.3127 - acc: 0.8984 - val_loss: 0.7697 - val_acc: 0.7842
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 47s - loss: 0.3126 - acc: 0.8975 - val_loss: 0.6699 - val_acc: 0.7972
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 47s - loss: 0.3070 - acc: 0.9008 - val_loss: 0.7329 - val_acc: 0.7866
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 47s - loss: 0.3038 - acc: 0.9008 - val_loss: 0.6207 - val_acc: 0.8178
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 48s - loss: 0.3012 - acc: 0.9034 - val_loss: 0.6769 - val_acc: 0.8000
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 47s - loss: 0.3064 - acc: 0.8998 - val_loss: 0.7290 - val_acc: 0.7858
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 48s - loss: 0.3030 - acc: 0.9021 - val_loss: 0.7401 - val_acc: 0.7876
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 47s - loss: 0.3020 - acc: 0.9011 - val_loss: 0.6686 - val_acc: 0.7950
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 47s - loss: 0.2995 - acc: 0.9016 - val_loss: 0.6555 - val_acc: 0.8028
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 48s - loss: 0.2959 - acc: 0.9048 - val_loss: 0.7920 - val_acc: 0.7756
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 47s - loss: 0.3002 - acc: 0.9026 - val_loss: 0.6632 - val_acc: 0.8044
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 48s - loss: 0.3028 - acc: 0.9005 - val_loss: 0.7385 - val_acc: 0.7848
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 47s - loss: 0.3007 - acc: 0.9011 - val_loss: 0.8137 - val_acc: 0.7618
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 47s - loss: 0.2919 - acc: 0.9051 - val_loss: 0.6266 - val_acc: 0.8190
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 47s - loss: 0.2927 - acc: 0.9047 - val_loss: 0.7992 - val_acc: 0.7774
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc improved from 0.82520 to 0.84060, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 0.1993 - acc: 0.9416 - val_loss: 0.5715 - val_acc: 0.8406
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 47s - loss: 0.1738 - acc: 0.9512 - val_loss: 0.5636 - val_acc: 0.8404
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc improved from 0.84060 to 0.84300, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 0.1694 - acc: 0.9522 - val_loss: 0.5730 - val_acc: 0.8430
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 47s - loss: 0.1696 - acc: 0.9514 - val_loss: 0.6462 - val_acc: 0.8320
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 47s - loss: 0.1647 - acc: 0.9526 - val_loss: 0.6254 - val_acc: 0.8314
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 47s - loss: 0.1649 - acc: 0.9532 - val_loss: 0.6148 - val_acc: 0.8348
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 47s - loss: 0.1632 - acc: 0.9531 - val_loss: 0.5907 - val_acc: 0.8358
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 48s - loss: 0.1629 - acc: 0.9516 - val_loss: 0.5794 - val_acc: 0.8390
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 47s - loss: 0.1615 - acc: 0.9530 - val_loss: 0.6000 - val_acc: 0.8418
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 48s - loss: 0.1621 - acc: 0.9525 - val_loss: 0.6105 - val_acc: 0.8344
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 47s - loss: 0.1596 - acc: 0.9526 - val_loss: 0.6667 - val_acc: 0.8276
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 47s - loss: 0.1604 - acc: 0.9539 - val_loss: 0.6012 - val_acc: 0.8350
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 47s - loss: 0.1577 - acc: 0.9541 - val_loss: 0.6806 - val_acc: 0.8174
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 47s - loss: 0.1597 - acc: 0.9530 - val_loss: 0.6703 - val_acc: 0.8268
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 48s - loss: 0.1565 - acc: 0.9545 - val_loss: 0.7384 - val_acc: 0.8148
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 47s - loss: 0.1579 - acc: 0.9542 - val_loss: 0.6456 - val_acc: 0.8260
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 47s - loss: 0.1576 - acc: 0.9545 - val_loss: 0.6532 - val_acc: 0.8280
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 47s - loss: 0.1558 - acc: 0.9541 - val_loss: 0.6592 - val_acc: 0.8190
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 47s - loss: 0.1540 - acc: 0.9555 - val_loss: 0.6791 - val_acc: 0.8234
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 47s - loss: 0.1547 - acc: 0.9543 - val_loss: 0.6808 - val_acc: 0.8274
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 47s - loss: 0.1508 - acc: 0.9554 - val_loss: 0.8147 - val_acc: 0.7930
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 47s - loss: 0.1529 - acc: 0.9560 - val_loss: 0.7139 - val_acc: 0.8204
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 47s - loss: 0.1577 - acc: 0.9522 - val_loss: 0.6478 - val_acc: 0.8286
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 47s - loss: 0.1525 - acc: 0.9556 - val_loss: 0.7072 - val_acc: 0.8150
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 47s - loss: 0.1560 - acc: 0.9531 - val_loss: 0.6440 - val_acc: 0.8254
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 47s - loss: 0.1501 - acc: 0.9564 - val_loss: 0.7347 - val_acc: 0.8106
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 47s - loss: 0.1518 - acc: 0.9557 - val_loss: 0.7176 - val_acc: 0.8168
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 47s - loss: 0.1512 - acc: 0.9560 - val_loss: 0.6809 - val_acc: 0.8188
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 47s - loss: 0.1538 - acc: 0.9538 - val_loss: 0.6863 - val_acc: 0.8336
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 47s - loss: 0.1506 - acc: 0.9557 - val_loss: 0.7688 - val_acc: 0.8100
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 47s - loss: 0.1521 - acc: 0.9561 - val_loss: 0.7358 - val_acc: 0.8154
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 48s - loss: 0.1549 - acc: 0.9541 - val_loss: 0.6456 - val_acc: 0.8308
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 47s - loss: 0.1578 - acc: 0.9524 - val_loss: 0.6630 - val_acc: 0.8222
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 48s - loss: 0.1513 - acc: 0.9561 - val_loss: 0.8249 - val_acc: 0.7940
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 47s - loss: 0.1527 - acc: 0.9552 - val_loss: 0.7074 - val_acc: 0.8208
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 47s - loss: 0.1492 - acc: 0.9556 - val_loss: 0.6933 - val_acc: 0.8276
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 47s - loss: 0.1502 - acc: 0.9557 - val_loss: 0.7098 - val_acc: 0.8164
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 47s - loss: 0.1469 - acc: 0.9569 - val_loss: 0.7464 - val_acc: 0.8170
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 47s - loss: 0.1478 - acc: 0.9562 - val_loss: 0.7098 - val_acc: 0.8230
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 47s - loss: 0.1508 - acc: 0.9560 - val_loss: 0.7458 - val_acc: 0.8140
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 47s - loss: 0.1080 - acc: 0.9736 - val_loss: 0.6590 - val_acc: 0.8322
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 47s - loss: 0.0979 - acc: 0.9780 - val_loss: 0.6200 - val_acc: 0.8394
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc improved from 0.84300 to 0.84320, saving model to ./weights/CIFAR-10_tnn_8b_4b_1_64_1_128_1_256.hdf5
 - 49s - loss: 0.0980 - acc: 0.9781 - val_loss: 0.6334 - val_acc: 0.8432
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 47s - loss: 0.0985 - acc: 0.9773 - val_loss: 0.6224 - val_acc: 0.8428
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 48s - loss: 0.1002 - acc: 0.9770 - val_loss: 0.6450 - val_acc: 0.8404
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 48s - loss: 0.1002 - acc: 0.9769 - val_loss: 0.6124 - val_acc: 0.8378
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 48s - loss: 0.0989 - acc: 0.9767 - val_loss: 0.6650 - val_acc: 0.8358
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 47s - loss: 0.1027 - acc: 0.9754 - val_loss: 0.7077 - val_acc: 0.8268
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 48s - loss: 0.1020 - acc: 0.9749 - val_loss: 0.6622 - val_acc: 0.8374
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 47s - loss: 0.0996 - acc: 0.9764 - val_loss: 0.7022 - val_acc: 0.8258
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 47s - loss: 0.1023 - acc: 0.9755 - val_loss: 0.6456 - val_acc: 0.8360
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 48s - loss: 0.1053 - acc: 0.9742 - val_loss: 0.6823 - val_acc: 0.8308
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 47s - loss: 0.1053 - acc: 0.9745 - val_loss: 0.6697 - val_acc: 0.8422
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 48s - loss: 0.1029 - acc: 0.9743 - val_loss: 0.6313 - val_acc: 0.8394
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 47s - loss: 0.1055 - acc: 0.9742 - val_loss: 0.7040 - val_acc: 0.8326
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 47s - loss: 0.1024 - acc: 0.9755 - val_loss: 0.7033 - val_acc: 0.8294
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 48s - loss: 0.1029 - acc: 0.9747 - val_loss: 0.6780 - val_acc: 0.8322
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 48s - loss: 0.1017 - acc: 0.9756 - val_loss: 0.6726 - val_acc: 0.8400
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 47s - loss: 0.1058 - acc: 0.9732 - val_loss: 0.6928 - val_acc: 0.8282
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 47s - loss: 0.1064 - acc: 0.9726 - val_loss: 0.7071 - val_acc: 0.8220
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 48s - loss: 0.0940 - acc: 0.9792 - val_loss: 0.6796 - val_acc: 0.8388
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 47s - loss: 0.0972 - acc: 0.9774 - val_loss: 0.6728 - val_acc: 0.8344
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 47s - loss: 0.0983 - acc: 0.9770 - val_loss: 0.6412 - val_acc: 0.8408
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 47s - loss: 0.1004 - acc: 0.9762 - val_loss: 0.7007 - val_acc: 0.8250
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 47s - loss: 0.1021 - acc: 0.9754 - val_loss: 0.7172 - val_acc: 0.8302
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 47s - loss: 0.1000 - acc: 0.9758 - val_loss: 0.7612 - val_acc: 0.8156
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 47s - loss: 0.1020 - acc: 0.9755 - val_loss: 0.6920 - val_acc: 0.8324
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 47s - loss: 0.1021 - acc: 0.9755 - val_loss: 0.7136 - val_acc: 0.8240
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 48s - loss: 0.1010 - acc: 0.9757 - val_loss: 0.7262 - val_acc: 0.8258
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 47s - loss: 0.1023 - acc: 0.9744 - val_loss: 0.7819 - val_acc: 0.8058
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 48s - loss: 0.1030 - acc: 0.9747 - val_loss: 0.7777 - val_acc: 0.8166
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 48s - loss: 0.1021 - acc: 0.9752 - val_loss: 0.7038 - val_acc: 0.8268
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 47s - loss: 0.1001 - acc: 0.9757 - val_loss: 0.7507 - val_acc: 0.8176
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 47s - loss: 0.1035 - acc: 0.9742 - val_loss: 0.6660 - val_acc: 0.8396
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 47s - loss: 0.1053 - acc: 0.9733 - val_loss: 0.6668 - val_acc: 0.8344
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 47s - loss: 0.1009 - acc: 0.9760 - val_loss: 0.6840 - val_acc: 0.8346
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 47s - loss: 0.1039 - acc: 0.9736 - val_loss: 0.6910 - val_acc: 0.8276
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 47s - loss: 0.1028 - acc: 0.9740 - val_loss: 0.7336 - val_acc: 0.8276
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 47s - loss: 0.1028 - acc: 0.9746 - val_loss: 0.6941 - val_acc: 0.8346
Done

