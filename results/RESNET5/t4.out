Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
ternary_conv2d_1 (TernaryConv2D (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_2 (TernaryConv2D (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_2[0][0]           
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_3 (TernaryConv2D (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_3[0][0]           
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_4 (TernaryConv2D (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_4[0][0]           
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_5 (TernaryConv2D (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_5[0][0]           
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_6 (TernaryConv2D (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_6[0][0]           
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_7 (TernaryConv2D (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_7[0][0]           
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_8 (TernaryConv2D (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_8[0][0]           
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_9 (TernaryConv2D (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_9[0][0]           
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_10 (TernaryConv2 (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_10[0][0]          
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_11 (TernaryConv2 (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_11[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_12 (TernaryConv2 (None, 16, 16, 32)   4640        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_12[0][0]          
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_13 (TernaryConv2 (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_14 (TernaryConv2 (None, 16, 16, 32)   544         activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_13[0][0]          
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           ternary_conv2d_14[0][0]          
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_15 (TernaryConv2 (None, 16, 16, 32)   9248        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_15[0][0]          
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_16 (TernaryConv2 (None, 16, 16, 32)   9248        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_16[0][0]          
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 32)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_17 (TernaryConv2 (None, 16, 16, 32)   9248        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_17[0][0]          
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_18 (TernaryConv2 (None, 16, 16, 32)   9248        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_18[0][0]          
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 32)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_19 (TernaryConv2 (None, 16, 16, 32)   9248        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_19[0][0]          
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_20 (TernaryConv2 (None, 16, 16, 32)   9248        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_20[0][0]          
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 32)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_21 (TernaryConv2 (None, 16, 16, 32)   9248        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_21[0][0]          
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_22 (TernaryConv2 (None, 16, 16, 32)   9248        activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_22[0][0]          
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           activation_19[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_23 (TernaryConv2 (None, 8, 8, 64)     18496       activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_23[0][0]          
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_24 (TernaryConv2 (None, 8, 8, 64)     36928       activation_22[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_25 (TernaryConv2 (None, 8, 8, 64)     2112        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_24[0][0]          
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 64)     0           ternary_conv2d_25[0][0]          
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_26 (TernaryConv2 (None, 8, 8, 64)     36928       activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_26[0][0]          
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_27 (TernaryConv2 (None, 8, 8, 64)     36928       activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_27[0][0]          
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 64)     0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_28 (TernaryConv2 (None, 8, 8, 64)     36928       activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_28[0][0]          
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_29 (TernaryConv2 (None, 8, 8, 64)     36928       activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_29[0][0]          
__________________________________________________________________________________________________
add_13 (Add)                    (None, 8, 8, 64)     0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_30 (TernaryConv2 (None, 8, 8, 64)     36928       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_30[0][0]          
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_31 (TernaryConv2 (None, 8, 8, 64)     36928       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_31[0][0]          
__________________________________________________________________________________________________
add_14 (Add)                    (None, 8, 8, 64)     0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_32 (TernaryConv2 (None, 8, 8, 64)     36928       activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_32[0][0]          
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_33 (TernaryConv2 (None, 8, 8, 64)     36928       activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_33[0][0]          
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 8, 64)     0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_31[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
ternary_dense_1 (TernaryDense)  (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 470,218
Trainable params: 467,946
Non-trainable params: 2,272
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.10260, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 42s - loss: 17.1192 - acc: 0.1024 - val_loss: 16.2831 - val_acc: 0.1026
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.10260 to 0.10600, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 15.5658 - acc: 0.1028 - val_loss: 14.9638 - val_acc: 0.1060
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc did not improve
 - 34s - loss: 14.4010 - acc: 0.1048 - val_loss: 13.9561 - val_acc: 0.1030
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc did not improve
 - 34s - loss: 13.4691 - acc: 0.1002 - val_loss: 13.0554 - val_acc: 0.1006
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc did not improve
 - 34s - loss: 12.6883 - acc: 0.1008 - val_loss: 12.3593 - val_acc: 0.1046
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc improved from 0.10600 to 0.11160, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 12.0244 - acc: 0.1075 - val_loss: 11.7371 - val_acc: 0.1116
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.11160 to 0.11640, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 11.4314 - acc: 0.1253 - val_loss: 11.1944 - val_acc: 0.1164
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc improved from 0.11640 to 0.12880, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 10.9212 - acc: 0.1307 - val_loss: 10.7499 - val_acc: 0.1288
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc improved from 0.12880 to 0.13820, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 10.4605 - acc: 0.1340 - val_loss: 10.2870 - val_acc: 0.1382
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc improved from 0.13820 to 0.16260, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 9.9775 - acc: 0.1689 - val_loss: 9.7966 - val_acc: 0.1626
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 34s - loss: 9.5669 - acc: 0.1830 - val_loss: 9.5061 - val_acc: 0.1546
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc improved from 0.16260 to 0.17740, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 9.1816 - acc: 0.1885 - val_loss: 9.0284 - val_acc: 0.1774
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc improved from 0.17740 to 0.18020, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 8.8256 - acc: 0.1898 - val_loss: 8.6780 - val_acc: 0.1802
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 34s - loss: 8.4669 - acc: 0.2070 - val_loss: 8.3533 - val_acc: 0.1790
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc improved from 0.18020 to 0.19360, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 8.1255 - acc: 0.2207 - val_loss: 8.1016 - val_acc: 0.1936
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc improved from 0.19360 to 0.22000, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 7.8191 - acc: 0.2274 - val_loss: 7.6828 - val_acc: 0.2200
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 34s - loss: 7.5118 - acc: 0.2433 - val_loss: 7.4715 - val_acc: 0.2098
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 34s - loss: 7.2555 - acc: 0.2456 - val_loss: 7.2719 - val_acc: 0.2052
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc improved from 0.22000 to 0.23500, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 7.0218 - acc: 0.2496 - val_loss: 6.9443 - val_acc: 0.2350
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 34s - loss: 6.7853 - acc: 0.2655 - val_loss: 6.7444 - val_acc: 0.2340
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc improved from 0.23500 to 0.25760, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 6.5848 - acc: 0.2699 - val_loss: 6.5051 - val_acc: 0.2576
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 34s - loss: 6.3842 - acc: 0.2787 - val_loss: 6.6493 - val_acc: 0.1712
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 34s - loss: 6.2044 - acc: 0.2872 - val_loss: 6.2640 - val_acc: 0.2464
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 34s - loss: 6.0196 - acc: 0.3002 - val_loss: 6.2235 - val_acc: 0.2372
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc improved from 0.25760 to 0.30360, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 5.8732 - acc: 0.3090 - val_loss: 5.8717 - val_acc: 0.3036
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 34s - loss: 5.7453 - acc: 0.3116 - val_loss: 5.7484 - val_acc: 0.3028
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 34s - loss: 5.6344 - acc: 0.3145 - val_loss: 5.6505 - val_acc: 0.2824
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 34s - loss: 5.5122 - acc: 0.3280 - val_loss: 5.5634 - val_acc: 0.2958
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc improved from 0.30360 to 0.31940, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 5.3982 - acc: 0.3346 - val_loss: 5.4602 - val_acc: 0.3194
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 34s - loss: 5.3029 - acc: 0.3402 - val_loss: 5.5955 - val_acc: 0.2520
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 34s - loss: 5.2154 - acc: 0.3412 - val_loss: 5.2718 - val_acc: 0.3126
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc improved from 0.31940 to 0.35440, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 5.1289 - acc: 0.3454 - val_loss: 5.0751 - val_acc: 0.3544
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 34s - loss: 5.0336 - acc: 0.3560 - val_loss: 5.1360 - val_acc: 0.2970
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 34s - loss: 4.9405 - acc: 0.3684 - val_loss: 5.2008 - val_acc: 0.2904
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 34s - loss: 4.8752 - acc: 0.3675 - val_loss: 5.0342 - val_acc: 0.3042
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 34s - loss: 4.7878 - acc: 0.3761 - val_loss: 5.0688 - val_acc: 0.2732
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 34s - loss: 4.7259 - acc: 0.3772 - val_loss: 4.7789 - val_acc: 0.3320
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 34s - loss: 4.6559 - acc: 0.3786 - val_loss: 4.8926 - val_acc: 0.2812
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 34s - loss: 4.5834 - acc: 0.3866 - val_loss: 4.7585 - val_acc: 0.3200
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 34s - loss: 4.5160 - acc: 0.3850 - val_loss: 4.7076 - val_acc: 0.2954
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 34s - loss: 4.4776 - acc: 0.3796 - val_loss: 4.5945 - val_acc: 0.3072
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc improved from 0.35440 to 0.37280, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 4.3786 - acc: 0.3957 - val_loss: 4.4193 - val_acc: 0.3728
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 34s - loss: 4.3171 - acc: 0.3981 - val_loss: 4.4715 - val_acc: 0.3436
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc improved from 0.37280 to 0.39480, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 4.2506 - acc: 0.4023 - val_loss: 4.2471 - val_acc: 0.3948
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 34s - loss: 4.1847 - acc: 0.4026 - val_loss: 4.3744 - val_acc: 0.3248
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 34s - loss: 4.1097 - acc: 0.4143 - val_loss: 4.5768 - val_acc: 0.2680
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 34s - loss: 4.0433 - acc: 0.4187 - val_loss: 4.1751 - val_acc: 0.3726
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 34s - loss: 3.9817 - acc: 0.4217 - val_loss: 4.1131 - val_acc: 0.3526
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc improved from 0.39480 to 0.41000, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 3.9085 - acc: 0.4302 - val_loss: 3.9629 - val_acc: 0.4100
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 34s - loss: 3.8481 - acc: 0.4301 - val_loss: 4.2600 - val_acc: 0.3066
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc improved from 0.41000 to 0.41860, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 3.7810 - acc: 0.4378 - val_loss: 3.8380 - val_acc: 0.4186
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 34s - loss: 3.7216 - acc: 0.4439 - val_loss: 4.2013 - val_acc: 0.2744
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 34s - loss: 3.6658 - acc: 0.4445 - val_loss: 3.8933 - val_acc: 0.3476
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 34s - loss: 3.6048 - acc: 0.4495 - val_loss: 4.1780 - val_acc: 0.3148
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 34s - loss: 3.5432 - acc: 0.4568 - val_loss: 3.7168 - val_acc: 0.3726
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 34s - loss: 3.4866 - acc: 0.4608 - val_loss: 3.6905 - val_acc: 0.3770
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 34s - loss: 3.4327 - acc: 0.4670 - val_loss: 3.7041 - val_acc: 0.3680
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 34s - loss: 3.3766 - acc: 0.4714 - val_loss: 3.7316 - val_acc: 0.3788
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 34s - loss: 3.3187 - acc: 0.4777 - val_loss: 3.6298 - val_acc: 0.3638
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 34s - loss: 3.2641 - acc: 0.4820 - val_loss: 3.5816 - val_acc: 0.3534
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 34s - loss: 3.2130 - acc: 0.4858 - val_loss: 3.4048 - val_acc: 0.4106
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc improved from 0.41860 to 0.42980, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 3.1652 - acc: 0.4880 - val_loss: 3.3230 - val_acc: 0.4298
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 34s - loss: 3.1132 - acc: 0.4944 - val_loss: 3.6148 - val_acc: 0.3384
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 34s - loss: 3.0584 - acc: 0.5021 - val_loss: 3.2432 - val_acc: 0.4290
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 34s - loss: 3.0143 - acc: 0.5038 - val_loss: 3.4778 - val_acc: 0.3434
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 34s - loss: 2.9554 - acc: 0.5163 - val_loss: 3.2574 - val_acc: 0.3936
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc improved from 0.42980 to 0.45540, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 2.9102 - acc: 0.5205 - val_loss: 3.1218 - val_acc: 0.4554
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 34s - loss: 2.8672 - acc: 0.5231 - val_loss: 3.0535 - val_acc: 0.4526
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 34s - loss: 2.8232 - acc: 0.5294 - val_loss: 3.8504 - val_acc: 0.2978
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 34s - loss: 2.7767 - acc: 0.5343 - val_loss: 3.7394 - val_acc: 0.3018
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 34s - loss: 2.7329 - acc: 0.5396 - val_loss: 3.2389 - val_acc: 0.3794
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 34s - loss: 2.6946 - acc: 0.5418 - val_loss: 3.0386 - val_acc: 0.4246
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 34s - loss: 2.6548 - acc: 0.5487 - val_loss: 3.3080 - val_acc: 0.3604
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 34s - loss: 2.6158 - acc: 0.5531 - val_loss: 3.3400 - val_acc: 0.3760
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 34s - loss: 2.5813 - acc: 0.5560 - val_loss: 2.9440 - val_acc: 0.4150
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 34s - loss: 2.5544 - acc: 0.5580 - val_loss: 3.1512 - val_acc: 0.3978
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 34s - loss: 2.5237 - acc: 0.5575 - val_loss: 2.9580 - val_acc: 0.4060
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 34s - loss: 2.4734 - acc: 0.5684 - val_loss: 2.7935 - val_acc: 0.4536
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 34s - loss: 2.4493 - acc: 0.5679 - val_loss: 2.8201 - val_acc: 0.4410
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc improved from 0.45540 to 0.45780, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 2.4156 - acc: 0.5741 - val_loss: 2.7719 - val_acc: 0.4578
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 34s - loss: 2.3763 - acc: 0.5807 - val_loss: 2.8422 - val_acc: 0.4400
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.45780 to 0.61400, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 2.2355 - acc: 0.6291 - val_loss: 2.2754 - val_acc: 0.6140
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.61400 to 0.61620, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 2.1869 - acc: 0.6472 - val_loss: 2.2685 - val_acc: 0.6162
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc did not improve
 - 34s - loss: 2.1638 - acc: 0.6558 - val_loss: 2.2899 - val_acc: 0.6060
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc improved from 0.61620 to 0.62840, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 2.1389 - acc: 0.6625 - val_loss: 2.2407 - val_acc: 0.6284
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 34s - loss: 2.1230 - acc: 0.6647 - val_loss: 2.2939 - val_acc: 0.6158
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 34s - loss: 2.1113 - acc: 0.6712 - val_loss: 2.3009 - val_acc: 0.6084
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 34s - loss: 2.0982 - acc: 0.6726 - val_loss: 2.2390 - val_acc: 0.6110
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 34s - loss: 2.0824 - acc: 0.6785 - val_loss: 2.2914 - val_acc: 0.6114
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 34s - loss: 2.0704 - acc: 0.6801 - val_loss: 2.3032 - val_acc: 0.6004
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 34s - loss: 2.0619 - acc: 0.6820 - val_loss: 2.2937 - val_acc: 0.6058
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 34s - loss: 2.0538 - acc: 0.6836 - val_loss: 2.2550 - val_acc: 0.6162
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 34s - loss: 2.0474 - acc: 0.6862 - val_loss: 2.2395 - val_acc: 0.6172
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 34s - loss: 2.0345 - acc: 0.6912 - val_loss: 2.2618 - val_acc: 0.6240
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 34s - loss: 2.0243 - acc: 0.6945 - val_loss: 2.3026 - val_acc: 0.5960
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 34s - loss: 2.0226 - acc: 0.6923 - val_loss: 2.4145 - val_acc: 0.5692
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 34s - loss: 2.0091 - acc: 0.6971 - val_loss: 2.2541 - val_acc: 0.6064
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 34s - loss: 2.0022 - acc: 0.6994 - val_loss: 2.2576 - val_acc: 0.6176
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 34s - loss: 1.9915 - acc: 0.7017 - val_loss: 2.2336 - val_acc: 0.6218
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 34s - loss: 1.9901 - acc: 0.7019 - val_loss: 2.2327 - val_acc: 0.6192
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 34s - loss: 1.9784 - acc: 0.7063 - val_loss: 2.3645 - val_acc: 0.5910
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 34s - loss: 1.9745 - acc: 0.7076 - val_loss: 2.4634 - val_acc: 0.5680
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 34s - loss: 1.9655 - acc: 0.7083 - val_loss: 2.3028 - val_acc: 0.5956
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 34s - loss: 1.9709 - acc: 0.7058 - val_loss: 2.3082 - val_acc: 0.5974
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 34s - loss: 1.9562 - acc: 0.7109 - val_loss: 2.3210 - val_acc: 0.5984
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 34s - loss: 1.9510 - acc: 0.7109 - val_loss: 2.2259 - val_acc: 0.6182
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 34s - loss: 1.9377 - acc: 0.7137 - val_loss: 2.3407 - val_acc: 0.5870
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 34s - loss: 1.9377 - acc: 0.7153 - val_loss: 2.2671 - val_acc: 0.6094
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 34s - loss: 1.9306 - acc: 0.7141 - val_loss: 2.2908 - val_acc: 0.6002
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 34s - loss: 1.9282 - acc: 0.7182 - val_loss: 2.4622 - val_acc: 0.5650
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 34s - loss: 1.9233 - acc: 0.7178 - val_loss: 2.3371 - val_acc: 0.5790
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 34s - loss: 1.9177 - acc: 0.7190 - val_loss: 2.5039 - val_acc: 0.5548
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 34s - loss: 1.9160 - acc: 0.7220 - val_loss: 2.2151 - val_acc: 0.6276
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 34s - loss: 1.9146 - acc: 0.7190 - val_loss: 2.3929 - val_acc: 0.5746
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 34s - loss: 1.9000 - acc: 0.7251 - val_loss: 2.2860 - val_acc: 0.5964
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 34s - loss: 1.8963 - acc: 0.7243 - val_loss: 2.3765 - val_acc: 0.5870
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 34s - loss: 1.8868 - acc: 0.7281 - val_loss: 2.4106 - val_acc: 0.5650
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 34s - loss: 1.8800 - acc: 0.7292 - val_loss: 2.3300 - val_acc: 0.5950
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 34s - loss: 1.8781 - acc: 0.7316 - val_loss: 2.3327 - val_acc: 0.5868
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 34s - loss: 1.8750 - acc: 0.7307 - val_loss: 2.2969 - val_acc: 0.6024
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 34s - loss: 1.8746 - acc: 0.7308 - val_loss: 2.3670 - val_acc: 0.5864
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc improved from 0.62840 to 0.64440, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 1.7911 - acc: 0.7596 - val_loss: 2.1369 - val_acc: 0.6444
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 34s - loss: 1.7719 - acc: 0.7697 - val_loss: 2.1686 - val_acc: 0.6354
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc improved from 0.64440 to 0.64760, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 1.7604 - acc: 0.7713 - val_loss: 2.1213 - val_acc: 0.6476
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 34s - loss: 1.7501 - acc: 0.7761 - val_loss: 2.1958 - val_acc: 0.6324
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 34s - loss: 1.7494 - acc: 0.7752 - val_loss: 2.1534 - val_acc: 0.6392
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 34s - loss: 1.7539 - acc: 0.7748 - val_loss: 2.1575 - val_acc: 0.6406
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 34s - loss: 1.7489 - acc: 0.7763 - val_loss: 2.1660 - val_acc: 0.6390
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 34s - loss: 1.7488 - acc: 0.7758 - val_loss: 2.2683 - val_acc: 0.6080
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 34s - loss: 1.7516 - acc: 0.7751 - val_loss: 2.3607 - val_acc: 0.5934
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 34s - loss: 1.7492 - acc: 0.7763 - val_loss: 2.2002 - val_acc: 0.6334
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 34s - loss: 1.7475 - acc: 0.7755 - val_loss: 2.2724 - val_acc: 0.6052
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 34s - loss: 1.7445 - acc: 0.7778 - val_loss: 2.2246 - val_acc: 0.6232
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 34s - loss: 1.7470 - acc: 0.7753 - val_loss: 2.2073 - val_acc: 0.6286
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 34s - loss: 1.7432 - acc: 0.7782 - val_loss: 2.2506 - val_acc: 0.6198
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 34s - loss: 1.7398 - acc: 0.7776 - val_loss: 2.2029 - val_acc: 0.6318
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 34s - loss: 1.7375 - acc: 0.7768 - val_loss: 2.2187 - val_acc: 0.6298
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 34s - loss: 1.7375 - acc: 0.7760 - val_loss: 2.2123 - val_acc: 0.6408
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 34s - loss: 1.7385 - acc: 0.7770 - val_loss: 2.3873 - val_acc: 0.5826
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 34s - loss: 1.7430 - acc: 0.7763 - val_loss: 2.2195 - val_acc: 0.6308
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 34s - loss: 1.7438 - acc: 0.7762 - val_loss: 2.1610 - val_acc: 0.6368
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 34s - loss: 1.7388 - acc: 0.7784 - val_loss: 2.1927 - val_acc: 0.6366
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 34s - loss: 1.7375 - acc: 0.7772 - val_loss: 2.2385 - val_acc: 0.6212
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 34s - loss: 1.7366 - acc: 0.7765 - val_loss: 2.1704 - val_acc: 0.6398
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 34s - loss: 1.7374 - acc: 0.7781 - val_loss: 2.1980 - val_acc: 0.6252
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 34s - loss: 1.7439 - acc: 0.7749 - val_loss: 2.2091 - val_acc: 0.6308
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 34s - loss: 1.7350 - acc: 0.7780 - val_loss: 2.1701 - val_acc: 0.6360
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 34s - loss: 1.7355 - acc: 0.7783 - val_loss: 2.2528 - val_acc: 0.6140
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 34s - loss: 1.7411 - acc: 0.7747 - val_loss: 2.1809 - val_acc: 0.6420
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 34s - loss: 1.7320 - acc: 0.7792 - val_loss: 2.1758 - val_acc: 0.6376
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 34s - loss: 1.7367 - acc: 0.7782 - val_loss: 2.1884 - val_acc: 0.6322
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 34s - loss: 1.7299 - acc: 0.7791 - val_loss: 2.1990 - val_acc: 0.6336
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 34s - loss: 1.7277 - acc: 0.7793 - val_loss: 2.2325 - val_acc: 0.6150
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 34s - loss: 1.7282 - acc: 0.7804 - val_loss: 2.2220 - val_acc: 0.6228
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 34s - loss: 1.7302 - acc: 0.7786 - val_loss: 2.1822 - val_acc: 0.6314
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 34s - loss: 1.7358 - acc: 0.7769 - val_loss: 2.3951 - val_acc: 0.5852
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 34s - loss: 1.7276 - acc: 0.7790 - val_loss: 2.2271 - val_acc: 0.6188
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 34s - loss: 1.7344 - acc: 0.7792 - val_loss: 2.2443 - val_acc: 0.6120
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 34s - loss: 1.7298 - acc: 0.7776 - val_loss: 2.2463 - val_acc: 0.6126
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 34s - loss: 1.7376 - acc: 0.7778 - val_loss: 2.2523 - val_acc: 0.6152
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 34s - loss: 1.7266 - acc: 0.7796 - val_loss: 2.2020 - val_acc: 0.6338
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 34s - loss: 1.6964 - acc: 0.7926 - val_loss: 2.1403 - val_acc: 0.6440
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 34s - loss: 1.6749 - acc: 0.8000 - val_loss: 2.1697 - val_acc: 0.6430
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc improved from 0.64760 to 0.64780, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 1.6773 - acc: 0.7987 - val_loss: 2.1678 - val_acc: 0.6478
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 34s - loss: 1.6801 - acc: 0.7987 - val_loss: 2.1698 - val_acc: 0.6410
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 34s - loss: 1.6831 - acc: 0.7958 - val_loss: 2.1943 - val_acc: 0.6342
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc improved from 0.64780 to 0.65180, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_5.hdf5
 - 35s - loss: 1.6823 - acc: 0.7973 - val_loss: 2.1318 - val_acc: 0.6518
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 34s - loss: 1.6925 - acc: 0.7939 - val_loss: 2.1914 - val_acc: 0.6376
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 34s - loss: 1.6863 - acc: 0.7951 - val_loss: 2.2326 - val_acc: 0.6282
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 34s - loss: 1.6862 - acc: 0.7966 - val_loss: 2.1527 - val_acc: 0.6424
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 34s - loss: 1.6855 - acc: 0.7957 - val_loss: 2.1908 - val_acc: 0.6370
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 34s - loss: 1.6902 - acc: 0.7946 - val_loss: 2.1568 - val_acc: 0.6486
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 34s - loss: 1.6950 - acc: 0.7938 - val_loss: 2.1836 - val_acc: 0.6352
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 34s - loss: 1.6907 - acc: 0.7940 - val_loss: 2.1924 - val_acc: 0.6430
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 34s - loss: 1.6926 - acc: 0.7931 - val_loss: 2.2220 - val_acc: 0.6234
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 34s - loss: 1.6866 - acc: 0.7956 - val_loss: 2.1803 - val_acc: 0.6418
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 34s - loss: 1.6888 - acc: 0.7954 - val_loss: 2.1678 - val_acc: 0.6474
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 34s - loss: 1.6837 - acc: 0.7977 - val_loss: 2.2115 - val_acc: 0.6360
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 34s - loss: 1.6912 - acc: 0.7931 - val_loss: 2.2019 - val_acc: 0.6272
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 34s - loss: 1.6810 - acc: 0.7965 - val_loss: 2.1577 - val_acc: 0.6386
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 34s - loss: 1.6879 - acc: 0.7949 - val_loss: 2.2472 - val_acc: 0.6320
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 34s - loss: 1.6814 - acc: 0.7969 - val_loss: 2.1399 - val_acc: 0.6504
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 34s - loss: 1.6817 - acc: 0.7954 - val_loss: 2.2288 - val_acc: 0.6260
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 34s - loss: 1.6782 - acc: 0.8001 - val_loss: 2.2165 - val_acc: 0.6298
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 34s - loss: 1.6769 - acc: 0.7983 - val_loss: 2.1931 - val_acc: 0.6388
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 34s - loss: 1.6835 - acc: 0.7975 - val_loss: 2.2266 - val_acc: 0.6306
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 34s - loss: 1.6835 - acc: 0.7961 - val_loss: 2.1724 - val_acc: 0.6406
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 34s - loss: 1.6897 - acc: 0.7948 - val_loss: 2.2411 - val_acc: 0.6252
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 34s - loss: 1.6844 - acc: 0.7976 - val_loss: 2.2236 - val_acc: 0.6282
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 34s - loss: 1.6904 - acc: 0.7947 - val_loss: 2.1504 - val_acc: 0.6498
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 34s - loss: 1.6839 - acc: 0.7973 - val_loss: 2.1736 - val_acc: 0.6316
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 34s - loss: 1.6871 - acc: 0.7952 - val_loss: 2.2055 - val_acc: 0.6334
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 34s - loss: 1.6867 - acc: 0.7951 - val_loss: 2.1827 - val_acc: 0.6402
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 34s - loss: 1.6856 - acc: 0.7962 - val_loss: 2.2722 - val_acc: 0.6204
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 34s - loss: 1.6809 - acc: 0.7955 - val_loss: 2.1779 - val_acc: 0.6426
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 34s - loss: 1.6883 - acc: 0.7940 - val_loss: 2.1605 - val_acc: 0.6442
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 34s - loss: 1.6885 - acc: 0.7944 - val_loss: 2.1852 - val_acc: 0.6408
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 34s - loss: 1.6869 - acc: 0.7944 - val_loss: 2.2149 - val_acc: 0.6296
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 34s - loss: 1.6860 - acc: 0.7947 - val_loss: 2.2185 - val_acc: 0.6252
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 34s - loss: 1.6824 - acc: 0.7960 - val_loss: 2.2001 - val_acc: 0.6324
Done

