Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_1[0][0]              
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_3[0][0]              
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_5[0][0]              
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_7[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_8[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_7[0][0]              
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_9 (LeakyReLU)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_9[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_10[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_10 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 16)   2320        leaky_re_lu_10[0][0]             
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_9[0][0]              
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_11 (LeakyReLU)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 32)   4640        leaky_re_lu_11[0][0]             
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_12 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_12[0][0]             
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 32)   544         leaky_re_lu_11[0][0]             
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           conv2d_14[0][0]                  
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_13 (LeakyReLU)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_13[0][0]             
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         conv2d_15[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_14 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_14[0][0]             
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 32)   0           leaky_re_lu_13[0][0]             
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_15 (LeakyReLU)      (None, 16, 16, 32)   0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_15[0][0]             
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_16 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_16[0][0]             
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         conv2d_18[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 32)   0           leaky_re_lu_15[0][0]             
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_17 (LeakyReLU)      (None, 16, 16, 32)   0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_17[0][0]             
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         conv2d_19[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_18 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_18[0][0]             
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         conv2d_20[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 32)   0           leaky_re_lu_17[0][0]             
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_19 (LeakyReLU)      (None, 16, 16, 32)   0           add_9[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_19[0][0]             
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_21[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_20 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_20[0][0]             
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_22[0][0]                  
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           leaky_re_lu_19[0][0]             
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_21 (LeakyReLU)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 64)     18496       leaky_re_lu_21[0][0]             
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         conv2d_23[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_22 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_22[0][0]             
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 64)     2112        leaky_re_lu_21[0][0]             
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         conv2d_24[0][0]                  
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 64)     0           conv2d_25[0][0]                  
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_23 (LeakyReLU)      (None, 8, 8, 64)     0           add_11[0][0]                     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_23[0][0]             
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         conv2d_26[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_24 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_24[0][0]             
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         conv2d_27[0][0]                  
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_23[0][0]             
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_25 (LeakyReLU)      (None, 8, 8, 64)     0           add_12[0][0]                     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_25[0][0]             
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv2d_28[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_26 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_26[0][0]             
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_29[0][0]                  
__________________________________________________________________________________________________
add_13 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_25[0][0]             
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_27 (LeakyReLU)      (None, 8, 8, 64)     0           add_13[0][0]                     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_27[0][0]             
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         conv2d_30[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_28 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_28[0][0]             
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv2d_31[0][0]                  
__________________________________________________________________________________________________
add_14 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_27[0][0]             
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_29 (LeakyReLU)      (None, 8, 8, 64)     0           add_14[0][0]                     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_29[0][0]             
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         conv2d_32[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_30 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_30[0][0]             
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         conv2d_33[0][0]                  
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 8, 64)     0           leaky_re_lu_29[0][0]             
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_31 (LeakyReLU)      (None, 8, 8, 64)     0           add_15[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           leaky_re_lu_31[0][0]             
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 470,218
Trainable params: 467,946
Non-trainable params: 2,272
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.44740, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 32s - loss: 1.6372 - acc: 0.4911 - val_loss: 1.8939 - val_acc: 0.4474
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.44740 to 0.61920, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 25s - loss: 1.1876 - acc: 0.6419 - val_loss: 1.2731 - val_acc: 0.6192
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc did not improve
 - 24s - loss: 1.0327 - acc: 0.6960 - val_loss: 1.4309 - val_acc: 0.5920
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc did not improve
 - 24s - loss: 0.9316 - acc: 0.7329 - val_loss: 1.5303 - val_acc: 0.5830
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc improved from 0.61920 to 0.66780, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 25s - loss: 0.8531 - acc: 0.7624 - val_loss: 1.1425 - val_acc: 0.6678
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc improved from 0.66780 to 0.70100, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 25s - loss: 0.7839 - acc: 0.7882 - val_loss: 1.0520 - val_acc: 0.7010
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.70100 to 0.73000, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 25s - loss: 0.7310 - acc: 0.8079 - val_loss: 0.9582 - val_acc: 0.7300
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc did not improve
 - 24s - loss: 0.6794 - acc: 0.8225 - val_loss: 1.0897 - val_acc: 0.7138
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 25s - loss: 0.6506 - acc: 0.8339 - val_loss: 1.0207 - val_acc: 0.7282
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 25s - loss: 0.6096 - acc: 0.8491 - val_loss: 1.0906 - val_acc: 0.7170
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 25s - loss: 0.5778 - acc: 0.8592 - val_loss: 1.1988 - val_acc: 0.6992
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 25s - loss: 0.5511 - acc: 0.8703 - val_loss: 1.0819 - val_acc: 0.7250
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc improved from 0.73000 to 0.76400, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 26s - loss: 0.5229 - acc: 0.8791 - val_loss: 0.9192 - val_acc: 0.7640
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 25s - loss: 0.4999 - acc: 0.8892 - val_loss: 1.0238 - val_acc: 0.7458
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc did not improve
 - 25s - loss: 0.4794 - acc: 0.8961 - val_loss: 1.0651 - val_acc: 0.7532
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 25s - loss: 0.4589 - acc: 0.9045 - val_loss: 1.1625 - val_acc: 0.7308
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 25s - loss: 0.4426 - acc: 0.9124 - val_loss: 1.0205 - val_acc: 0.7634
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 24s - loss: 0.4181 - acc: 0.9202 - val_loss: 1.2327 - val_acc: 0.7384
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 25s - loss: 0.4122 - acc: 0.9222 - val_loss: 1.3273 - val_acc: 0.7076
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 25s - loss: 0.3992 - acc: 0.9284 - val_loss: 1.1823 - val_acc: 0.7426
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 25s - loss: 0.3948 - acc: 0.9302 - val_loss: 1.2276 - val_acc: 0.7548
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 25s - loss: 0.3757 - acc: 0.9384 - val_loss: 1.1911 - val_acc: 0.7592
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 24s - loss: 0.3727 - acc: 0.9397 - val_loss: 1.3005 - val_acc: 0.7412
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 25s - loss: 0.3658 - acc: 0.9431 - val_loss: 1.5594 - val_acc: 0.7014
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 25s - loss: 0.3566 - acc: 0.9449 - val_loss: 1.3081 - val_acc: 0.7564
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc improved from 0.76400 to 0.79300, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 26s - loss: 0.3499 - acc: 0.9484 - val_loss: 1.1359 - val_acc: 0.7930
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 25s - loss: 0.3588 - acc: 0.9462 - val_loss: 1.4131 - val_acc: 0.7362
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 24s - loss: 0.3390 - acc: 0.9536 - val_loss: 1.4317 - val_acc: 0.7464
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 25s - loss: 0.3409 - acc: 0.9536 - val_loss: 1.3673 - val_acc: 0.7390
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 25s - loss: 0.3380 - acc: 0.9547 - val_loss: 1.2500 - val_acc: 0.7682
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 25s - loss: 0.3438 - acc: 0.9536 - val_loss: 1.3539 - val_acc: 0.7402
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 25s - loss: 0.3365 - acc: 0.9560 - val_loss: 1.2992 - val_acc: 0.7594
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 25s - loss: 0.3250 - acc: 0.9607 - val_loss: 1.2820 - val_acc: 0.7676
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 25s - loss: 0.3285 - acc: 0.9590 - val_loss: 1.4883 - val_acc: 0.7378
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 25s - loss: 0.3286 - acc: 0.9580 - val_loss: 1.3008 - val_acc: 0.7608
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 25s - loss: 0.3321 - acc: 0.9574 - val_loss: 1.2721 - val_acc: 0.7660
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 24s - loss: 0.3262 - acc: 0.9602 - val_loss: 1.6588 - val_acc: 0.7054
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 25s - loss: 0.3242 - acc: 0.9606 - val_loss: 1.3548 - val_acc: 0.7552
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 25s - loss: 0.3197 - acc: 0.9627 - val_loss: 1.4226 - val_acc: 0.7360
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 25s - loss: 0.3287 - acc: 0.9596 - val_loss: 1.3342 - val_acc: 0.7670
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 25s - loss: 0.3072 - acc: 0.9673 - val_loss: 1.3977 - val_acc: 0.7596
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 25s - loss: 0.3235 - acc: 0.9617 - val_loss: 1.3559 - val_acc: 0.7672
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 25s - loss: 0.3140 - acc: 0.9650 - val_loss: 1.5745 - val_acc: 0.7374
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 25s - loss: 0.3131 - acc: 0.9646 - val_loss: 1.4991 - val_acc: 0.7304
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 25s - loss: 0.3244 - acc: 0.9624 - val_loss: 1.7194 - val_acc: 0.7292
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 25s - loss: 0.3218 - acc: 0.9628 - val_loss: 1.4738 - val_acc: 0.7382
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 25s - loss: 0.2925 - acc: 0.9729 - val_loss: 1.3346 - val_acc: 0.7712
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 25s - loss: 0.3136 - acc: 0.9651 - val_loss: 2.0722 - val_acc: 0.6978
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 25s - loss: 0.3225 - acc: 0.9621 - val_loss: 1.5660 - val_acc: 0.7384
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 25s - loss: 0.3093 - acc: 0.9668 - val_loss: 1.4765 - val_acc: 0.7426
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 25s - loss: 0.3083 - acc: 0.9674 - val_loss: 1.6342 - val_acc: 0.7358
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 25s - loss: 0.3098 - acc: 0.9672 - val_loss: 1.6729 - val_acc: 0.7276
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 25s - loss: 0.3005 - acc: 0.9696 - val_loss: 1.3950 - val_acc: 0.7560
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 25s - loss: 0.3062 - acc: 0.9680 - val_loss: 1.4415 - val_acc: 0.7520
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 25s - loss: 0.3111 - acc: 0.9666 - val_loss: 1.5378 - val_acc: 0.7368
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 25s - loss: 0.3106 - acc: 0.9660 - val_loss: 1.4399 - val_acc: 0.7532
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 25s - loss: 0.3009 - acc: 0.9694 - val_loss: 1.8573 - val_acc: 0.7162
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 25s - loss: 0.3078 - acc: 0.9686 - val_loss: 1.2438 - val_acc: 0.7804
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 25s - loss: 0.2965 - acc: 0.9713 - val_loss: 1.3014 - val_acc: 0.7664
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 25s - loss: 0.3072 - acc: 0.9671 - val_loss: 1.4121 - val_acc: 0.7688
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 25s - loss: 0.3009 - acc: 0.9696 - val_loss: 1.3797 - val_acc: 0.7644
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 25s - loss: 0.3023 - acc: 0.9689 - val_loss: 1.2960 - val_acc: 0.7712
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 24s - loss: 0.2980 - acc: 0.9704 - val_loss: 1.3221 - val_acc: 0.7708
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 25s - loss: 0.2976 - acc: 0.9702 - val_loss: 1.7383 - val_acc: 0.7364
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 25s - loss: 0.3028 - acc: 0.9692 - val_loss: 1.3201 - val_acc: 0.7656
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 25s - loss: 0.2877 - acc: 0.9735 - val_loss: 1.8245 - val_acc: 0.7262
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 24s - loss: 0.2990 - acc: 0.9694 - val_loss: 1.2093 - val_acc: 0.7886
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 25s - loss: 0.2963 - acc: 0.9706 - val_loss: 1.5646 - val_acc: 0.7572
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 25s - loss: 0.2916 - acc: 0.9722 - val_loss: 1.4474 - val_acc: 0.7638
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 25s - loss: 0.2871 - acc: 0.9723 - val_loss: 1.3530 - val_acc: 0.7650
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 25s - loss: 0.2995 - acc: 0.9684 - val_loss: 1.5508 - val_acc: 0.7534
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 25s - loss: 0.2930 - acc: 0.9715 - val_loss: 1.7798 - val_acc: 0.7316
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 25s - loss: 0.2894 - acc: 0.9710 - val_loss: 1.3955 - val_acc: 0.7628
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 25s - loss: 0.2978 - acc: 0.9690 - val_loss: 1.3464 - val_acc: 0.7700
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 25s - loss: 0.2825 - acc: 0.9740 - val_loss: 1.3490 - val_acc: 0.7708
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 25s - loss: 0.2914 - acc: 0.9710 - val_loss: 1.4867 - val_acc: 0.7654
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 25s - loss: 0.2948 - acc: 0.9710 - val_loss: 1.3863 - val_acc: 0.7522
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 24s - loss: 0.2877 - acc: 0.9733 - val_loss: 1.2579 - val_acc: 0.7734
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 25s - loss: 0.2834 - acc: 0.9739 - val_loss: 1.5429 - val_acc: 0.7546
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 25s - loss: 0.2942 - acc: 0.9695 - val_loss: 1.3987 - val_acc: 0.7544
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 25s - loss: 0.2785 - acc: 0.9749 - val_loss: 1.2551 - val_acc: 0.7836
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.79300 to 0.81800, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 26s - loss: 0.2308 - acc: 0.9931 - val_loss: 1.0904 - val_acc: 0.8180
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc did not improve
 - 25s - loss: 0.2133 - acc: 0.9991 - val_loss: 1.1064 - val_acc: 0.8162
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc did not improve
 - 25s - loss: 0.2087 - acc: 0.9998 - val_loss: 1.1198 - val_acc: 0.8168
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc improved from 0.81800 to 0.81820, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 26s - loss: 0.2060 - acc: 0.9998 - val_loss: 1.1229 - val_acc: 0.8182
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 25s - loss: 0.2029 - acc: 1.0000 - val_loss: 1.1365 - val_acc: 0.8170
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 25s - loss: 0.1997 - acc: 1.0000 - val_loss: 1.1461 - val_acc: 0.8166
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc improved from 0.81820 to 0.81960, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 26s - loss: 0.1965 - acc: 1.0000 - val_loss: 1.1544 - val_acc: 0.8196
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 25s - loss: 0.1931 - acc: 0.9999 - val_loss: 1.1598 - val_acc: 0.8184
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc improved from 0.81960 to 0.82020, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 25s - loss: 0.1887 - acc: 1.0000 - val_loss: 1.1617 - val_acc: 0.8202
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 25s - loss: 0.1841 - acc: 1.0000 - val_loss: 1.1687 - val_acc: 0.8194
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc improved from 0.82020 to 0.82080, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 26s - loss: 0.1790 - acc: 1.0000 - val_loss: 1.1726 - val_acc: 0.8208
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc improved from 0.82080 to 0.82220, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 26s - loss: 0.1732 - acc: 1.0000 - val_loss: 1.1680 - val_acc: 0.8222
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 25s - loss: 0.1669 - acc: 1.0000 - val_loss: 1.1823 - val_acc: 0.8182
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 25s - loss: 0.1601 - acc: 1.0000 - val_loss: 1.1806 - val_acc: 0.8204
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 25s - loss: 0.1527 - acc: 1.0000 - val_loss: 1.1726 - val_acc: 0.8210
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 25s - loss: 0.1455 - acc: 1.0000 - val_loss: 1.2403 - val_acc: 0.8138
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 25s - loss: 0.1445 - acc: 0.9982 - val_loss: 1.2594 - val_acc: 0.8062
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 25s - loss: 0.1386 - acc: 0.9994 - val_loss: 1.2367 - val_acc: 0.8126
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 25s - loss: 0.1347 - acc: 0.9998 - val_loss: 1.2302 - val_acc: 0.8130
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 25s - loss: 0.1316 - acc: 1.0000 - val_loss: 1.2191 - val_acc: 0.8214
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 25s - loss: 0.1282 - acc: 1.0000 - val_loss: 1.2058 - val_acc: 0.8210
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 25s - loss: 0.1251 - acc: 0.9999 - val_loss: 1.2640 - val_acc: 0.8174
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 25s - loss: 0.1213 - acc: 1.0000 - val_loss: 1.2272 - val_acc: 0.8114
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 25s - loss: 0.1175 - acc: 1.0000 - val_loss: 1.2875 - val_acc: 0.8086
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 25s - loss: 0.1200 - acc: 0.9982 - val_loss: 1.3795 - val_acc: 0.8036
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 25s - loss: 0.1159 - acc: 0.9991 - val_loss: 1.2745 - val_acc: 0.8128
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 25s - loss: 0.1118 - acc: 0.9999 - val_loss: 1.2597 - val_acc: 0.8166
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 25s - loss: 0.1096 - acc: 1.0000 - val_loss: 1.2724 - val_acc: 0.8168
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 24s - loss: 0.1075 - acc: 1.0000 - val_loss: 1.2379 - val_acc: 0.8156
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 25s - loss: 0.1052 - acc: 1.0000 - val_loss: 1.2390 - val_acc: 0.8178
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 25s - loss: 0.1038 - acc: 0.9997 - val_loss: 1.3385 - val_acc: 0.8072
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 25s - loss: 0.1061 - acc: 0.9984 - val_loss: 1.2911 - val_acc: 0.8116
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 24s - loss: 0.1017 - acc: 0.9996 - val_loss: 1.2817 - val_acc: 0.8144
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 25s - loss: 0.0994 - acc: 0.9999 - val_loss: 1.2671 - val_acc: 0.8126
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 24s - loss: 0.0974 - acc: 1.0000 - val_loss: 1.2673 - val_acc: 0.8214
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 25s - loss: 0.0970 - acc: 0.9996 - val_loss: 1.3583 - val_acc: 0.8068
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 25s - loss: 0.0978 - acc: 0.9990 - val_loss: 1.3600 - val_acc: 0.8060
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 25s - loss: 0.0974 - acc: 0.9987 - val_loss: 1.3009 - val_acc: 0.8130
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 25s - loss: 0.0937 - acc: 0.9997 - val_loss: 1.3163 - val_acc: 0.8174
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 25s - loss: 0.0919 - acc: 0.9999 - val_loss: 1.2864 - val_acc: 0.8196
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc did not improve
 - 25s - loss: 0.0909 - acc: 1.0000 - val_loss: 1.2949 - val_acc: 0.8204
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 25s - loss: 0.0908 - acc: 1.0000 - val_loss: 1.2945 - val_acc: 0.8206
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 25s - loss: 0.0906 - acc: 1.0000 - val_loss: 1.2894 - val_acc: 0.8218
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 25s - loss: 0.0903 - acc: 1.0000 - val_loss: 1.2904 - val_acc: 0.8198
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 25s - loss: 0.0901 - acc: 1.0000 - val_loss: 1.2884 - val_acc: 0.8212
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 25s - loss: 0.0898 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.8196
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 25s - loss: 0.0894 - acc: 1.0000 - val_loss: 1.2860 - val_acc: 0.8210
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 25s - loss: 0.0891 - acc: 1.0000 - val_loss: 1.2867 - val_acc: 0.8216
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 25s - loss: 0.0887 - acc: 1.0000 - val_loss: 1.2854 - val_acc: 0.8206
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 25s - loss: 0.0882 - acc: 1.0000 - val_loss: 1.2875 - val_acc: 0.8200
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 25s - loss: 0.0876 - acc: 1.0000 - val_loss: 1.2838 - val_acc: 0.8190
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 25s - loss: 0.0871 - acc: 1.0000 - val_loss: 1.2842 - val_acc: 0.8208
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 25s - loss: 0.0864 - acc: 1.0000 - val_loss: 1.2870 - val_acc: 0.8190
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 25s - loss: 0.0857 - acc: 1.0000 - val_loss: 1.2859 - val_acc: 0.8186
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc improved from 0.82220 to 0.82240, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_5.hdf5
 - 26s - loss: 0.0849 - acc: 1.0000 - val_loss: 1.2889 - val_acc: 0.8224
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 25s - loss: 0.0841 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.8216
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 25s - loss: 0.0832 - acc: 1.0000 - val_loss: 1.2858 - val_acc: 0.8204
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 25s - loss: 0.0822 - acc: 1.0000 - val_loss: 1.2827 - val_acc: 0.8204
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 25s - loss: 0.0812 - acc: 1.0000 - val_loss: 1.2777 - val_acc: 0.8202
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 25s - loss: 0.0802 - acc: 1.0000 - val_loss: 1.2799 - val_acc: 0.8202
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 25s - loss: 0.0791 - acc: 1.0000 - val_loss: 1.2756 - val_acc: 0.8204
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 25s - loss: 0.0780 - acc: 1.0000 - val_loss: 1.2828 - val_acc: 0.8182
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 25s - loss: 0.0771 - acc: 1.0000 - val_loss: 1.2814 - val_acc: 0.8190
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 25s - loss: 0.0761 - acc: 1.0000 - val_loss: 1.2770 - val_acc: 0.8208
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 25s - loss: 0.0750 - acc: 1.0000 - val_loss: 1.2781 - val_acc: 0.8206
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 25s - loss: 0.0740 - acc: 1.0000 - val_loss: 1.2771 - val_acc: 0.8196
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 25s - loss: 0.0729 - acc: 1.0000 - val_loss: 1.2795 - val_acc: 0.8196
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 25s - loss: 0.0718 - acc: 1.0000 - val_loss: 1.2777 - val_acc: 0.8180
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 25s - loss: 0.0706 - acc: 1.0000 - val_loss: 1.2821 - val_acc: 0.8174
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 25s - loss: 0.0695 - acc: 1.0000 - val_loss: 1.2915 - val_acc: 0.8168
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 25s - loss: 0.0684 - acc: 1.0000 - val_loss: 1.2935 - val_acc: 0.8194
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 25s - loss: 0.0674 - acc: 1.0000 - val_loss: 1.2880 - val_acc: 0.8202
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 25s - loss: 0.0664 - acc: 1.0000 - val_loss: 1.2931 - val_acc: 0.8198
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 25s - loss: 0.0654 - acc: 1.0000 - val_loss: 1.2873 - val_acc: 0.8190
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 25s - loss: 0.0644 - acc: 1.0000 - val_loss: 1.2837 - val_acc: 0.8204
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 25s - loss: 0.0634 - acc: 1.0000 - val_loss: 1.2842 - val_acc: 0.8210
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 24s - loss: 0.0625 - acc: 1.0000 - val_loss: 1.3097 - val_acc: 0.8166
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 25s - loss: 0.0617 - acc: 1.0000 - val_loss: 1.3005 - val_acc: 0.8180
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 25s - loss: 0.0610 - acc: 1.0000 - val_loss: 1.2898 - val_acc: 0.8186
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 25s - loss: 0.0603 - acc: 1.0000 - val_loss: 1.2946 - val_acc: 0.8180
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 25s - loss: 0.0599 - acc: 1.0000 - val_loss: 1.3074 - val_acc: 0.8186
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 25s - loss: 0.0598 - acc: 1.0000 - val_loss: 1.3061 - val_acc: 0.8182
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 25s - loss: 0.0597 - acc: 1.0000 - val_loss: 1.3071 - val_acc: 0.8190
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 25s - loss: 0.0596 - acc: 1.0000 - val_loss: 1.3063 - val_acc: 0.8182
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 25s - loss: 0.0596 - acc: 1.0000 - val_loss: 1.3056 - val_acc: 0.8188
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 25s - loss: 0.0595 - acc: 1.0000 - val_loss: 1.3053 - val_acc: 0.8196
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 25s - loss: 0.0594 - acc: 1.0000 - val_loss: 1.3046 - val_acc: 0.8186
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 25s - loss: 0.0593 - acc: 1.0000 - val_loss: 1.3067 - val_acc: 0.8192
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 25s - loss: 0.0592 - acc: 1.0000 - val_loss: 1.3070 - val_acc: 0.8184
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 25s - loss: 0.0592 - acc: 1.0000 - val_loss: 1.3038 - val_acc: 0.8186
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 25s - loss: 0.0591 - acc: 1.0000 - val_loss: 1.3046 - val_acc: 0.8182
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 25s - loss: 0.0590 - acc: 1.0000 - val_loss: 1.3040 - val_acc: 0.8198
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 25s - loss: 0.0589 - acc: 1.0000 - val_loss: 1.3058 - val_acc: 0.8182
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 25s - loss: 0.0588 - acc: 1.0000 - val_loss: 1.3042 - val_acc: 0.8190
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 25s - loss: 0.0587 - acc: 1.0000 - val_loss: 1.3049 - val_acc: 0.8180
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 25s - loss: 0.0586 - acc: 1.0000 - val_loss: 1.3041 - val_acc: 0.8182
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 25s - loss: 0.0585 - acc: 1.0000 - val_loss: 1.3030 - val_acc: 0.8188
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 25s - loss: 0.0584 - acc: 1.0000 - val_loss: 1.3019 - val_acc: 0.8198
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 25s - loss: 0.0583 - acc: 1.0000 - val_loss: 1.3034 - val_acc: 0.8196
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 25s - loss: 0.0581 - acc: 1.0000 - val_loss: 1.3046 - val_acc: 0.8190
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 25s - loss: 0.0581 - acc: 1.0000 - val_loss: 1.3042 - val_acc: 0.8190
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 25s - loss: 0.0580 - acc: 1.0000 - val_loss: 1.3065 - val_acc: 0.8182
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 25s - loss: 0.0579 - acc: 1.0000 - val_loss: 1.3056 - val_acc: 0.8180
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 25s - loss: 0.0579 - acc: 1.0000 - val_loss: 1.3070 - val_acc: 0.8178
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 25s - loss: 0.0578 - acc: 1.0000 - val_loss: 1.3058 - val_acc: 0.8184
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 25s - loss: 0.0578 - acc: 1.0000 - val_loss: 1.3056 - val_acc: 0.8182
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 25s - loss: 0.0577 - acc: 1.0000 - val_loss: 1.3062 - val_acc: 0.8194
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 25s - loss: 0.0577 - acc: 1.0000 - val_loss: 1.3058 - val_acc: 0.8192
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 25s - loss: 0.0576 - acc: 1.0000 - val_loss: 1.3070 - val_acc: 0.8186
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 25s - loss: 0.0575 - acc: 1.0000 - val_loss: 1.3064 - val_acc: 0.8192
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 25s - loss: 0.0575 - acc: 1.0000 - val_loss: 1.3060 - val_acc: 0.8182
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 25s - loss: 0.0574 - acc: 1.0000 - val_loss: 1.3059 - val_acc: 0.8182
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 25s - loss: 0.0574 - acc: 1.0000 - val_loss: 1.3049 - val_acc: 0.8188
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 25s - loss: 0.0573 - acc: 1.0000 - val_loss: 1.3041 - val_acc: 0.8188
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 25s - loss: 0.0572 - acc: 1.0000 - val_loss: 1.3049 - val_acc: 0.8190
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 25s - loss: 0.0572 - acc: 1.0000 - val_loss: 1.3061 - val_acc: 0.8184
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 25s - loss: 0.0571 - acc: 1.0000 - val_loss: 1.3054 - val_acc: 0.8188
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 25s - loss: 0.0571 - acc: 1.0000 - val_loss: 1.3058 - val_acc: 0.8186
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 25s - loss: 0.0570 - acc: 1.0000 - val_loss: 1.3048 - val_acc: 0.8184
Done

