Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
ternary_conv2d_1 (TernaryConv2D (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_2 (TernaryConv2D (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_2[0][0]           
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_3 (TernaryConv2D (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_3[0][0]           
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_4 (TernaryConv2D (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_4[0][0]           
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_5 (TernaryConv2D (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_5[0][0]           
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_6 (TernaryConv2D (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_6[0][0]           
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_7 (TernaryConv2D (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_7[0][0]           
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_8 (TernaryConv2D (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_8[0][0]           
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_9 (TernaryConv2D (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_9[0][0]           
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_10 (TernaryConv2 (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_10[0][0]          
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_11 (TernaryConv2 (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_11[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_12 (TernaryConv2 (None, 16, 16, 32)   4640        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_12[0][0]          
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_13 (TernaryConv2 (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_14 (TernaryConv2 (None, 16, 16, 32)   544         activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_13[0][0]          
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           ternary_conv2d_14[0][0]          
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_15 (TernaryConv2 (None, 16, 16, 32)   9248        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_15[0][0]          
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_16 (TernaryConv2 (None, 16, 16, 32)   9248        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_16[0][0]          
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 32)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_17 (TernaryConv2 (None, 16, 16, 32)   9248        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_17[0][0]          
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_18 (TernaryConv2 (None, 16, 16, 32)   9248        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_18[0][0]          
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 32)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_19 (TernaryConv2 (None, 16, 16, 32)   9248        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_19[0][0]          
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_20 (TernaryConv2 (None, 16, 16, 32)   9248        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_20[0][0]          
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 32)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_21 (TernaryConv2 (None, 16, 16, 32)   9248        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_21[0][0]          
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_22 (TernaryConv2 (None, 16, 16, 32)   9248        activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_22[0][0]          
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           activation_19[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_23 (TernaryConv2 (None, 8, 8, 64)     18496       activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_23[0][0]          
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_24 (TernaryConv2 (None, 8, 8, 64)     36928       activation_22[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_25 (TernaryConv2 (None, 8, 8, 64)     2112        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_24[0][0]          
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 64)     0           ternary_conv2d_25[0][0]          
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_26 (TernaryConv2 (None, 8, 8, 64)     36928       activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_26[0][0]          
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_27 (TernaryConv2 (None, 8, 8, 64)     36928       activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_27[0][0]          
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 64)     0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_28 (TernaryConv2 (None, 8, 8, 64)     36928       activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_28[0][0]          
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_29 (TernaryConv2 (None, 8, 8, 64)     36928       activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_29[0][0]          
__________________________________________________________________________________________________
add_13 (Add)                    (None, 8, 8, 64)     0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_30 (TernaryConv2 (None, 8, 8, 64)     36928       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_30[0][0]          
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_31 (TernaryConv2 (None, 8, 8, 64)     36928       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_31[0][0]          
__________________________________________________________________________________________________
add_14 (Add)                    (None, 8, 8, 64)     0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_32 (TernaryConv2 (None, 8, 8, 64)     36928       activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_32[0][0]          
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_33 (TernaryConv2 (None, 8, 8, 64)     36928       activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_33[0][0]          
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 8, 64)     0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_31[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
ternary_dense_1 (TernaryDense)  (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 470,218
Trainable params: 467,946
Non-trainable params: 2,272
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.20860, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 38s - loss: 15.8516 - acc: 0.1837 - val_loss: 14.0593 - val_acc: 0.2086
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.20860 to 0.25160, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 12.6191 - acc: 0.2284 - val_loss: 11.3033 - val_acc: 0.2516
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc improved from 0.25160 to 0.26820, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 10.2481 - acc: 0.2563 - val_loss: 9.3288 - val_acc: 0.2682
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc did not improve
 - 31s - loss: 8.5123 - acc: 0.2779 - val_loss: 8.0183 - val_acc: 0.2290
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc improved from 0.26820 to 0.28420, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 7.2435 - acc: 0.2862 - val_loss: 6.7338 - val_acc: 0.2842
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc did not improve
 - 31s - loss: 6.2731 - acc: 0.3087 - val_loss: 6.0374 - val_acc: 0.2690
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.28420 to 0.30720, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 5.5346 - acc: 0.3285 - val_loss: 5.2950 - val_acc: 0.3072
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc improved from 0.30720 to 0.33400, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 4.9657 - acc: 0.3443 - val_loss: 4.7586 - val_acc: 0.3340
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 31s - loss: 4.5099 - acc: 0.3580 - val_loss: 4.7655 - val_acc: 0.2522
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc improved from 0.33400 to 0.34940, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 4.1278 - acc: 0.3759 - val_loss: 4.0560 - val_acc: 0.3494
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc improved from 0.34940 to 0.37220, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 3.8081 - acc: 0.3907 - val_loss: 3.7126 - val_acc: 0.3722
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc improved from 0.37220 to 0.38360, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 3.5350 - acc: 0.4027 - val_loss: 3.4686 - val_acc: 0.3836
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc improved from 0.38360 to 0.38880, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 3.2854 - acc: 0.4140 - val_loss: 3.2488 - val_acc: 0.3888
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc improved from 0.38880 to 0.39300, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 3.0678 - acc: 0.4248 - val_loss: 3.0678 - val_acc: 0.3930
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc improved from 0.39300 to 0.40420, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 2.8709 - acc: 0.4330 - val_loss: 2.8345 - val_acc: 0.4042
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc improved from 0.40420 to 0.40660, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 2.7028 - acc: 0.4374 - val_loss: 2.6906 - val_acc: 0.4066
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 31s - loss: 2.5455 - acc: 0.4434 - val_loss: 2.6570 - val_acc: 0.3646
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 31s - loss: 2.4254 - acc: 0.4380 - val_loss: 2.5127 - val_acc: 0.3734
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc improved from 0.40660 to 0.44560, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 2.3115 - acc: 0.4431 - val_loss: 2.2504 - val_acc: 0.4456
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 31s - loss: 2.2025 - acc: 0.4491 - val_loss: 2.3101 - val_acc: 0.4020
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 31s - loss: 2.1080 - acc: 0.4557 - val_loss: 2.4015 - val_acc: 0.3550
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 31s - loss: 2.0374 - acc: 0.4538 - val_loss: 2.2395 - val_acc: 0.3694
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 31s - loss: 1.9740 - acc: 0.4546 - val_loss: 2.1283 - val_acc: 0.3982
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 31s - loss: 1.9099 - acc: 0.4568 - val_loss: 2.1799 - val_acc: 0.3768
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 31s - loss: 1.8561 - acc: 0.4623 - val_loss: 2.0692 - val_acc: 0.3816
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 31s - loss: 1.8028 - acc: 0.4671 - val_loss: 2.1666 - val_acc: 0.3540
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 31s - loss: 1.7744 - acc: 0.4634 - val_loss: 3.0032 - val_acc: 0.2332
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 31s - loss: 1.7352 - acc: 0.4668 - val_loss: 2.0818 - val_acc: 0.3612
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 31s - loss: 1.6958 - acc: 0.4701 - val_loss: 1.9630 - val_acc: 0.3734
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 31s - loss: 1.6621 - acc: 0.4744 - val_loss: 2.0618 - val_acc: 0.3648
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 31s - loss: 1.6343 - acc: 0.4776 - val_loss: 1.9546 - val_acc: 0.3594
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 31s - loss: 1.6122 - acc: 0.4766 - val_loss: 3.2151 - val_acc: 0.2068
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 31s - loss: 1.5735 - acc: 0.4864 - val_loss: 2.4126 - val_acc: 0.3096
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 31s - loss: 1.5465 - acc: 0.4922 - val_loss: 3.2246 - val_acc: 0.2402
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 31s - loss: 1.5275 - acc: 0.4918 - val_loss: 2.8473 - val_acc: 0.2152
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 31s - loss: 1.5017 - acc: 0.4960 - val_loss: 1.8081 - val_acc: 0.4124
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 31s - loss: 1.4766 - acc: 0.5013 - val_loss: 3.0687 - val_acc: 0.2344
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 31s - loss: 1.4481 - acc: 0.5081 - val_loss: 3.9777 - val_acc: 0.1326
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 31s - loss: 1.4239 - acc: 0.5153 - val_loss: 2.6675 - val_acc: 0.2544
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 31s - loss: 1.3977 - acc: 0.5230 - val_loss: 1.7235 - val_acc: 0.4092
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 31s - loss: 1.3688 - acc: 0.5335 - val_loss: 2.7020 - val_acc: 0.2474
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 31s - loss: 1.3525 - acc: 0.5370 - val_loss: 2.4832 - val_acc: 0.2970
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 31s - loss: 1.3140 - acc: 0.5518 - val_loss: 3.7224 - val_acc: 0.1842
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 31s - loss: 1.3015 - acc: 0.5529 - val_loss: 2.0999 - val_acc: 0.3340
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 31s - loss: 1.2854 - acc: 0.5577 - val_loss: 2.2891 - val_acc: 0.3094
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 31s - loss: 1.2691 - acc: 0.5619 - val_loss: 2.3692 - val_acc: 0.2618
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 31s - loss: 1.2517 - acc: 0.5676 - val_loss: 2.4111 - val_acc: 0.2896
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 31s - loss: 1.2339 - acc: 0.5738 - val_loss: 2.0934 - val_acc: 0.3374
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 31s - loss: 1.2250 - acc: 0.5740 - val_loss: 1.7213 - val_acc: 0.4412
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 31s - loss: 1.2039 - acc: 0.5837 - val_loss: 3.0889 - val_acc: 0.2098
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 31s - loss: 1.1983 - acc: 0.5810 - val_loss: 1.8668 - val_acc: 0.3512
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 31s - loss: 1.1827 - acc: 0.5910 - val_loss: 2.5893 - val_acc: 0.2484
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 31s - loss: 1.1752 - acc: 0.5916 - val_loss: 2.3379 - val_acc: 0.3124
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc improved from 0.44560 to 0.46580, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 1.1630 - acc: 0.5970 - val_loss: 1.5449 - val_acc: 0.4658
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 31s - loss: 1.1692 - acc: 0.5927 - val_loss: 1.8247 - val_acc: 0.3740
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 31s - loss: 1.1552 - acc: 0.5951 - val_loss: 1.6557 - val_acc: 0.4104
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 31s - loss: 1.1393 - acc: 0.6032 - val_loss: 3.2948 - val_acc: 0.2672
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 31s - loss: 1.1414 - acc: 0.5994 - val_loss: 2.9153 - val_acc: 0.2094
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 31s - loss: 1.1405 - acc: 0.5990 - val_loss: 1.6005 - val_acc: 0.4500
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 31s - loss: 1.1214 - acc: 0.6089 - val_loss: 2.9410 - val_acc: 0.2534
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 31s - loss: 1.1294 - acc: 0.6043 - val_loss: 3.3588 - val_acc: 0.2478
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 31s - loss: 1.1182 - acc: 0.6090 - val_loss: 2.6101 - val_acc: 0.3048
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 31s - loss: 1.1100 - acc: 0.6118 - val_loss: 3.1935 - val_acc: 0.2772
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 31s - loss: 1.1068 - acc: 0.6125 - val_loss: 2.1913 - val_acc: 0.3262
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc improved from 0.46580 to 0.52220, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 1.0970 - acc: 0.6150 - val_loss: 1.4577 - val_acc: 0.5222
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 31s - loss: 1.1029 - acc: 0.6145 - val_loss: 1.8750 - val_acc: 0.4256
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 31s - loss: 1.0901 - acc: 0.6167 - val_loss: 1.8527 - val_acc: 0.4310
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 31s - loss: 1.0805 - acc: 0.6226 - val_loss: 2.9233 - val_acc: 0.2198
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 31s - loss: 1.0935 - acc: 0.6174 - val_loss: 2.3924 - val_acc: 0.3212
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 31s - loss: 1.0894 - acc: 0.6180 - val_loss: 2.4135 - val_acc: 0.2958
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 31s - loss: 1.0805 - acc: 0.6218 - val_loss: 2.1732 - val_acc: 0.3306
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 31s - loss: 1.0767 - acc: 0.6226 - val_loss: 2.4966 - val_acc: 0.3000
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 31s - loss: 1.0730 - acc: 0.6226 - val_loss: 2.3108 - val_acc: 0.3218
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 31s - loss: 1.0638 - acc: 0.6247 - val_loss: 3.3054 - val_acc: 0.2574
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 31s - loss: 1.0708 - acc: 0.6246 - val_loss: 2.9896 - val_acc: 0.2512
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 31s - loss: 1.0663 - acc: 0.6256 - val_loss: 2.1322 - val_acc: 0.3416
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 31s - loss: 1.0737 - acc: 0.6228 - val_loss: 2.3555 - val_acc: 0.2684
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 31s - loss: 1.0645 - acc: 0.6268 - val_loss: 3.7365 - val_acc: 0.1280
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 31s - loss: 1.0522 - acc: 0.6309 - val_loss: 2.1002 - val_acc: 0.3534
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 31s - loss: 1.0438 - acc: 0.6334 - val_loss: 2.9592 - val_acc: 0.3294
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 31s - loss: 1.0463 - acc: 0.6312 - val_loss: 2.0385 - val_acc: 0.3446
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.52220 to 0.63820, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 0.8992 - acc: 0.6838 - val_loss: 1.0606 - val_acc: 0.6382
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.63820 to 0.63920, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 33s - loss: 0.8518 - acc: 0.7030 - val_loss: 1.0364 - val_acc: 0.6392
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc improved from 0.63920 to 0.64520, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 0.8298 - acc: 0.7112 - val_loss: 0.9691 - val_acc: 0.6452
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 31s - loss: 0.8135 - acc: 0.7164 - val_loss: 1.2826 - val_acc: 0.5542
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 31s - loss: 0.8080 - acc: 0.7170 - val_loss: 1.2716 - val_acc: 0.5704
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 31s - loss: 0.8000 - acc: 0.7222 - val_loss: 1.6603 - val_acc: 0.4750
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 31s - loss: 0.7901 - acc: 0.7233 - val_loss: 1.2502 - val_acc: 0.5736
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 31s - loss: 0.7862 - acc: 0.7271 - val_loss: 1.7795 - val_acc: 0.4480
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 31s - loss: 0.7850 - acc: 0.7259 - val_loss: 1.4611 - val_acc: 0.5062
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 31s - loss: 0.7741 - acc: 0.7307 - val_loss: 1.7170 - val_acc: 0.5012
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 31s - loss: 0.7694 - acc: 0.7312 - val_loss: 1.2174 - val_acc: 0.5774
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 31s - loss: 0.7610 - acc: 0.7355 - val_loss: 1.5279 - val_acc: 0.4772
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 31s - loss: 0.7537 - acc: 0.7386 - val_loss: 1.3718 - val_acc: 0.5296
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 31s - loss: 0.7623 - acc: 0.7348 - val_loss: 1.7058 - val_acc: 0.4616
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 31s - loss: 0.7529 - acc: 0.7373 - val_loss: 1.6935 - val_acc: 0.4404
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 31s - loss: 0.7485 - acc: 0.7372 - val_loss: 1.4988 - val_acc: 0.5188
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 31s - loss: 0.7440 - acc: 0.7414 - val_loss: 1.9342 - val_acc: 0.4326
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 31s - loss: 0.7398 - acc: 0.7436 - val_loss: 1.6642 - val_acc: 0.4348
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 31s - loss: 0.7433 - acc: 0.7403 - val_loss: 1.1349 - val_acc: 0.6052
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 31s - loss: 0.7360 - acc: 0.7428 - val_loss: 1.1917 - val_acc: 0.5950
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 31s - loss: 0.7291 - acc: 0.7458 - val_loss: 1.5142 - val_acc: 0.5070
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 31s - loss: 0.7316 - acc: 0.7437 - val_loss: 1.4678 - val_acc: 0.5302
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 31s - loss: 0.7307 - acc: 0.7467 - val_loss: 1.4560 - val_acc: 0.5108
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 31s - loss: 0.7288 - acc: 0.7464 - val_loss: 1.4434 - val_acc: 0.5222
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 31s - loss: 0.7236 - acc: 0.7469 - val_loss: 1.1619 - val_acc: 0.5974
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 31s - loss: 0.7288 - acc: 0.7451 - val_loss: 1.6448 - val_acc: 0.4476
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 31s - loss: 0.7247 - acc: 0.7481 - val_loss: 2.8554 - val_acc: 0.3896
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 31s - loss: 0.7295 - acc: 0.7450 - val_loss: 1.6032 - val_acc: 0.4666
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 31s - loss: 0.7185 - acc: 0.7505 - val_loss: 1.7533 - val_acc: 0.4958
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 31s - loss: 0.7172 - acc: 0.7494 - val_loss: 1.7825 - val_acc: 0.4552
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 31s - loss: 0.7221 - acc: 0.7484 - val_loss: 1.3364 - val_acc: 0.5672
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 31s - loss: 0.7132 - acc: 0.7513 - val_loss: 1.1189 - val_acc: 0.6054
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 31s - loss: 0.7160 - acc: 0.7483 - val_loss: 1.9513 - val_acc: 0.4366
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 31s - loss: 0.7127 - acc: 0.7495 - val_loss: 1.4537 - val_acc: 0.5148
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 31s - loss: 0.7170 - acc: 0.7496 - val_loss: 2.4566 - val_acc: 0.3706
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 31s - loss: 0.7122 - acc: 0.7523 - val_loss: 1.3247 - val_acc: 0.5656
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 31s - loss: 0.7075 - acc: 0.7536 - val_loss: 1.5675 - val_acc: 0.5212
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 31s - loss: 0.7010 - acc: 0.7567 - val_loss: 1.9239 - val_acc: 0.4478
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 31s - loss: 0.7020 - acc: 0.7539 - val_loss: 1.4341 - val_acc: 0.5100
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 31s - loss: 0.6996 - acc: 0.7540 - val_loss: 1.8122 - val_acc: 0.4486
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc did not improve
 - 31s - loss: 0.6388 - acc: 0.7780 - val_loss: 1.1290 - val_acc: 0.6258
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc improved from 0.64520 to 0.67800, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 0.6253 - acc: 0.7849 - val_loss: 0.9220 - val_acc: 0.6780
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 31s - loss: 0.6165 - acc: 0.7860 - val_loss: 1.0792 - val_acc: 0.6262
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 31s - loss: 0.6209 - acc: 0.7838 - val_loss: 1.0194 - val_acc: 0.6576
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc improved from 0.67800 to 0.67940, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 0.6094 - acc: 0.7899 - val_loss: 0.9330 - val_acc: 0.6794
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 31s - loss: 0.6098 - acc: 0.7859 - val_loss: 1.5301 - val_acc: 0.5582
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 31s - loss: 0.6109 - acc: 0.7875 - val_loss: 1.0654 - val_acc: 0.6550
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 31s - loss: 0.6095 - acc: 0.7898 - val_loss: 1.0012 - val_acc: 0.6600
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 31s - loss: 0.6061 - acc: 0.7909 - val_loss: 1.8130 - val_acc: 0.4920
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc improved from 0.67940 to 0.68320, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 0.6052 - acc: 0.7884 - val_loss: 0.9279 - val_acc: 0.6832
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 31s - loss: 0.6024 - acc: 0.7905 - val_loss: 1.3192 - val_acc: 0.5898
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc improved from 0.68320 to 0.70160, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 0.6008 - acc: 0.7907 - val_loss: 0.8844 - val_acc: 0.7016
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 31s - loss: 0.6011 - acc: 0.7904 - val_loss: 1.1210 - val_acc: 0.6170
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 31s - loss: 0.6015 - acc: 0.7904 - val_loss: 1.4232 - val_acc: 0.5554
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 31s - loss: 0.5995 - acc: 0.7923 - val_loss: 1.3583 - val_acc: 0.5918
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 31s - loss: 0.6009 - acc: 0.7902 - val_loss: 1.0843 - val_acc: 0.6310
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 31s - loss: 0.5988 - acc: 0.7906 - val_loss: 2.1212 - val_acc: 0.4730
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 31s - loss: 0.5981 - acc: 0.7913 - val_loss: 1.1454 - val_acc: 0.6080
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 31s - loss: 0.5996 - acc: 0.7916 - val_loss: 1.1801 - val_acc: 0.6200
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 31s - loss: 0.5968 - acc: 0.7910 - val_loss: 2.1583 - val_acc: 0.4462
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 31s - loss: 0.6005 - acc: 0.7903 - val_loss: 1.1080 - val_acc: 0.6246
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 31s - loss: 0.5986 - acc: 0.7920 - val_loss: 1.3195 - val_acc: 0.5740
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 31s - loss: 0.5994 - acc: 0.7898 - val_loss: 1.4671 - val_acc: 0.5516
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 31s - loss: 0.5953 - acc: 0.7928 - val_loss: 1.8712 - val_acc: 0.4190
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 31s - loss: 0.5920 - acc: 0.7935 - val_loss: 1.1076 - val_acc: 0.6258
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 31s - loss: 0.5909 - acc: 0.7944 - val_loss: 0.9448 - val_acc: 0.6820
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 31s - loss: 0.5971 - acc: 0.7917 - val_loss: 1.6198 - val_acc: 0.4714
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 31s - loss: 0.5952 - acc: 0.7913 - val_loss: 1.0694 - val_acc: 0.6416
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 31s - loss: 0.5933 - acc: 0.7934 - val_loss: 1.4741 - val_acc: 0.5466
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 31s - loss: 0.5897 - acc: 0.7943 - val_loss: 1.5290 - val_acc: 0.5302
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 31s - loss: 0.5895 - acc: 0.7951 - val_loss: 0.8838 - val_acc: 0.6974
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 31s - loss: 0.5907 - acc: 0.7953 - val_loss: 1.7399 - val_acc: 0.4852
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 31s - loss: 0.5957 - acc: 0.7917 - val_loss: 1.3482 - val_acc: 0.5762
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 31s - loss: 0.5904 - acc: 0.7952 - val_loss: 2.0517 - val_acc: 0.4218
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 31s - loss: 0.5903 - acc: 0.7942 - val_loss: 1.8743 - val_acc: 0.5472
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 31s - loss: 0.5815 - acc: 0.7971 - val_loss: 1.3643 - val_acc: 0.5644
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 31s - loss: 0.5919 - acc: 0.7944 - val_loss: 1.2940 - val_acc: 0.5828
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 31s - loss: 0.5896 - acc: 0.7942 - val_loss: 1.1631 - val_acc: 0.6002
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 31s - loss: 0.5901 - acc: 0.7947 - val_loss: 1.0548 - val_acc: 0.6412
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 31s - loss: 0.5836 - acc: 0.7971 - val_loss: 1.4113 - val_acc: 0.5954
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 31s - loss: 0.5638 - acc: 0.8040 - val_loss: 0.8698 - val_acc: 0.7010
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 31s - loss: 0.5560 - acc: 0.8077 - val_loss: 0.9842 - val_acc: 0.6778
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc improved from 0.70160 to 0.70340, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 0.5565 - acc: 0.8073 - val_loss: 0.8897 - val_acc: 0.7034
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 31s - loss: 0.5569 - acc: 0.8072 - val_loss: 1.0861 - val_acc: 0.6430
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 31s - loss: 0.5604 - acc: 0.8059 - val_loss: 1.0547 - val_acc: 0.6444
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 31s - loss: 0.5554 - acc: 0.8080 - val_loss: 1.1865 - val_acc: 0.6210
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 31s - loss: 0.5587 - acc: 0.8062 - val_loss: 1.1336 - val_acc: 0.6084
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 31s - loss: 0.5574 - acc: 0.8053 - val_loss: 1.2437 - val_acc: 0.5958
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 31s - loss: 0.5636 - acc: 0.8036 - val_loss: 1.1780 - val_acc: 0.6158
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 31s - loss: 0.5591 - acc: 0.8053 - val_loss: 0.9709 - val_acc: 0.6788
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 31s - loss: 0.5589 - acc: 0.8074 - val_loss: 1.3186 - val_acc: 0.6102
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 31s - loss: 0.5599 - acc: 0.8060 - val_loss: 1.1230 - val_acc: 0.6466
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 31s - loss: 0.5561 - acc: 0.8081 - val_loss: 1.6756 - val_acc: 0.5612
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 31s - loss: 0.5600 - acc: 0.8037 - val_loss: 0.9928 - val_acc: 0.6706
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 31s - loss: 0.5523 - acc: 0.8073 - val_loss: 1.0529 - val_acc: 0.6532
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 31s - loss: 0.5561 - acc: 0.8067 - val_loss: 1.0482 - val_acc: 0.6524
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 31s - loss: 0.5560 - acc: 0.8058 - val_loss: 2.3584 - val_acc: 0.3934
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 31s - loss: 0.5556 - acc: 0.8060 - val_loss: 1.2423 - val_acc: 0.6162
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 31s - loss: 0.5569 - acc: 0.8076 - val_loss: 1.1602 - val_acc: 0.6472
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 31s - loss: 0.5571 - acc: 0.8072 - val_loss: 1.5313 - val_acc: 0.5410
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc improved from 0.70340 to 0.70500, saving model to ./weights/RESNET_CIFAR-10_full-tnn_4b_4b_5.hdf5
 - 32s - loss: 0.5491 - acc: 0.8096 - val_loss: 0.8898 - val_acc: 0.7050
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 31s - loss: 0.5525 - acc: 0.8078 - val_loss: 1.2109 - val_acc: 0.6170
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 31s - loss: 0.5515 - acc: 0.8085 - val_loss: 1.1084 - val_acc: 0.6192
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 31s - loss: 0.5549 - acc: 0.8056 - val_loss: 1.1798 - val_acc: 0.6384
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 31s - loss: 0.5515 - acc: 0.8081 - val_loss: 1.3113 - val_acc: 0.5928
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 31s - loss: 0.5552 - acc: 0.8076 - val_loss: 1.0434 - val_acc: 0.6562
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 31s - loss: 0.5529 - acc: 0.8069 - val_loss: 0.9758 - val_acc: 0.6644
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 31s - loss: 0.5562 - acc: 0.8058 - val_loss: 1.1956 - val_acc: 0.6036
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 31s - loss: 0.5544 - acc: 0.8075 - val_loss: 1.5310 - val_acc: 0.5548
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 31s - loss: 0.5581 - acc: 0.8080 - val_loss: 1.1338 - val_acc: 0.6396
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 31s - loss: 0.5529 - acc: 0.8070 - val_loss: 0.9614 - val_acc: 0.6790
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 31s - loss: 0.5549 - acc: 0.8074 - val_loss: 1.3613 - val_acc: 0.5774
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 31s - loss: 0.5525 - acc: 0.8066 - val_loss: 1.3099 - val_acc: 0.5924
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 31s - loss: 0.5523 - acc: 0.8077 - val_loss: 0.9764 - val_acc: 0.6828
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 31s - loss: 0.5536 - acc: 0.8074 - val_loss: 2.6556 - val_acc: 0.3464
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 31s - loss: 0.5547 - acc: 0.8084 - val_loss: 1.8822 - val_acc: 0.4520
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 31s - loss: 0.5519 - acc: 0.8086 - val_loss: 1.2724 - val_acc: 0.6028
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 31s - loss: 0.5517 - acc: 0.8081 - val_loss: 1.3484 - val_acc: 0.5498
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 31s - loss: 0.5528 - acc: 0.8089 - val_loss: 1.1546 - val_acc: 0.6330
Done

