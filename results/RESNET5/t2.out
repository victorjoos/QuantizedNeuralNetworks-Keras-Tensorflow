Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
ternary_conv2d_1 (TernaryConv2D (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_2 (TernaryConv2D (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_2[0][0]           
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_3 (TernaryConv2D (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_3[0][0]           
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_4 (TernaryConv2D (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_4[0][0]           
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_5 (TernaryConv2D (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_5[0][0]           
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_6 (TernaryConv2D (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_6[0][0]           
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_7 (TernaryConv2D (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_7[0][0]           
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_8 (TernaryConv2D (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_8[0][0]           
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_9 (TernaryConv2D (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_9[0][0]           
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_10 (TernaryConv2 (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_10[0][0]          
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_11 (TernaryConv2 (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_11[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_12 (TernaryConv2 (None, 16, 16, 32)   4640        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_12[0][0]          
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_13 (TernaryConv2 (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_14 (TernaryConv2 (None, 16, 16, 32)   544         activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_13[0][0]          
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           ternary_conv2d_14[0][0]          
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_15 (TernaryConv2 (None, 16, 16, 32)   9248        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_15[0][0]          
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_16 (TernaryConv2 (None, 16, 16, 32)   9248        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_16[0][0]          
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 32)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_17 (TernaryConv2 (None, 16, 16, 32)   9248        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_17[0][0]          
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_18 (TernaryConv2 (None, 16, 16, 32)   9248        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_18[0][0]          
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 32)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_19 (TernaryConv2 (None, 16, 16, 32)   9248        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_19[0][0]          
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_20 (TernaryConv2 (None, 16, 16, 32)   9248        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_20[0][0]          
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 32)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_21 (TernaryConv2 (None, 16, 16, 32)   9248        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_21[0][0]          
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_22 (TernaryConv2 (None, 16, 16, 32)   9248        activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_22[0][0]          
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           activation_19[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_23 (TernaryConv2 (None, 8, 8, 64)     18496       activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_23[0][0]          
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_24 (TernaryConv2 (None, 8, 8, 64)     36928       activation_22[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_25 (TernaryConv2 (None, 8, 8, 64)     2112        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_24[0][0]          
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 64)     0           ternary_conv2d_25[0][0]          
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_26 (TernaryConv2 (None, 8, 8, 64)     36928       activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_26[0][0]          
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_27 (TernaryConv2 (None, 8, 8, 64)     36928       activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_27[0][0]          
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 64)     0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_28 (TernaryConv2 (None, 8, 8, 64)     36928       activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_28[0][0]          
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_29 (TernaryConv2 (None, 8, 8, 64)     36928       activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_29[0][0]          
__________________________________________________________________________________________________
add_13 (Add)                    (None, 8, 8, 64)     0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_30 (TernaryConv2 (None, 8, 8, 64)     36928       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_30[0][0]          
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_31 (TernaryConv2 (None, 8, 8, 64)     36928       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_31[0][0]          
__________________________________________________________________________________________________
add_14 (Add)                    (None, 8, 8, 64)     0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_32 (TernaryConv2 (None, 8, 8, 64)     36928       activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_32[0][0]          
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_33 (TernaryConv2 (None, 8, 8, 64)     36928       activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_33[0][0]          
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 8, 64)     0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_31[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
ternary_dense_1 (TernaryDense)  (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 470,218
Trainable params: 467,946
Non-trainable params: 2,272
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.10340, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 42s - loss: 17.4518 - acc: 0.1013 - val_loss: 16.8812 - val_acc: 0.1034
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc did not improve
 - 33s - loss: 16.4941 - acc: 0.0982 - val_loss: 16.1380 - val_acc: 0.1030
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc improved from 0.10340 to 0.10480, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 15.8319 - acc: 0.0974 - val_loss: 15.5490 - val_acc: 0.1048
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc did not improve
 - 34s - loss: 15.3144 - acc: 0.0988 - val_loss: 15.0974 - val_acc: 0.0946
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc did not improve
 - 34s - loss: 14.8994 - acc: 0.0991 - val_loss: 14.7365 - val_acc: 0.0962
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc did not improve
 - 34s - loss: 14.5560 - acc: 0.0995 - val_loss: 14.4166 - val_acc: 0.0960
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.10480 to 0.10780, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 14.2671 - acc: 0.0996 - val_loss: 14.1656 - val_acc: 0.1078
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc did not improve
 - 34s - loss: 14.0124 - acc: 0.1018 - val_loss: 13.9183 - val_acc: 0.0906
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 34s - loss: 13.7886 - acc: 0.1006 - val_loss: 13.7271 - val_acc: 0.1040
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 34s - loss: 13.5843 - acc: 0.1009 - val_loss: 13.5014 - val_acc: 0.0984
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 34s - loss: 13.3880 - acc: 0.0998 - val_loss: 13.3037 - val_acc: 0.1040
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 34s - loss: 13.1993 - acc: 0.1030 - val_loss: 13.1504 - val_acc: 0.0956
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc did not improve
 - 34s - loss: 13.0179 - acc: 0.1032 - val_loss: 12.9973 - val_acc: 0.0968
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc improved from 0.10780 to 0.12560, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 34s - loss: 12.8212 - acc: 0.1244 - val_loss: 12.8729 - val_acc: 0.1256
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc improved from 0.12560 to 0.19780, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 12.5521 - acc: 0.1938 - val_loss: 12.4852 - val_acc: 0.1978
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 34s - loss: 12.3517 - acc: 0.2192 - val_loss: 12.4026 - val_acc: 0.1338
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 34s - loss: 12.1855 - acc: 0.2296 - val_loss: 12.1910 - val_acc: 0.1946
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc improved from 0.19780 to 0.21460, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 12.0430 - acc: 0.2347 - val_loss: 12.0607 - val_acc: 0.2146
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc improved from 0.21460 to 0.22720, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 11.8786 - acc: 0.2458 - val_loss: 11.8581 - val_acc: 0.2272
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 33s - loss: 11.7324 - acc: 0.2545 - val_loss: 11.8171 - val_acc: 0.1978
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc improved from 0.22720 to 0.24480, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 11.5834 - acc: 0.2674 - val_loss: 11.5584 - val_acc: 0.2448
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 33s - loss: 11.4513 - acc: 0.2747 - val_loss: 11.4562 - val_acc: 0.2236
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 34s - loss: 11.3200 - acc: 0.2745 - val_loss: 11.3367 - val_acc: 0.2440
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 34s - loss: 11.2083 - acc: 0.2700 - val_loss: 11.3335 - val_acc: 0.2050
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 34s - loss: 11.1030 - acc: 0.2698 - val_loss: 11.2142 - val_acc: 0.2128
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 34s - loss: 10.9820 - acc: 0.2745 - val_loss: 11.2214 - val_acc: 0.2086
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc improved from 0.24480 to 0.26340, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 10.8704 - acc: 0.2818 - val_loss: 10.8962 - val_acc: 0.2634
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc improved from 0.26340 to 0.27400, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 10.7605 - acc: 0.2866 - val_loss: 10.7909 - val_acc: 0.2740
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 33s - loss: 10.6491 - acc: 0.2955 - val_loss: 10.7183 - val_acc: 0.2450
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 34s - loss: 10.5399 - acc: 0.3005 - val_loss: 10.6066 - val_acc: 0.2424
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc improved from 0.27400 to 0.29540, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 10.4444 - acc: 0.2970 - val_loss: 10.4231 - val_acc: 0.2954
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 33s - loss: 10.3312 - acc: 0.3085 - val_loss: 10.3775 - val_acc: 0.2804
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 34s - loss: 10.2335 - acc: 0.3134 - val_loss: 10.2403 - val_acc: 0.2944
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc improved from 0.29540 to 0.30040, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 10.1301 - acc: 0.3157 - val_loss: 10.1528 - val_acc: 0.3004
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 34s - loss: 10.0330 - acc: 0.3231 - val_loss: 10.0707 - val_acc: 0.2980
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 34s - loss: 9.9357 - acc: 0.3318 - val_loss: 10.2516 - val_acc: 0.2544
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 34s - loss: 9.8376 - acc: 0.3367 - val_loss: 10.1271 - val_acc: 0.2624
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc improved from 0.30040 to 0.31420, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 9.7426 - acc: 0.3463 - val_loss: 9.7583 - val_acc: 0.3142
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 34s - loss: 9.6546 - acc: 0.3485 - val_loss: 9.7022 - val_acc: 0.3072
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 34s - loss: 9.5629 - acc: 0.3568 - val_loss: 9.7902 - val_acc: 0.2990
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 33s - loss: 9.4785 - acc: 0.3627 - val_loss: 9.7564 - val_acc: 0.2646
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 34s - loss: 9.3987 - acc: 0.3655 - val_loss: 9.5329 - val_acc: 0.3140
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 34s - loss: 9.3051 - acc: 0.3750 - val_loss: 9.6325 - val_acc: 0.2920
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 34s - loss: 9.2188 - acc: 0.3836 - val_loss: 9.4168 - val_acc: 0.2980
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc improved from 0.31420 to 0.32700, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 9.1494 - acc: 0.3862 - val_loss: 9.2372 - val_acc: 0.3270
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 34s - loss: 9.0736 - acc: 0.3948 - val_loss: 9.5712 - val_acc: 0.2676
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc improved from 0.32700 to 0.37160, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 9.0102 - acc: 0.3948 - val_loss: 9.0292 - val_acc: 0.3716
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 34s - loss: 8.9294 - acc: 0.4061 - val_loss: 9.3875 - val_acc: 0.2638
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 33s - loss: 8.8575 - acc: 0.4131 - val_loss: 9.0715 - val_acc: 0.3368
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc improved from 0.37160 to 0.37220, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 8.7956 - acc: 0.4163 - val_loss: 8.9501 - val_acc: 0.3722
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 34s - loss: 8.7271 - acc: 0.4243 - val_loss: 8.9438 - val_acc: 0.3472
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc improved from 0.37220 to 0.38840, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 8.6731 - acc: 0.4303 - val_loss: 8.8104 - val_acc: 0.3884
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 34s - loss: 8.6117 - acc: 0.4340 - val_loss: 8.9096 - val_acc: 0.3242
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 33s - loss: 8.5567 - acc: 0.4357 - val_loss: 8.7373 - val_acc: 0.3594
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 34s - loss: 8.5010 - acc: 0.4452 - val_loss: 9.5229 - val_acc: 0.1870
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 34s - loss: 8.4580 - acc: 0.4463 - val_loss: 8.5895 - val_acc: 0.3750
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc improved from 0.38840 to 0.40100, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 8.3987 - acc: 0.4533 - val_loss: 8.5672 - val_acc: 0.4010
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 34s - loss: 8.3520 - acc: 0.4549 - val_loss: 8.7476 - val_acc: 0.3092
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc improved from 0.40100 to 0.41580, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 8.3001 - acc: 0.4646 - val_loss: 8.4151 - val_acc: 0.4158
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc improved from 0.41580 to 0.42260, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 8.2594 - acc: 0.4661 - val_loss: 8.3341 - val_acc: 0.4226
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 34s - loss: 8.2147 - acc: 0.4700 - val_loss: 8.3969 - val_acc: 0.3980
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 34s - loss: 8.1714 - acc: 0.4719 - val_loss: 8.3822 - val_acc: 0.3778
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 33s - loss: 8.1292 - acc: 0.4756 - val_loss: 8.4126 - val_acc: 0.3902
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 34s - loss: 8.0819 - acc: 0.4811 - val_loss: 8.2675 - val_acc: 0.4168
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc improved from 0.42260 to 0.42780, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 8.0465 - acc: 0.4841 - val_loss: 8.1776 - val_acc: 0.4278
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 34s - loss: 8.0045 - acc: 0.4900 - val_loss: 8.2737 - val_acc: 0.3944
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 33s - loss: 7.9762 - acc: 0.4909 - val_loss: 8.4557 - val_acc: 0.3330
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 34s - loss: 7.9361 - acc: 0.4950 - val_loss: 8.1913 - val_acc: 0.4110
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 33s - loss: 7.8932 - acc: 0.5003 - val_loss: 8.1050 - val_acc: 0.4230
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc improved from 0.42780 to 0.46680, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.8603 - acc: 0.5023 - val_loss: 7.9263 - val_acc: 0.4668
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 34s - loss: 7.8217 - acc: 0.5108 - val_loss: 8.1576 - val_acc: 0.3900
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc improved from 0.46680 to 0.47180, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.7920 - acc: 0.5086 - val_loss: 7.8943 - val_acc: 0.4718
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 34s - loss: 7.7529 - acc: 0.5155 - val_loss: 8.1402 - val_acc: 0.3952
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 34s - loss: 7.7178 - acc: 0.5190 - val_loss: 8.1455 - val_acc: 0.3792
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 34s - loss: 7.6963 - acc: 0.5199 - val_loss: 8.0399 - val_acc: 0.4298
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 34s - loss: 7.6540 - acc: 0.5243 - val_loss: 7.8030 - val_acc: 0.4702
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 34s - loss: 7.6342 - acc: 0.5248 - val_loss: 7.8350 - val_acc: 0.4526
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 34s - loss: 7.6014 - acc: 0.5260 - val_loss: 7.8639 - val_acc: 0.4554
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 34s - loss: 7.5756 - acc: 0.5273 - val_loss: 7.7240 - val_acc: 0.4678
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc improved from 0.47180 to 0.47240, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.5537 - acc: 0.5292 - val_loss: 7.6973 - val_acc: 0.4724
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 33s - loss: 7.5181 - acc: 0.5375 - val_loss: 8.1170 - val_acc: 0.3770
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.47240 to 0.52460, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.4365 - acc: 0.5638 - val_loss: 7.5538 - val_acc: 0.5246
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.52460 to 0.52860, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.4181 - acc: 0.5684 - val_loss: 7.5172 - val_acc: 0.5286
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc improved from 0.52860 to 0.53540, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.4126 - acc: 0.5706 - val_loss: 7.5042 - val_acc: 0.5354
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 34s - loss: 7.4030 - acc: 0.5710 - val_loss: 7.4957 - val_acc: 0.5278
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 34s - loss: 7.3950 - acc: 0.5737 - val_loss: 7.5112 - val_acc: 0.5276
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 34s - loss: 7.3906 - acc: 0.5742 - val_loss: 7.6485 - val_acc: 0.4984
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 34s - loss: 7.3815 - acc: 0.5761 - val_loss: 7.5589 - val_acc: 0.5180
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc improved from 0.53540 to 0.53760, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.3767 - acc: 0.5778 - val_loss: 7.4718 - val_acc: 0.5376
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 34s - loss: 7.3790 - acc: 0.5730 - val_loss: 7.4865 - val_acc: 0.5348
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 34s - loss: 7.3745 - acc: 0.5744 - val_loss: 7.5153 - val_acc: 0.5192
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 34s - loss: 7.3685 - acc: 0.5798 - val_loss: 7.6032 - val_acc: 0.5028
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc improved from 0.53760 to 0.54020, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.3650 - acc: 0.5774 - val_loss: 7.4981 - val_acc: 0.5402
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 34s - loss: 7.3519 - acc: 0.5819 - val_loss: 7.5039 - val_acc: 0.5232
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 34s - loss: 7.3546 - acc: 0.5805 - val_loss: 7.4801 - val_acc: 0.5214
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 34s - loss: 7.3522 - acc: 0.5806 - val_loss: 7.9633 - val_acc: 0.4104
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 34s - loss: 7.3423 - acc: 0.5808 - val_loss: 7.5068 - val_acc: 0.5198
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 34s - loss: 7.3426 - acc: 0.5809 - val_loss: 7.5700 - val_acc: 0.4974
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 34s - loss: 7.3330 - acc: 0.5847 - val_loss: 7.4943 - val_acc: 0.5226
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 34s - loss: 7.3323 - acc: 0.5848 - val_loss: 7.6141 - val_acc: 0.4838
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc improved from 0.54020 to 0.54700, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.3234 - acc: 0.5843 - val_loss: 7.4306 - val_acc: 0.5470
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 34s - loss: 7.3249 - acc: 0.5848 - val_loss: 7.5778 - val_acc: 0.4974
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 34s - loss: 7.3141 - acc: 0.5865 - val_loss: 7.4534 - val_acc: 0.5430
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 34s - loss: 7.3113 - acc: 0.5864 - val_loss: 7.4310 - val_acc: 0.5410
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 34s - loss: 7.3098 - acc: 0.5870 - val_loss: 7.5627 - val_acc: 0.5042
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc improved from 0.54700 to 0.56020, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.3034 - acc: 0.5878 - val_loss: 7.3831 - val_acc: 0.5602
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 34s - loss: 7.3016 - acc: 0.5868 - val_loss: 7.4140 - val_acc: 0.5518
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 34s - loss: 7.2934 - acc: 0.5932 - val_loss: 7.4695 - val_acc: 0.5268
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 34s - loss: 7.2977 - acc: 0.5884 - val_loss: 7.5175 - val_acc: 0.5094
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 34s - loss: 7.2827 - acc: 0.5920 - val_loss: 7.5253 - val_acc: 0.5012
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 34s - loss: 7.2890 - acc: 0.5885 - val_loss: 7.4603 - val_acc: 0.5240
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 34s - loss: 7.2844 - acc: 0.5886 - val_loss: 7.4617 - val_acc: 0.5208
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 34s - loss: 7.2734 - acc: 0.5929 - val_loss: 7.4192 - val_acc: 0.5432
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 34s - loss: 7.2765 - acc: 0.5920 - val_loss: 7.4852 - val_acc: 0.5150
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 34s - loss: 7.2713 - acc: 0.5904 - val_loss: 7.4064 - val_acc: 0.5444
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 34s - loss: 7.2690 - acc: 0.5928 - val_loss: 7.4064 - val_acc: 0.5386
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 33s - loss: 7.2678 - acc: 0.5926 - val_loss: 7.4754 - val_acc: 0.5204
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 34s - loss: 7.2642 - acc: 0.5918 - val_loss: 7.5109 - val_acc: 0.5100
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 34s - loss: 7.2592 - acc: 0.5947 - val_loss: 7.4384 - val_acc: 0.5284
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 34s - loss: 7.2521 - acc: 0.5939 - val_loss: 7.3760 - val_acc: 0.5414
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 34s - loss: 7.2461 - acc: 0.5950 - val_loss: 7.4927 - val_acc: 0.5186
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc did not improve
 - 34s - loss: 7.2217 - acc: 0.6036 - val_loss: 7.3745 - val_acc: 0.5544
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 34s - loss: 7.2202 - acc: 0.6042 - val_loss: 7.3927 - val_acc: 0.5382
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 34s - loss: 7.2153 - acc: 0.6098 - val_loss: 7.3651 - val_acc: 0.5458
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 34s - loss: 7.2152 - acc: 0.6066 - val_loss: 7.3979 - val_acc: 0.5492
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc improved from 0.56020 to 0.56520, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.2132 - acc: 0.6074 - val_loss: 7.3370 - val_acc: 0.5652
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 34s - loss: 7.2118 - acc: 0.6074 - val_loss: 7.5660 - val_acc: 0.4964
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc improved from 0.56520 to 0.56540, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.2113 - acc: 0.6085 - val_loss: 7.3447 - val_acc: 0.5654
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 34s - loss: 7.2149 - acc: 0.6078 - val_loss: 7.4131 - val_acc: 0.5480
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc improved from 0.56540 to 0.56940, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.2169 - acc: 0.6049 - val_loss: 7.3344 - val_acc: 0.5694
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 34s - loss: 7.2112 - acc: 0.6101 - val_loss: 7.3592 - val_acc: 0.5554
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 34s - loss: 7.2178 - acc: 0.6049 - val_loss: 7.3515 - val_acc: 0.5574
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 34s - loss: 7.2136 - acc: 0.6067 - val_loss: 7.4151 - val_acc: 0.5336
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 34s - loss: 7.2100 - acc: 0.6060 - val_loss: 7.3812 - val_acc: 0.5488
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 34s - loss: 7.2041 - acc: 0.6096 - val_loss: 7.4848 - val_acc: 0.5220
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc improved from 0.56940 to 0.57800, saving model to ./weights/RESNET_CIFAR-10_qtnn_2b_4b_5.hdf5
 - 35s - loss: 7.2114 - acc: 0.6056 - val_loss: 7.3003 - val_acc: 0.5780
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 34s - loss: 7.2099 - acc: 0.6078 - val_loss: 7.3584 - val_acc: 0.5564
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 34s - loss: 7.2095 - acc: 0.6061 - val_loss: 7.3687 - val_acc: 0.5542
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 34s - loss: 7.2116 - acc: 0.6055 - val_loss: 7.3728 - val_acc: 0.5570
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 34s - loss: 7.2126 - acc: 0.6073 - val_loss: 7.3141 - val_acc: 0.5636
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 34s - loss: 7.2106 - acc: 0.6074 - val_loss: 7.4537 - val_acc: 0.5220
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 34s - loss: 7.2064 - acc: 0.6093 - val_loss: 7.3137 - val_acc: 0.5736
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 34s - loss: 7.2084 - acc: 0.6071 - val_loss: 7.3452 - val_acc: 0.5630
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 34s - loss: 7.2056 - acc: 0.6092 - val_loss: 7.3712 - val_acc: 0.5598
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 34s - loss: 7.2047 - acc: 0.6103 - val_loss: 7.3348 - val_acc: 0.5674
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 33s - loss: 7.2050 - acc: 0.6078 - val_loss: 7.3415 - val_acc: 0.5548
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 34s - loss: 7.2033 - acc: 0.6098 - val_loss: 7.3864 - val_acc: 0.5480
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 34s - loss: 7.2046 - acc: 0.6093 - val_loss: 7.3720 - val_acc: 0.5420
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 34s - loss: 7.2034 - acc: 0.6100 - val_loss: 7.4249 - val_acc: 0.5298
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 34s - loss: 7.2028 - acc: 0.6090 - val_loss: 7.4491 - val_acc: 0.5274
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 34s - loss: 7.2035 - acc: 0.6070 - val_loss: 7.3533 - val_acc: 0.5584
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 34s - loss: 7.2076 - acc: 0.6058 - val_loss: 7.3207 - val_acc: 0.5674
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 34s - loss: 7.2056 - acc: 0.6068 - val_loss: 7.3711 - val_acc: 0.5526
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 34s - loss: 7.2027 - acc: 0.6096 - val_loss: 7.3260 - val_acc: 0.5666
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 34s - loss: 7.2069 - acc: 0.6061 - val_loss: 7.3396 - val_acc: 0.5606
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 34s - loss: 7.1980 - acc: 0.6094 - val_loss: 7.3884 - val_acc: 0.5432
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 34s - loss: 7.2028 - acc: 0.6099 - val_loss: 7.3500 - val_acc: 0.5552
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 34s - loss: 7.2007 - acc: 0.6086 - val_loss: 7.3626 - val_acc: 0.5574
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 34s - loss: 7.2017 - acc: 0.6085 - val_loss: 7.3073 - val_acc: 0.5748
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 33s - loss: 7.2079 - acc: 0.6062 - val_loss: 7.3255 - val_acc: 0.5624
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 34s - loss: 7.2008 - acc: 0.6098 - val_loss: 7.4069 - val_acc: 0.5386
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 34s - loss: 7.1937 - acc: 0.6115 - val_loss: 7.3084 - val_acc: 0.5664
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 34s - loss: 7.1848 - acc: 0.6148 - val_loss: 7.3174 - val_acc: 0.5718
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 34s - loss: 7.1871 - acc: 0.6170 - val_loss: 7.2993 - val_acc: 0.5714
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 34s - loss: 7.1918 - acc: 0.6121 - val_loss: 7.2969 - val_acc: 0.5738
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 34s - loss: 7.1857 - acc: 0.6155 - val_loss: 7.3032 - val_acc: 0.5774
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 34s - loss: 7.1915 - acc: 0.6113 - val_loss: 7.3012 - val_acc: 0.5748
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 33s - loss: 7.1896 - acc: 0.6123 - val_loss: 7.3681 - val_acc: 0.5492
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 34s - loss: 7.1897 - acc: 0.6150 - val_loss: 7.3230 - val_acc: 0.5668
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 33s - loss: 7.1919 - acc: 0.6105 - val_loss: 7.3158 - val_acc: 0.5656
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 34s - loss: 7.1907 - acc: 0.6138 - val_loss: 7.3062 - val_acc: 0.5750
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 34s - loss: 7.1904 - acc: 0.6119 - val_loss: 7.3392 - val_acc: 0.5622
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 34s - loss: 7.1953 - acc: 0.6119 - val_loss: 7.3439 - val_acc: 0.5550
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 34s - loss: 7.1915 - acc: 0.6132 - val_loss: 7.3234 - val_acc: 0.5634
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 34s - loss: 7.1912 - acc: 0.6125 - val_loss: 7.3858 - val_acc: 0.5444
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 34s - loss: 7.1904 - acc: 0.6106 - val_loss: 7.3226 - val_acc: 0.5618
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 34s - loss: 7.1891 - acc: 0.6133 - val_loss: 7.3786 - val_acc: 0.5578
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 34s - loss: 7.1951 - acc: 0.6115 - val_loss: 7.3678 - val_acc: 0.5464
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 34s - loss: 7.1867 - acc: 0.6158 - val_loss: 7.4105 - val_acc: 0.5380
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 34s - loss: 7.1945 - acc: 0.6118 - val_loss: 7.3730 - val_acc: 0.5516
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 34s - loss: 7.1936 - acc: 0.6117 - val_loss: 7.3424 - val_acc: 0.5622
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 34s - loss: 7.1889 - acc: 0.6126 - val_loss: 7.3011 - val_acc: 0.5730
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 34s - loss: 7.1815 - acc: 0.6170 - val_loss: 7.4561 - val_acc: 0.5280
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 34s - loss: 7.1887 - acc: 0.6149 - val_loss: 7.3269 - val_acc: 0.5630
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 34s - loss: 7.1923 - acc: 0.6109 - val_loss: 7.3743 - val_acc: 0.5412
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 34s - loss: 7.1929 - acc: 0.6116 - val_loss: 7.3509 - val_acc: 0.5658
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 34s - loss: 7.1905 - acc: 0.6150 - val_loss: 7.3129 - val_acc: 0.5676
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 34s - loss: 7.1887 - acc: 0.6144 - val_loss: 7.3241 - val_acc: 0.5674
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 34s - loss: 7.1861 - acc: 0.6131 - val_loss: 7.3419 - val_acc: 0.5556
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 34s - loss: 7.1928 - acc: 0.6136 - val_loss: 7.3821 - val_acc: 0.5470
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 34s - loss: 7.1862 - acc: 0.6144 - val_loss: 7.4297 - val_acc: 0.5258
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 34s - loss: 7.1818 - acc: 0.6167 - val_loss: 7.3640 - val_acc: 0.5436
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 34s - loss: 7.1911 - acc: 0.6114 - val_loss: 7.3291 - val_acc: 0.5640
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 34s - loss: 7.1889 - acc: 0.6151 - val_loss: 7.3686 - val_acc: 0.5512
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 33s - loss: 7.1947 - acc: 0.6113 - val_loss: 7.3524 - val_acc: 0.5520
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 34s - loss: 7.1876 - acc: 0.6165 - val_loss: 7.4220 - val_acc: 0.5386
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 33s - loss: 7.1913 - acc: 0.6120 - val_loss: 7.3897 - val_acc: 0.5456
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 34s - loss: 7.1894 - acc: 0.6152 - val_loss: 7.4334 - val_acc: 0.5338
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 33s - loss: 7.1888 - acc: 0.6122 - val_loss: 7.3321 - val_acc: 0.5596
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 34s - loss: 7.1841 - acc: 0.6158 - val_loss: 7.4589 - val_acc: 0.5140
Done

