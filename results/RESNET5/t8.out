Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
ternary_conv2d_1 (TernaryConv2D (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_2 (TernaryConv2D (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_2[0][0]           
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_3 (TernaryConv2D (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_3[0][0]           
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_4 (TernaryConv2D (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_4[0][0]           
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_5 (TernaryConv2D (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_5[0][0]           
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_6 (TernaryConv2D (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_6[0][0]           
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_7 (TernaryConv2D (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_7[0][0]           
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_8 (TernaryConv2D (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_8[0][0]           
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_9 (TernaryConv2D (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_9[0][0]           
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_10 (TernaryConv2 (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_10[0][0]          
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_11 (TernaryConv2 (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_11[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_12 (TernaryConv2 (None, 16, 16, 32)   4640        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_12[0][0]          
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_13 (TernaryConv2 (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_14 (TernaryConv2 (None, 16, 16, 32)   544         activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_13[0][0]          
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           ternary_conv2d_14[0][0]          
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_15 (TernaryConv2 (None, 16, 16, 32)   9248        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_15[0][0]          
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_16 (TernaryConv2 (None, 16, 16, 32)   9248        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_16[0][0]          
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 32)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_17 (TernaryConv2 (None, 16, 16, 32)   9248        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_17[0][0]          
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_18 (TernaryConv2 (None, 16, 16, 32)   9248        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_18[0][0]          
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 32)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_19 (TernaryConv2 (None, 16, 16, 32)   9248        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_19[0][0]          
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_20 (TernaryConv2 (None, 16, 16, 32)   9248        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_20[0][0]          
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 32)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_21 (TernaryConv2 (None, 16, 16, 32)   9248        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_21[0][0]          
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_22 (TernaryConv2 (None, 16, 16, 32)   9248        activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_22[0][0]          
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           activation_19[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_23 (TernaryConv2 (None, 8, 8, 64)     18496       activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_23[0][0]          
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_24 (TernaryConv2 (None, 8, 8, 64)     36928       activation_22[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_25 (TernaryConv2 (None, 8, 8, 64)     2112        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_24[0][0]          
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 64)     0           ternary_conv2d_25[0][0]          
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_26 (TernaryConv2 (None, 8, 8, 64)     36928       activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_26[0][0]          
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_27 (TernaryConv2 (None, 8, 8, 64)     36928       activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_27[0][0]          
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 64)     0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_28 (TernaryConv2 (None, 8, 8, 64)     36928       activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_28[0][0]          
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_29 (TernaryConv2 (None, 8, 8, 64)     36928       activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_29[0][0]          
__________________________________________________________________________________________________
add_13 (Add)                    (None, 8, 8, 64)     0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_30 (TernaryConv2 (None, 8, 8, 64)     36928       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_30[0][0]          
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_31 (TernaryConv2 (None, 8, 8, 64)     36928       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_31[0][0]          
__________________________________________________________________________________________________
add_14 (Add)                    (None, 8, 8, 64)     0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_32 (TernaryConv2 (None, 8, 8, 64)     36928       activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_32[0][0]          
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_33 (TernaryConv2 (None, 8, 8, 64)     36928       activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_33[0][0]          
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 8, 64)     0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_31[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
ternary_dense_1 (TernaryDense)  (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 470,218
Trainable params: 467,946
Non-trainable params: 2,272
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.10140, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 42s - loss: 17.3153 - acc: 0.0998 - val_loss: 15.9358 - val_acc: 0.1014
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.10140 to 0.10760, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 15.0615 - acc: 0.1019 - val_loss: 14.2449 - val_acc: 0.1076
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc improved from 0.10760 to 0.11600, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 13.5334 - acc: 0.1113 - val_loss: 12.9242 - val_acc: 0.1160
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.11600 to 0.15120, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 12.3006 - acc: 0.1328 - val_loss: 11.7549 - val_acc: 0.1512
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc improved from 0.15120 to 0.18080, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 11.2611 - acc: 0.1621 - val_loss: 10.7808 - val_acc: 0.1808
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc did not improve
 - 34s - loss: 10.4166 - acc: 0.1819 - val_loss: 10.0899 - val_acc: 0.1784
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.18080 to 0.19140, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 9.7038 - acc: 0.1953 - val_loss: 9.3957 - val_acc: 0.1914
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc did not improve
 - 34s - loss: 9.0887 - acc: 0.2074 - val_loss: 8.8732 - val_acc: 0.1850
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc improved from 0.19140 to 0.20000, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 8.5464 - acc: 0.2224 - val_loss: 8.3319 - val_acc: 0.2000
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc improved from 0.20000 to 0.22740, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 8.0680 - acc: 0.2317 - val_loss: 7.8781 - val_acc: 0.2274
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 34s - loss: 7.6397 - acc: 0.2398 - val_loss: 7.4778 - val_acc: 0.2250
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc improved from 0.22740 to 0.23180, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 7.2606 - acc: 0.2463 - val_loss: 7.1125 - val_acc: 0.2318
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc did not improve
 - 34s - loss: 6.9330 - acc: 0.2453 - val_loss: 6.8450 - val_acc: 0.2180
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 34s - loss: 6.6261 - acc: 0.2552 - val_loss: 6.5512 - val_acc: 0.2294
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc did not improve
 - 34s - loss: 6.3470 - acc: 0.2664 - val_loss: 6.3888 - val_acc: 0.1952
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 34s - loss: 6.1008 - acc: 0.2716 - val_loss: 6.1352 - val_acc: 0.2246
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 34s - loss: 5.9125 - acc: 0.2678 - val_loss: 5.8997 - val_acc: 0.2290
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc improved from 0.23180 to 0.23960, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 5.7157 - acc: 0.2835 - val_loss: 5.7690 - val_acc: 0.2396
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 34s - loss: 5.5508 - acc: 0.2873 - val_loss: 5.6295 - val_acc: 0.2292
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc improved from 0.23960 to 0.24200, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 5.3957 - acc: 0.2948 - val_loss: 5.4520 - val_acc: 0.2420
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc improved from 0.24200 to 0.27040, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 5.2515 - acc: 0.3028 - val_loss: 5.2988 - val_acc: 0.2704
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 34s - loss: 5.1109 - acc: 0.3177 - val_loss: 5.2248 - val_acc: 0.2612
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 34s - loss: 4.9892 - acc: 0.3234 - val_loss: 5.0800 - val_acc: 0.2698
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc improved from 0.27040 to 0.28680, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 4.8804 - acc: 0.3305 - val_loss: 4.9797 - val_acc: 0.2868
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 34s - loss: 4.7852 - acc: 0.3286 - val_loss: 5.1334 - val_acc: 0.2266
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 34s - loss: 4.6941 - acc: 0.3244 - val_loss: 4.8150 - val_acc: 0.2836
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 34s - loss: 4.5782 - acc: 0.3313 - val_loss: 4.8305 - val_acc: 0.2232
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc improved from 0.28680 to 0.29620, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 4.4726 - acc: 0.3334 - val_loss: 4.5368 - val_acc: 0.2962
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 34s - loss: 4.3772 - acc: 0.3362 - val_loss: 4.4795 - val_acc: 0.2548
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 34s - loss: 4.2721 - acc: 0.3408 - val_loss: 4.4888 - val_acc: 0.2960
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 34s - loss: 4.1666 - acc: 0.3448 - val_loss: 4.4160 - val_acc: 0.2842
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 34s - loss: 4.0519 - acc: 0.3551 - val_loss: 4.3895 - val_acc: 0.2582
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc improved from 0.29620 to 0.31500, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 3.9386 - acc: 0.3648 - val_loss: 4.0381 - val_acc: 0.3150
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc improved from 0.31500 to 0.33720, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 3.8450 - acc: 0.3635 - val_loss: 3.9712 - val_acc: 0.3372
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 34s - loss: 3.7520 - acc: 0.3727 - val_loss: 4.0070 - val_acc: 0.2932
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 34s - loss: 3.6657 - acc: 0.3716 - val_loss: 3.9523 - val_acc: 0.2708
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 34s - loss: 3.5734 - acc: 0.3772 - val_loss: 3.8034 - val_acc: 0.3130
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 34s - loss: 3.5035 - acc: 0.3765 - val_loss: 3.7196 - val_acc: 0.3126
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 34s - loss: 3.3929 - acc: 0.3880 - val_loss: 3.6251 - val_acc: 0.3118
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 34s - loss: 3.3017 - acc: 0.3970 - val_loss: 3.7307 - val_acc: 0.2898
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 34s - loss: 3.2224 - acc: 0.4024 - val_loss: 3.6180 - val_acc: 0.2634
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 34s - loss: 3.1593 - acc: 0.4037 - val_loss: 3.4728 - val_acc: 0.3152
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 34s - loss: 3.0830 - acc: 0.4093 - val_loss: 3.3252 - val_acc: 0.3364
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 34s - loss: 2.9878 - acc: 0.4225 - val_loss: 3.3696 - val_acc: 0.3152
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 34s - loss: 2.9254 - acc: 0.4265 - val_loss: 3.1662 - val_acc: 0.3306
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 34s - loss: 2.8531 - acc: 0.4327 - val_loss: 3.1472 - val_acc: 0.3112
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 34s - loss: 2.7849 - acc: 0.4372 - val_loss: 3.3682 - val_acc: 0.3154
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 34s - loss: 2.7313 - acc: 0.4391 - val_loss: 3.9398 - val_acc: 0.1798
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc improved from 0.33720 to 0.35620, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 2.6768 - acc: 0.4451 - val_loss: 2.8751 - val_acc: 0.3562
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 34s - loss: 2.6175 - acc: 0.4494 - val_loss: 3.5180 - val_acc: 0.2530
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 34s - loss: 2.5676 - acc: 0.4507 - val_loss: 2.9371 - val_acc: 0.3016
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 34s - loss: 2.5135 - acc: 0.4538 - val_loss: 3.0587 - val_acc: 0.3406
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 34s - loss: 2.4503 - acc: 0.4673 - val_loss: 2.7867 - val_acc: 0.3418
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 34s - loss: 2.4021 - acc: 0.4719 - val_loss: 3.0996 - val_acc: 0.3070
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 34s - loss: 2.3659 - acc: 0.4738 - val_loss: 2.6769 - val_acc: 0.3422
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc improved from 0.35620 to 0.37320, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 2.3202 - acc: 0.4789 - val_loss: 2.7016 - val_acc: 0.3732
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 34s - loss: 2.2792 - acc: 0.4831 - val_loss: 2.7470 - val_acc: 0.3500
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 34s - loss: 2.2370 - acc: 0.4918 - val_loss: 2.7966 - val_acc: 0.3294
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 34s - loss: 2.2077 - acc: 0.4952 - val_loss: 2.9329 - val_acc: 0.2648
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 34s - loss: 2.1676 - acc: 0.5016 - val_loss: 3.4918 - val_acc: 0.2322
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 34s - loss: 2.1364 - acc: 0.5031 - val_loss: 2.6977 - val_acc: 0.3314
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc improved from 0.37320 to 0.40200, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 2.1028 - acc: 0.5077 - val_loss: 2.4496 - val_acc: 0.4020
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 34s - loss: 2.0636 - acc: 0.5157 - val_loss: 2.5902 - val_acc: 0.3268
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 34s - loss: 2.0500 - acc: 0.5165 - val_loss: 2.4944 - val_acc: 0.3664
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc improved from 0.40200 to 0.42220, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 2.0106 - acc: 0.5249 - val_loss: 2.2720 - val_acc: 0.4222
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 34s - loss: 1.9849 - acc: 0.5272 - val_loss: 2.4272 - val_acc: 0.3972
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 34s - loss: 1.9689 - acc: 0.5283 - val_loss: 3.3146 - val_acc: 0.2622
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 34s - loss: 1.9429 - acc: 0.5371 - val_loss: 2.7202 - val_acc: 0.3150
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 34s - loss: 1.9103 - acc: 0.5413 - val_loss: 2.3126 - val_acc: 0.4204
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc improved from 0.42220 to 0.43640, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 1.8873 - acc: 0.5456 - val_loss: 2.2338 - val_acc: 0.4364
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 34s - loss: 1.8635 - acc: 0.5492 - val_loss: 2.4720 - val_acc: 0.3782
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 34s - loss: 1.8438 - acc: 0.5514 - val_loss: 2.7476 - val_acc: 0.3626
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 34s - loss: 1.8241 - acc: 0.5554 - val_loss: 2.3194 - val_acc: 0.3856
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 34s - loss: 1.8139 - acc: 0.5556 - val_loss: 2.2700 - val_acc: 0.3772
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 34s - loss: 1.7890 - acc: 0.5586 - val_loss: 2.2213 - val_acc: 0.4090
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 34s - loss: 1.7675 - acc: 0.5646 - val_loss: 2.6156 - val_acc: 0.3210
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 34s - loss: 1.7425 - acc: 0.5664 - val_loss: 2.1766 - val_acc: 0.4196
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 34s - loss: 1.7182 - acc: 0.5755 - val_loss: 2.9389 - val_acc: 0.2566
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 34s - loss: 1.7048 - acc: 0.5771 - val_loss: 2.3148 - val_acc: 0.3970
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 34s - loss: 1.6812 - acc: 0.5801 - val_loss: 2.9069 - val_acc: 0.3072
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc improved from 0.43640 to 0.45680, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 1.6738 - acc: 0.5803 - val_loss: 2.0789 - val_acc: 0.4568
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.45680 to 0.60420, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 1.5381 - acc: 0.6278 - val_loss: 1.5811 - val_acc: 0.6042
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.60420 to 0.60760, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 1.4771 - acc: 0.6493 - val_loss: 1.5851 - val_acc: 0.6076
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc did not improve
 - 34s - loss: 1.4499 - acc: 0.6585 - val_loss: 1.5751 - val_acc: 0.6058
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc improved from 0.60760 to 0.62660, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 1.4289 - acc: 0.6664 - val_loss: 1.5260 - val_acc: 0.6266
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 34s - loss: 1.4077 - acc: 0.6748 - val_loss: 1.5433 - val_acc: 0.6194
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 34s - loss: 1.3868 - acc: 0.6787 - val_loss: 1.6094 - val_acc: 0.5964
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 34s - loss: 1.3745 - acc: 0.6857 - val_loss: 1.7227 - val_acc: 0.5790
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 34s - loss: 1.3686 - acc: 0.6856 - val_loss: 1.6186 - val_acc: 0.5890
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 34s - loss: 1.3545 - acc: 0.6923 - val_loss: 1.5410 - val_acc: 0.6242
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 34s - loss: 1.3406 - acc: 0.6941 - val_loss: 1.6278 - val_acc: 0.6046
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 34s - loss: 1.3264 - acc: 0.6993 - val_loss: 1.7162 - val_acc: 0.5716
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 34s - loss: 1.3183 - acc: 0.7042 - val_loss: 1.8697 - val_acc: 0.5268
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 34s - loss: 1.3137 - acc: 0.7057 - val_loss: 1.6531 - val_acc: 0.6024
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 34s - loss: 1.3220 - acc: 0.7003 - val_loss: 1.8942 - val_acc: 0.5256
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 34s - loss: 1.3128 - acc: 0.7032 - val_loss: 1.6531 - val_acc: 0.5816
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 34s - loss: 1.3126 - acc: 0.7041 - val_loss: 1.5822 - val_acc: 0.6058
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 34s - loss: 1.2960 - acc: 0.7111 - val_loss: 1.7895 - val_acc: 0.5650
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 34s - loss: 1.2816 - acc: 0.7114 - val_loss: 1.5975 - val_acc: 0.6096
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 34s - loss: 1.2884 - acc: 0.7092 - val_loss: 1.7735 - val_acc: 0.5602
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 34s - loss: 1.2828 - acc: 0.7108 - val_loss: 1.6459 - val_acc: 0.6026
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 34s - loss: 1.2816 - acc: 0.7109 - val_loss: 1.6620 - val_acc: 0.5766
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 34s - loss: 1.2687 - acc: 0.7157 - val_loss: 1.8596 - val_acc: 0.5302
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 34s - loss: 1.2649 - acc: 0.7192 - val_loss: 1.7881 - val_acc: 0.5672
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 34s - loss: 1.2688 - acc: 0.7152 - val_loss: 1.6175 - val_acc: 0.5922
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 34s - loss: 1.2584 - acc: 0.7188 - val_loss: 1.7014 - val_acc: 0.5786
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 34s - loss: 1.2563 - acc: 0.7214 - val_loss: 2.0062 - val_acc: 0.5304
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 34s - loss: 1.2398 - acc: 0.7263 - val_loss: 1.6825 - val_acc: 0.5640
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 34s - loss: 1.2437 - acc: 0.7241 - val_loss: 1.8724 - val_acc: 0.5306
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 34s - loss: 1.2416 - acc: 0.7241 - val_loss: 1.7178 - val_acc: 0.5690
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 34s - loss: 1.2450 - acc: 0.7230 - val_loss: 1.7115 - val_acc: 0.5680
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 34s - loss: 1.2300 - acc: 0.7258 - val_loss: 2.0117 - val_acc: 0.5110
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 34s - loss: 1.2307 - acc: 0.7294 - val_loss: 1.8784 - val_acc: 0.5276
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 34s - loss: 1.2374 - acc: 0.7249 - val_loss: 1.7258 - val_acc: 0.5906
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 34s - loss: 1.2318 - acc: 0.7251 - val_loss: 1.6285 - val_acc: 0.5952
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 34s - loss: 1.2224 - acc: 0.7275 - val_loss: 1.8810 - val_acc: 0.5550
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 34s - loss: 1.2226 - acc: 0.7305 - val_loss: 1.8604 - val_acc: 0.5458
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 34s - loss: 1.2271 - acc: 0.7272 - val_loss: 1.9388 - val_acc: 0.5194
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 34s - loss: 1.2299 - acc: 0.7249 - val_loss: 1.7601 - val_acc: 0.5700
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 34s - loss: 1.2252 - acc: 0.7264 - val_loss: 1.5776 - val_acc: 0.6164
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 34s - loss: 1.2046 - acc: 0.7343 - val_loss: 1.7304 - val_acc: 0.5770
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc improved from 0.62660 to 0.65900, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 1.1262 - acc: 0.7665 - val_loss: 1.4291 - val_acc: 0.6590
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 34s - loss: 1.0974 - acc: 0.7760 - val_loss: 1.4842 - val_acc: 0.6392
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 34s - loss: 1.0914 - acc: 0.7789 - val_loss: 1.5162 - val_acc: 0.6438
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 34s - loss: 1.0864 - acc: 0.7782 - val_loss: 1.4937 - val_acc: 0.6468
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 34s - loss: 1.0835 - acc: 0.7798 - val_loss: 1.4439 - val_acc: 0.6562
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 34s - loss: 1.0854 - acc: 0.7794 - val_loss: 1.4944 - val_acc: 0.6476
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 34s - loss: 1.0748 - acc: 0.7824 - val_loss: 1.5235 - val_acc: 0.6310
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 34s - loss: 1.0829 - acc: 0.7785 - val_loss: 1.5349 - val_acc: 0.6294
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 34s - loss: 1.0839 - acc: 0.7772 - val_loss: 1.6131 - val_acc: 0.6072
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 34s - loss: 1.0817 - acc: 0.7807 - val_loss: 1.5570 - val_acc: 0.6240
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 34s - loss: 1.0741 - acc: 0.7825 - val_loss: 1.5028 - val_acc: 0.6442
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 34s - loss: 1.0753 - acc: 0.7803 - val_loss: 1.6195 - val_acc: 0.6200
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 34s - loss: 1.0704 - acc: 0.7839 - val_loss: 1.4802 - val_acc: 0.6500
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 34s - loss: 1.0631 - acc: 0.7855 - val_loss: 1.5275 - val_acc: 0.6336
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 34s - loss: 1.0663 - acc: 0.7833 - val_loss: 1.4993 - val_acc: 0.6376
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 34s - loss: 1.0665 - acc: 0.7841 - val_loss: 1.6976 - val_acc: 0.5978
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 34s - loss: 1.0568 - acc: 0.7901 - val_loss: 1.5110 - val_acc: 0.6370
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 34s - loss: 1.0583 - acc: 0.7891 - val_loss: 1.6114 - val_acc: 0.6084
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 34s - loss: 1.0622 - acc: 0.7872 - val_loss: 1.7814 - val_acc: 0.5716
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 34s - loss: 1.0670 - acc: 0.7867 - val_loss: 1.5245 - val_acc: 0.6386
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 34s - loss: 1.0548 - acc: 0.7878 - val_loss: 1.4941 - val_acc: 0.6498
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 34s - loss: 1.0568 - acc: 0.7856 - val_loss: 1.5362 - val_acc: 0.6358
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 34s - loss: 1.0539 - acc: 0.7894 - val_loss: 1.5005 - val_acc: 0.6506
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 34s - loss: 1.0555 - acc: 0.7882 - val_loss: 1.7474 - val_acc: 0.5722
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 34s - loss: 1.0543 - acc: 0.7877 - val_loss: 1.5338 - val_acc: 0.6392
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 34s - loss: 1.0548 - acc: 0.7862 - val_loss: 1.5042 - val_acc: 0.6378
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 34s - loss: 1.0540 - acc: 0.7896 - val_loss: 1.5348 - val_acc: 0.6322
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 34s - loss: 1.0467 - acc: 0.7905 - val_loss: 1.7838 - val_acc: 0.5856
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 34s - loss: 1.0523 - acc: 0.7895 - val_loss: 1.6759 - val_acc: 0.6180
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 34s - loss: 1.0560 - acc: 0.7879 - val_loss: 1.6363 - val_acc: 0.6064
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 34s - loss: 1.0465 - acc: 0.7914 - val_loss: 1.6653 - val_acc: 0.6044
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 34s - loss: 1.0488 - acc: 0.7904 - val_loss: 1.5441 - val_acc: 0.6324
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 34s - loss: 1.0537 - acc: 0.7881 - val_loss: 1.6999 - val_acc: 0.5960
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 34s - loss: 1.0618 - acc: 0.7845 - val_loss: 1.5985 - val_acc: 0.6100
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 34s - loss: 1.0455 - acc: 0.7916 - val_loss: 1.6398 - val_acc: 0.6026
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 34s - loss: 1.0565 - acc: 0.7861 - val_loss: 1.5322 - val_acc: 0.6344
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 34s - loss: 1.0443 - acc: 0.7916 - val_loss: 1.7825 - val_acc: 0.5756
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 34s - loss: 1.0448 - acc: 0.7932 - val_loss: 1.5729 - val_acc: 0.6274
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 34s - loss: 1.0437 - acc: 0.7909 - val_loss: 1.5564 - val_acc: 0.6282
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 34s - loss: 1.0333 - acc: 0.7957 - val_loss: 1.8760 - val_acc: 0.5516
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc improved from 0.65900 to 0.66220, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_5.hdf5
 - 35s - loss: 0.9923 - acc: 0.8133 - val_loss: 1.4421 - val_acc: 0.6622
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 34s - loss: 0.9822 - acc: 0.8160 - val_loss: 1.4846 - val_acc: 0.6500
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 34s - loss: 0.9932 - acc: 0.8103 - val_loss: 1.4814 - val_acc: 0.6540
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 34s - loss: 0.9969 - acc: 0.8090 - val_loss: 1.6365 - val_acc: 0.6182
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 34s - loss: 0.9859 - acc: 0.8150 - val_loss: 1.4694 - val_acc: 0.6582
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 34s - loss: 0.9960 - acc: 0.8111 - val_loss: 1.5255 - val_acc: 0.6426
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 34s - loss: 0.9956 - acc: 0.8104 - val_loss: 1.5337 - val_acc: 0.6450
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 34s - loss: 0.9850 - acc: 0.8160 - val_loss: 1.5706 - val_acc: 0.6292
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 34s - loss: 0.9801 - acc: 0.8172 - val_loss: 1.5731 - val_acc: 0.6326
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 34s - loss: 0.9974 - acc: 0.8102 - val_loss: 1.5048 - val_acc: 0.6312
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 34s - loss: 0.9950 - acc: 0.8116 - val_loss: 1.5944 - val_acc: 0.6152
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 34s - loss: 1.0033 - acc: 0.8091 - val_loss: 1.5107 - val_acc: 0.6554
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 34s - loss: 0.9999 - acc: 0.8092 - val_loss: 1.8220 - val_acc: 0.5768
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 34s - loss: 1.0000 - acc: 0.8083 - val_loss: 1.4373 - val_acc: 0.6598
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 34s - loss: 0.9909 - acc: 0.8126 - val_loss: 1.5723 - val_acc: 0.6318
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 34s - loss: 0.9908 - acc: 0.8129 - val_loss: 1.6794 - val_acc: 0.6026
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 34s - loss: 0.9839 - acc: 0.8152 - val_loss: 1.5958 - val_acc: 0.6302
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 34s - loss: 0.9899 - acc: 0.8132 - val_loss: 1.7362 - val_acc: 0.5860
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 34s - loss: 0.9988 - acc: 0.8083 - val_loss: 1.6261 - val_acc: 0.6144
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 34s - loss: 1.0015 - acc: 0.8084 - val_loss: 1.6308 - val_acc: 0.6144
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 34s - loss: 0.9863 - acc: 0.8142 - val_loss: 1.5801 - val_acc: 0.6266
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 34s - loss: 0.9907 - acc: 0.8139 - val_loss: 1.4860 - val_acc: 0.6516
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 34s - loss: 0.9880 - acc: 0.8139 - val_loss: 1.5266 - val_acc: 0.6288
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 34s - loss: 0.9876 - acc: 0.8129 - val_loss: 1.5382 - val_acc: 0.6362
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 34s - loss: 0.9771 - acc: 0.8184 - val_loss: 1.4685 - val_acc: 0.6594
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 34s - loss: 1.0069 - acc: 0.8059 - val_loss: 1.5260 - val_acc: 0.6382
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 34s - loss: 0.9940 - acc: 0.8107 - val_loss: 1.4878 - val_acc: 0.6482
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 34s - loss: 0.9993 - acc: 0.8073 - val_loss: 1.5123 - val_acc: 0.6444
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 34s - loss: 0.9992 - acc: 0.8082 - val_loss: 1.5925 - val_acc: 0.6254
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 34s - loss: 1.0079 - acc: 0.8051 - val_loss: 1.5368 - val_acc: 0.6426
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 34s - loss: 0.9950 - acc: 0.8103 - val_loss: 1.5824 - val_acc: 0.6306
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 34s - loss: 0.9992 - acc: 0.8092 - val_loss: 1.5542 - val_acc: 0.6382
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 34s - loss: 0.9888 - acc: 0.8118 - val_loss: 1.6052 - val_acc: 0.6238
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 34s - loss: 1.0002 - acc: 0.8080 - val_loss: 1.5006 - val_acc: 0.6482
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 34s - loss: 1.0046 - acc: 0.8088 - val_loss: 1.6387 - val_acc: 0.6256
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 34s - loss: 1.0012 - acc: 0.8063 - val_loss: 1.5936 - val_acc: 0.6166
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 34s - loss: 0.9859 - acc: 0.8133 - val_loss: 1.6246 - val_acc: 0.6096
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 34s - loss: 0.9884 - acc: 0.8156 - val_loss: 1.5870 - val_acc: 0.6254
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 34s - loss: 1.0059 - acc: 0.8058 - val_loss: 1.6178 - val_acc: 0.6284
Done

