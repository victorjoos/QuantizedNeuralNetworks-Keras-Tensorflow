Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
binary_conv2d_1 (BinaryConv2D)  (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_1[0][0]            
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
binary_conv2d_2 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_2[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
binary_conv2d_3 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_3[0][0]            
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_4 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_4[0][0]            
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
binary_conv2d_5 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_5[0][0]            
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_6 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_6[0][0]            
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
binary_conv2d_7 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_7[0][0]            
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_8 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_8[0][0]            
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
binary_conv2d_9 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_9[0][0]            
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_10 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_10[0][0]           
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
binary_conv2d_11 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_11[0][0]           
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_12 (BinaryConv2D) (None, 16, 16, 32)   4640        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_12[0][0]           
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
binary_conv2d_13 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
binary_conv2d_14 (BinaryConv2D) (None, 16, 16, 32)   544         activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_13[0][0]           
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           binary_conv2d_14[0][0]           
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_15 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_15[0][0]           
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
binary_conv2d_16 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_16[0][0]           
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 32)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_17 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_17[0][0]           
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
binary_conv2d_18 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_18[0][0]           
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 32)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_19 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_19[0][0]           
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
binary_conv2d_20 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_20[0][0]           
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 32)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_21 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_21[0][0]           
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
binary_conv2d_22 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_22[0][0]           
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           activation_19[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_23 (BinaryConv2D) (None, 8, 8, 64)     18496       activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_23[0][0]           
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
binary_conv2d_24 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_22[0][0]              
__________________________________________________________________________________________________
binary_conv2d_25 (BinaryConv2D) (None, 8, 8, 64)     2112        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_24[0][0]           
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 64)     0           binary_conv2d_25[0][0]           
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_26 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_26[0][0]           
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
binary_conv2d_27 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_27[0][0]           
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 64)     0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_28 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_28[0][0]           
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
binary_conv2d_29 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_29[0][0]           
__________________________________________________________________________________________________
add_13 (Add)                    (None, 8, 8, 64)     0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_30 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_30[0][0]           
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
binary_conv2d_31 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_31[0][0]           
__________________________________________________________________________________________________
add_14 (Add)                    (None, 8, 8, 64)     0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_32 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_32[0][0]           
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
binary_conv2d_33 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_33[0][0]           
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 8, 64)     0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_31[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
binary_dense_2 (BinaryDense)    (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 470,218
Trainable params: 467,946
Non-trainable params: 2,272
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.10320, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 48s - loss: 18.3113 - acc: 0.0964 - val_loss: 17.7950 - val_acc: 0.1032
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc did not improve
 - 37s - loss: 17.6975 - acc: 0.1014 - val_loss: 17.6488 - val_acc: 0.0998
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc did not improve
 - 38s - loss: 17.5812 - acc: 0.1022 - val_loss: 17.5489 - val_acc: 0.0970
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.10320 to 0.11120, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 17.4783 - acc: 0.1066 - val_loss: 17.4168 - val_acc: 0.1112
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc improved from 0.11120 to 0.11980, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 17.3335 - acc: 0.1255 - val_loss: 17.3400 - val_acc: 0.1198
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc did not improve
 - 38s - loss: 17.2478 - acc: 0.1239 - val_loss: 17.4054 - val_acc: 0.0954
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc did not improve
 - 38s - loss: 17.1731 - acc: 0.1184 - val_loss: 17.1831 - val_acc: 0.1164
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc did not improve
 - 38s - loss: 17.0831 - acc: 0.1128 - val_loss: 17.1355 - val_acc: 0.1016
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc improved from 0.11980 to 0.16580, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 16.8966 - acc: 0.1441 - val_loss: 16.7748 - val_acc: 0.1658
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 38s - loss: 16.7485 - acc: 0.1585 - val_loss: 16.8444 - val_acc: 0.1254
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc improved from 0.16580 to 0.18440, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 16.6080 - acc: 0.1766 - val_loss: 16.5189 - val_acc: 0.1844
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 38s - loss: 16.4294 - acc: 0.1998 - val_loss: 16.6350 - val_acc: 0.1158
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc improved from 0.18440 to 0.19680, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 16.3052 - acc: 0.2014 - val_loss: 16.2466 - val_acc: 0.1968
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 38s - loss: 16.1953 - acc: 0.1969 - val_loss: 16.1529 - val_acc: 0.1796
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc improved from 0.19680 to 0.20500, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 16.0221 - acc: 0.2107 - val_loss: 15.9857 - val_acc: 0.2050
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc improved from 0.20500 to 0.21680, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 15.8559 - acc: 0.2202 - val_loss: 15.8228 - val_acc: 0.2168
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 38s - loss: 15.7168 - acc: 0.2225 - val_loss: 15.6764 - val_acc: 0.2152
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 38s - loss: 15.5680 - acc: 0.2205 - val_loss: 15.6035 - val_acc: 0.1934
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 38s - loss: 15.4465 - acc: 0.2102 - val_loss: 15.3826 - val_acc: 0.2082
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc improved from 0.21680 to 0.23500, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 15.2602 - acc: 0.2321 - val_loss: 15.1879 - val_acc: 0.2350
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc improved from 0.23500 to 0.23520, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 15.0764 - acc: 0.2400 - val_loss: 15.0160 - val_acc: 0.2352
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc improved from 0.23520 to 0.26040, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 14.8798 - acc: 0.2577 - val_loss: 14.8199 - val_acc: 0.2604
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 38s - loss: 14.6995 - acc: 0.2640 - val_loss: 14.6279 - val_acc: 0.2522
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc improved from 0.26040 to 0.27280, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 14.5119 - acc: 0.2740 - val_loss: 14.4640 - val_acc: 0.2728
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 38s - loss: 14.3237 - acc: 0.2859 - val_loss: 14.3890 - val_acc: 0.2270
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc improved from 0.27280 to 0.27800, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 14.1542 - acc: 0.2818 - val_loss: 14.1118 - val_acc: 0.2780
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc improved from 0.27800 to 0.28160, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 13.9949 - acc: 0.2843 - val_loss: 13.9261 - val_acc: 0.2816
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 38s - loss: 13.8325 - acc: 0.2783 - val_loss: 13.9015 - val_acc: 0.2100
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 38s - loss: 13.7486 - acc: 0.2334 - val_loss: 13.7457 - val_acc: 0.2024
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 38s - loss: 13.5148 - acc: 0.2564 - val_loss: 13.4343 - val_acc: 0.2554
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 38s - loss: 13.2994 - acc: 0.2691 - val_loss: 13.2615 - val_acc: 0.2532
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc improved from 0.28160 to 0.29080, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 13.0855 - acc: 0.2911 - val_loss: 13.0139 - val_acc: 0.2908
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 38s - loss: 12.8772 - acc: 0.3069 - val_loss: 12.8637 - val_acc: 0.2686
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 38s - loss: 12.7031 - acc: 0.3072 - val_loss: 12.7460 - val_acc: 0.2686
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 38s - loss: 12.5199 - acc: 0.3132 - val_loss: 12.5093 - val_acc: 0.2900
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 38s - loss: 12.3397 - acc: 0.3157 - val_loss: 12.3330 - val_acc: 0.2738
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 38s - loss: 12.1740 - acc: 0.3169 - val_loss: 12.1784 - val_acc: 0.2856
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc improved from 0.29080 to 0.30940, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 11.9982 - acc: 0.3244 - val_loss: 11.9587 - val_acc: 0.3094
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 38s - loss: 11.8171 - acc: 0.3302 - val_loss: 11.8269 - val_acc: 0.2918
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc improved from 0.30940 to 0.32000, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 11.6534 - acc: 0.3318 - val_loss: 11.5947 - val_acc: 0.3200
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 38s - loss: 11.4835 - acc: 0.3320 - val_loss: 11.5256 - val_acc: 0.2974
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 38s - loss: 11.3291 - acc: 0.3340 - val_loss: 11.2836 - val_acc: 0.3152
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 38s - loss: 11.1772 - acc: 0.3312 - val_loss: 11.2731 - val_acc: 0.2878
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 38s - loss: 11.0136 - acc: 0.3336 - val_loss: 11.0897 - val_acc: 0.2742
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 38s - loss: 10.8548 - acc: 0.3334 - val_loss: 10.8238 - val_acc: 0.3092
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 38s - loss: 10.6874 - acc: 0.3441 - val_loss: 10.6712 - val_acc: 0.3192
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc improved from 0.32000 to 0.32860, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 10.5363 - acc: 0.3450 - val_loss: 10.5223 - val_acc: 0.3286
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc improved from 0.32860 to 0.33680, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 10.3740 - acc: 0.3574 - val_loss: 10.3544 - val_acc: 0.3368
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 38s - loss: 10.2710 - acc: 0.3404 - val_loss: 10.4095 - val_acc: 0.2952
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc improved from 0.33680 to 0.34160, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 10.1363 - acc: 0.3426 - val_loss: 10.0706 - val_acc: 0.3416
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 38s - loss: 9.9975 - acc: 0.3424 - val_loss: 9.9607 - val_acc: 0.3382
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 38s - loss: 9.8715 - acc: 0.3437 - val_loss: 9.8293 - val_acc: 0.3334
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 38s - loss: 9.7501 - acc: 0.3392 - val_loss: 9.7789 - val_acc: 0.2958
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 38s - loss: 9.6048 - acc: 0.3476 - val_loss: 9.5907 - val_acc: 0.3336
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc improved from 0.34160 to 0.34600, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 9.4677 - acc: 0.3512 - val_loss: 9.4197 - val_acc: 0.3460
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 38s - loss: 9.3322 - acc: 0.3581 - val_loss: 9.2979 - val_acc: 0.3384
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 38s - loss: 9.2049 - acc: 0.3573 - val_loss: 9.2661 - val_acc: 0.3042
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 38s - loss: 9.0643 - acc: 0.3673 - val_loss: 9.1132 - val_acc: 0.3266
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc improved from 0.34600 to 0.36400, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 8.9346 - acc: 0.3735 - val_loss: 8.8852 - val_acc: 0.3640
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 38s - loss: 8.7950 - acc: 0.3894 - val_loss: 8.9447 - val_acc: 0.3136
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 38s - loss: 8.6814 - acc: 0.3942 - val_loss: 8.7888 - val_acc: 0.3422
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 38s - loss: 8.5651 - acc: 0.3985 - val_loss: 8.6078 - val_acc: 0.3620
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 38s - loss: 8.4620 - acc: 0.3977 - val_loss: 8.5777 - val_acc: 0.3476
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 38s - loss: 8.3541 - acc: 0.4054 - val_loss: 8.4886 - val_acc: 0.3406
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc improved from 0.36400 to 0.37100, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 8.2485 - acc: 0.4075 - val_loss: 8.2966 - val_acc: 0.3710
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 38s - loss: 8.1559 - acc: 0.4067 - val_loss: 8.2721 - val_acc: 0.3634
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 38s - loss: 8.0830 - acc: 0.4016 - val_loss: 8.1977 - val_acc: 0.3332
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 38s - loss: 7.9786 - acc: 0.4119 - val_loss: 8.0827 - val_acc: 0.3614
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc improved from 0.37100 to 0.39120, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 7.8732 - acc: 0.4159 - val_loss: 7.9136 - val_acc: 0.3912
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 38s - loss: 7.7803 - acc: 0.4221 - val_loss: 8.2558 - val_acc: 0.2790
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc improved from 0.39120 to 0.41080, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 7.6765 - acc: 0.4350 - val_loss: 7.7019 - val_acc: 0.4108
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 38s - loss: 7.5821 - acc: 0.4377 - val_loss: 7.6586 - val_acc: 0.3980
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 38s - loss: 7.5049 - acc: 0.4395 - val_loss: 7.6497 - val_acc: 0.3746
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 38s - loss: 7.4159 - acc: 0.4440 - val_loss: 7.5905 - val_acc: 0.3656
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 38s - loss: 7.3546 - acc: 0.4407 - val_loss: 7.4235 - val_acc: 0.3982
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 38s - loss: 7.2611 - acc: 0.4502 - val_loss: 7.4604 - val_acc: 0.3710
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 38s - loss: 7.1735 - acc: 0.4564 - val_loss: 7.3191 - val_acc: 0.3990
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 38s - loss: 7.0938 - acc: 0.4612 - val_loss: 7.4935 - val_acc: 0.3762
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 38s - loss: 7.0310 - acc: 0.4655 - val_loss: 7.1433 - val_acc: 0.4090
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 38s - loss: 6.9569 - acc: 0.4667 - val_loss: 7.3572 - val_acc: 0.3732
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 38s - loss: 6.8769 - acc: 0.4762 - val_loss: 7.2719 - val_acc: 0.3750
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.41080 to 0.47460, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.8017 - acc: 0.4871 - val_loss: 6.8406 - val_acc: 0.4746
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.47460 to 0.48480, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.7752 - acc: 0.4959 - val_loss: 6.8111 - val_acc: 0.4848
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc did not improve
 - 37s - loss: 6.7578 - acc: 0.5010 - val_loss: 6.7987 - val_acc: 0.4802
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 38s - loss: 6.7411 - acc: 0.5048 - val_loss: 6.8005 - val_acc: 0.4802
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc improved from 0.48480 to 0.48940, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.7309 - acc: 0.5063 - val_loss: 6.7718 - val_acc: 0.4894
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 38s - loss: 6.7157 - acc: 0.5087 - val_loss: 6.7703 - val_acc: 0.4884
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 38s - loss: 6.7060 - acc: 0.5110 - val_loss: 6.7601 - val_acc: 0.4858
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc improved from 0.48940 to 0.49140, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.6952 - acc: 0.5122 - val_loss: 6.7607 - val_acc: 0.4914
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 38s - loss: 6.6931 - acc: 0.5107 - val_loss: 6.7922 - val_acc: 0.4704
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 38s - loss: 6.6820 - acc: 0.5108 - val_loss: 6.7825 - val_acc: 0.4784
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 38s - loss: 6.6680 - acc: 0.5107 - val_loss: 6.7451 - val_acc: 0.4764
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc improved from 0.49140 to 0.49440, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.6564 - acc: 0.5138 - val_loss: 6.7351 - val_acc: 0.4944
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 38s - loss: 6.6516 - acc: 0.5143 - val_loss: 6.7279 - val_acc: 0.4878
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 38s - loss: 6.6447 - acc: 0.5157 - val_loss: 6.9719 - val_acc: 0.4118
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 38s - loss: 6.6445 - acc: 0.5110 - val_loss: 6.7439 - val_acc: 0.4774
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 38s - loss: 6.6469 - acc: 0.5087 - val_loss: 6.7288 - val_acc: 0.4822
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 38s - loss: 6.6448 - acc: 0.5070 - val_loss: 6.7010 - val_acc: 0.4858
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 38s - loss: 6.6265 - acc: 0.5113 - val_loss: 6.7506 - val_acc: 0.4682
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc improved from 0.49440 to 0.50080, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.5974 - acc: 0.5197 - val_loss: 6.6529 - val_acc: 0.5008
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 38s - loss: 6.5838 - acc: 0.5221 - val_loss: 6.7143 - val_acc: 0.4720
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 38s - loss: 6.5707 - acc: 0.5263 - val_loss: 6.7033 - val_acc: 0.4786
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 38s - loss: 6.5667 - acc: 0.5237 - val_loss: 6.6803 - val_acc: 0.4874
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 38s - loss: 6.5521 - acc: 0.5279 - val_loss: 6.6647 - val_acc: 0.4904
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 38s - loss: 6.5499 - acc: 0.5266 - val_loss: 6.6432 - val_acc: 0.4884
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 38s - loss: 6.5396 - acc: 0.5273 - val_loss: 6.7235 - val_acc: 0.4706
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 38s - loss: 6.5296 - acc: 0.5302 - val_loss: 6.6516 - val_acc: 0.4768
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 38s - loss: 6.5214 - acc: 0.5303 - val_loss: 6.6249 - val_acc: 0.4996
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 38s - loss: 6.5104 - acc: 0.5314 - val_loss: 6.6571 - val_acc: 0.4776
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 38s - loss: 6.5042 - acc: 0.5330 - val_loss: 6.6253 - val_acc: 0.4908
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 38s - loss: 6.4986 - acc: 0.5322 - val_loss: 6.6336 - val_acc: 0.4848
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 38s - loss: 6.4962 - acc: 0.5289 - val_loss: 6.6201 - val_acc: 0.4866
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 38s - loss: 6.4883 - acc: 0.5324 - val_loss: 6.6077 - val_acc: 0.4814
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 38s - loss: 6.4744 - acc: 0.5347 - val_loss: 6.6161 - val_acc: 0.4794
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 38s - loss: 6.4722 - acc: 0.5310 - val_loss: 6.6123 - val_acc: 0.4908
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 38s - loss: 6.4723 - acc: 0.5329 - val_loss: 6.5879 - val_acc: 0.4884
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 38s - loss: 6.4618 - acc: 0.5313 - val_loss: 6.5666 - val_acc: 0.4976
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 38s - loss: 6.4525 - acc: 0.5350 - val_loss: 6.5475 - val_acc: 0.5006
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc improved from 0.50080 to 0.50160, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.4404 - acc: 0.5366 - val_loss: 6.5515 - val_acc: 0.5016
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 38s - loss: 6.4312 - acc: 0.5389 - val_loss: 6.5628 - val_acc: 0.4916
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 38s - loss: 6.4229 - acc: 0.5398 - val_loss: 6.6237 - val_acc: 0.4658
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc improved from 0.50160 to 0.51320, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.4022 - acc: 0.5452 - val_loss: 6.4969 - val_acc: 0.5132
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc improved from 0.51320 to 0.51540, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.3981 - acc: 0.5484 - val_loss: 6.4929 - val_acc: 0.5154
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 38s - loss: 6.3955 - acc: 0.5485 - val_loss: 6.5022 - val_acc: 0.5096
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 38s - loss: 6.3904 - acc: 0.5516 - val_loss: 6.5153 - val_acc: 0.5074
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc improved from 0.51540 to 0.51760, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.3943 - acc: 0.5481 - val_loss: 6.5011 - val_acc: 0.5176
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 38s - loss: 6.3918 - acc: 0.5494 - val_loss: 6.5035 - val_acc: 0.5080
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 38s - loss: 6.3907 - acc: 0.5491 - val_loss: 6.5064 - val_acc: 0.5030
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 38s - loss: 6.3865 - acc: 0.5498 - val_loss: 6.5048 - val_acc: 0.5068
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 38s - loss: 6.3877 - acc: 0.5512 - val_loss: 6.4932 - val_acc: 0.5104
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 38s - loss: 6.3909 - acc: 0.5487 - val_loss: 6.4855 - val_acc: 0.5174
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc improved from 0.51760 to 0.52180, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.3907 - acc: 0.5516 - val_loss: 6.4789 - val_acc: 0.5218
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 38s - loss: 6.3864 - acc: 0.5497 - val_loss: 6.5438 - val_acc: 0.4906
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 38s - loss: 6.3869 - acc: 0.5489 - val_loss: 6.4888 - val_acc: 0.5128
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 38s - loss: 6.3863 - acc: 0.5519 - val_loss: 6.5013 - val_acc: 0.5120
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 38s - loss: 6.3846 - acc: 0.5501 - val_loss: 6.5042 - val_acc: 0.5004
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 38s - loss: 6.3846 - acc: 0.5502 - val_loss: 6.4924 - val_acc: 0.5004
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 38s - loss: 6.3847 - acc: 0.5505 - val_loss: 6.5287 - val_acc: 0.4954
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 38s - loss: 6.3878 - acc: 0.5493 - val_loss: 6.4981 - val_acc: 0.5002
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 38s - loss: 6.3844 - acc: 0.5486 - val_loss: 6.5013 - val_acc: 0.5036
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 38s - loss: 6.3818 - acc: 0.5522 - val_loss: 6.5174 - val_acc: 0.5004
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 38s - loss: 6.3838 - acc: 0.5520 - val_loss: 6.4870 - val_acc: 0.5098
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 38s - loss: 6.3864 - acc: 0.5491 - val_loss: 6.4900 - val_acc: 0.5070
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 38s - loss: 6.3827 - acc: 0.5489 - val_loss: 6.5047 - val_acc: 0.5074
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 38s - loss: 6.3777 - acc: 0.5512 - val_loss: 6.4795 - val_acc: 0.5122
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 38s - loss: 6.3788 - acc: 0.5514 - val_loss: 6.4976 - val_acc: 0.5136
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 38s - loss: 6.3775 - acc: 0.5527 - val_loss: 6.4835 - val_acc: 0.5146
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 38s - loss: 6.3742 - acc: 0.5533 - val_loss: 6.5063 - val_acc: 0.5028
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 38s - loss: 6.3770 - acc: 0.5511 - val_loss: 6.5067 - val_acc: 0.5034
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 38s - loss: 6.3750 - acc: 0.5524 - val_loss: 6.5347 - val_acc: 0.5046
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 38s - loss: 6.3765 - acc: 0.5524 - val_loss: 6.4793 - val_acc: 0.5082
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 38s - loss: 6.3731 - acc: 0.5503 - val_loss: 6.4915 - val_acc: 0.5096
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 38s - loss: 6.3698 - acc: 0.5538 - val_loss: 6.4879 - val_acc: 0.5168
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 38s - loss: 6.3732 - acc: 0.5521 - val_loss: 6.4937 - val_acc: 0.5064
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 38s - loss: 6.3706 - acc: 0.5505 - val_loss: 6.5113 - val_acc: 0.5096
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 38s - loss: 6.3683 - acc: 0.5503 - val_loss: 6.5531 - val_acc: 0.4952
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 38s - loss: 6.3683 - acc: 0.5520 - val_loss: 6.5419 - val_acc: 0.4982
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 38s - loss: 6.3662 - acc: 0.5523 - val_loss: 6.5287 - val_acc: 0.4932
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 38s - loss: 6.3682 - acc: 0.5504 - val_loss: 6.4742 - val_acc: 0.5160
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 38s - loss: 6.3668 - acc: 0.5519 - val_loss: 6.4789 - val_acc: 0.5094
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 38s - loss: 6.3649 - acc: 0.5526 - val_loss: 6.4904 - val_acc: 0.5124
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 38s - loss: 6.3572 - acc: 0.5550 - val_loss: 6.4687 - val_acc: 0.5172
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 38s - loss: 6.3558 - acc: 0.5558 - val_loss: 6.4567 - val_acc: 0.5206
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 38s - loss: 6.3567 - acc: 0.5580 - val_loss: 6.4626 - val_acc: 0.5218
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 38s - loss: 6.3537 - acc: 0.5566 - val_loss: 6.4692 - val_acc: 0.5178
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 38s - loss: 6.3582 - acc: 0.5564 - val_loss: 6.4612 - val_acc: 0.5188
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 38s - loss: 6.3560 - acc: 0.5580 - val_loss: 6.4636 - val_acc: 0.5140
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 38s - loss: 6.3572 - acc: 0.5576 - val_loss: 6.4808 - val_acc: 0.5178
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 38s - loss: 6.3549 - acc: 0.5562 - val_loss: 6.4767 - val_acc: 0.5138
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc improved from 0.52180 to 0.52280, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.3566 - acc: 0.5544 - val_loss: 6.4581 - val_acc: 0.5228
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 38s - loss: 6.3575 - acc: 0.5555 - val_loss: 6.4791 - val_acc: 0.5164
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 38s - loss: 6.3547 - acc: 0.5561 - val_loss: 6.4622 - val_acc: 0.5206
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 38s - loss: 6.3586 - acc: 0.5548 - val_loss: 6.4753 - val_acc: 0.5182
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 38s - loss: 6.3542 - acc: 0.5564 - val_loss: 6.4769 - val_acc: 0.5190
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 38s - loss: 6.3546 - acc: 0.5564 - val_loss: 6.4633 - val_acc: 0.5192
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 38s - loss: 6.3556 - acc: 0.5573 - val_loss: 6.4774 - val_acc: 0.5138
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 38s - loss: 6.3588 - acc: 0.5541 - val_loss: 6.4561 - val_acc: 0.5200
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc improved from 0.52280 to 0.52860, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_5.hdf5
 - 39s - loss: 6.3575 - acc: 0.5549 - val_loss: 6.4497 - val_acc: 0.5286
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 38s - loss: 6.3551 - acc: 0.5560 - val_loss: 6.4837 - val_acc: 0.5118
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 38s - loss: 6.3544 - acc: 0.5567 - val_loss: 6.4779 - val_acc: 0.5188
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 38s - loss: 6.3582 - acc: 0.5548 - val_loss: 6.4728 - val_acc: 0.5180
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 38s - loss: 6.3542 - acc: 0.5573 - val_loss: 6.4631 - val_acc: 0.5210
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 38s - loss: 6.3569 - acc: 0.5564 - val_loss: 6.4603 - val_acc: 0.5140
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 38s - loss: 6.3546 - acc: 0.5554 - val_loss: 6.4783 - val_acc: 0.5144
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 38s - loss: 6.3527 - acc: 0.5576 - val_loss: 6.4747 - val_acc: 0.5216
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 38s - loss: 6.3507 - acc: 0.5584 - val_loss: 6.4801 - val_acc: 0.5078
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 38s - loss: 6.3557 - acc: 0.5557 - val_loss: 6.4684 - val_acc: 0.5144
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 38s - loss: 6.3553 - acc: 0.5554 - val_loss: 6.4708 - val_acc: 0.5194
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 38s - loss: 6.3560 - acc: 0.5552 - val_loss: 6.4807 - val_acc: 0.5112
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 38s - loss: 6.3559 - acc: 0.5534 - val_loss: 6.4617 - val_acc: 0.5136
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 38s - loss: 6.3544 - acc: 0.5585 - val_loss: 6.4851 - val_acc: 0.5162
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 38s - loss: 6.3547 - acc: 0.5563 - val_loss: 6.4841 - val_acc: 0.5098
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 38s - loss: 6.3513 - acc: 0.5597 - val_loss: 6.4840 - val_acc: 0.5124
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 38s - loss: 6.3553 - acc: 0.5560 - val_loss: 6.4960 - val_acc: 0.5060
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 38s - loss: 6.3561 - acc: 0.5558 - val_loss: 6.4618 - val_acc: 0.5218
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 38s - loss: 6.3529 - acc: 0.5531 - val_loss: 6.4656 - val_acc: 0.5160
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 38s - loss: 6.3540 - acc: 0.5554 - val_loss: 6.4772 - val_acc: 0.5252
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 38s - loss: 6.3532 - acc: 0.5562 - val_loss: 6.4856 - val_acc: 0.5142
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 38s - loss: 6.3525 - acc: 0.5578 - val_loss: 6.4679 - val_acc: 0.5174
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 38s - loss: 6.3530 - acc: 0.5572 - val_loss: 6.4714 - val_acc: 0.5166
Done

