Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
quantized_conv2d_1 (QuantizedCo (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_1[0][0]         
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_2 (QuantizedCo (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_2[0][0]         
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_3 (QuantizedCo (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_3[0][0]         
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_4 (QuantizedCo (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_4[0][0]         
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_5 (QuantizedCo (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_5[0][0]         
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_6 (QuantizedCo (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_6[0][0]         
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_7 (QuantizedCo (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_7[0][0]         
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_8 (QuantizedCo (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_8[0][0]         
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_9 (QuantizedCo (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_9[0][0]         
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_10 (QuantizedC (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          quantized_conv2d_10[0][0]        
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_11 (QuantizedC (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          quantized_conv2d_11[0][0]        
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_12 (QuantizedC (None, 16, 16, 32)   4640        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_12[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_13 (QuantizedC (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
quantized_conv2d_14 (QuantizedC (None, 16, 16, 32)   544         activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_13[0][0]        
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           quantized_conv2d_14[0][0]        
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_15 (QuantizedC (None, 16, 16, 32)   9248        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_15[0][0]        
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_16 (QuantizedC (None, 16, 16, 32)   9248        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_16[0][0]        
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 32)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_17 (QuantizedC (None, 16, 16, 32)   9248        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_17[0][0]        
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_18 (QuantizedC (None, 16, 16, 32)   9248        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_18[0][0]        
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 32)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_19 (QuantizedC (None, 16, 16, 32)   9248        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_19[0][0]        
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_20 (QuantizedC (None, 16, 16, 32)   9248        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_20[0][0]        
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 32)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_21 (QuantizedC (None, 16, 16, 32)   9248        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_21[0][0]        
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_22 (QuantizedC (None, 16, 16, 32)   9248        activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_22[0][0]        
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           activation_19[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
quantized_conv2d_23 (QuantizedC (None, 8, 8, 64)     18496       activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_23[0][0]        
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_24 (QuantizedC (None, 8, 8, 64)     36928       activation_22[0][0]              
__________________________________________________________________________________________________
quantized_conv2d_25 (QuantizedC (None, 8, 8, 64)     2112        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_24[0][0]        
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 64)     0           quantized_conv2d_25[0][0]        
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     
__________________________________________________________________________________________________
quantized_conv2d_26 (QuantizedC (None, 8, 8, 64)     36928       activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_26[0][0]        
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_27 (QuantizedC (None, 8, 8, 64)     36928       activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_27[0][0]        
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 64)     0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     
__________________________________________________________________________________________________
quantized_conv2d_28 (QuantizedC (None, 8, 8, 64)     36928       activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_28[0][0]        
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_29 (QuantizedC (None, 8, 8, 64)     36928       activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_29[0][0]        
__________________________________________________________________________________________________
add_13 (Add)                    (None, 8, 8, 64)     0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     
__________________________________________________________________________________________________
quantized_conv2d_30 (QuantizedC (None, 8, 8, 64)     36928       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_30[0][0]        
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_31 (QuantizedC (None, 8, 8, 64)     36928       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_31[0][0]        
__________________________________________________________________________________________________
add_14 (Add)                    (None, 8, 8, 64)     0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     
__________________________________________________________________________________________________
quantized_conv2d_32 (QuantizedC (None, 8, 8, 64)     36928       activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_32[0][0]        
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_33 (QuantizedC (None, 8, 8, 64)     36928       activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_33[0][0]        
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 8, 64)     0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_31[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
quantized_dense_2 (QuantizedDen (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 470,218
Trainable params: 467,946
Non-trainable params: 2,272
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.09500, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 57s - loss: 17.6836 - acc: 0.1017 - val_loss: 17.6318 - val_acc: 0.0950
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.09500 to 0.09660, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 17.6068 - acc: 0.1006 - val_loss: 17.5920 - val_acc: 0.0966
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc improved from 0.09660 to 0.10020, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 17.5650 - acc: 0.1015 - val_loss: 17.5459 - val_acc: 0.1002
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.10020 to 0.10500, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 17.5234 - acc: 0.0976 - val_loss: 17.5035 - val_acc: 0.1050
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc did not improve
 - 38s - loss: 17.4814 - acc: 0.1003 - val_loss: 17.4605 - val_acc: 0.1022
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc did not improve
 - 38s - loss: 17.4394 - acc: 0.1006 - val_loss: 17.4204 - val_acc: 0.1016
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc did not improve
 - 38s - loss: 17.3991 - acc: 0.1000 - val_loss: 17.3775 - val_acc: 0.1032
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc did not improve
 - 37s - loss: 17.3575 - acc: 0.0978 - val_loss: 17.3362 - val_acc: 0.1006
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 38s - loss: 17.3145 - acc: 0.1010 - val_loss: 17.2944 - val_acc: 0.0960
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 37s - loss: 17.2732 - acc: 0.1002 - val_loss: 17.2550 - val_acc: 0.0966
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 38s - loss: 17.2314 - acc: 0.0995 - val_loss: 17.2114 - val_acc: 0.0936
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 38s - loss: 17.1880 - acc: 0.0999 - val_loss: 17.1688 - val_acc: 0.0972
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc did not improve
 - 38s - loss: 17.1456 - acc: 0.1009 - val_loss: 17.1245 - val_acc: 0.1012
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 38s - loss: 17.1019 - acc: 0.1003 - val_loss: 17.0796 - val_acc: 0.0982
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc did not improve
 - 38s - loss: 17.0604 - acc: 0.0998 - val_loss: 17.0386 - val_acc: 0.0886
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 38s - loss: 17.0166 - acc: 0.0985 - val_loss: 16.9929 - val_acc: 0.1006
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 37s - loss: 16.9727 - acc: 0.1001 - val_loss: 16.9515 - val_acc: 0.1008
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 38s - loss: 16.9283 - acc: 0.0983 - val_loss: 16.9091 - val_acc: 0.0996
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 37s - loss: 16.8839 - acc: 0.0993 - val_loss: 16.8598 - val_acc: 0.1034
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 38s - loss: 16.8379 - acc: 0.1008 - val_loss: 16.8180 - val_acc: 0.1022
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 37s - loss: 16.7927 - acc: 0.0993 - val_loss: 16.7669 - val_acc: 0.1006
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 38s - loss: 16.7446 - acc: 0.1021 - val_loss: 16.7196 - val_acc: 0.0998
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc improved from 0.10500 to 0.18440, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 16.6443 - acc: 0.1432 - val_loss: 16.5640 - val_acc: 0.1844
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc improved from 0.18440 to 0.22860, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 16.4992 - acc: 0.2062 - val_loss: 16.4635 - val_acc: 0.2286
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc improved from 0.22860 to 0.23300, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 16.4129 - acc: 0.2288 - val_loss: 16.3834 - val_acc: 0.2330
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc improved from 0.23300 to 0.23580, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 16.3565 - acc: 0.2416 - val_loss: 16.3343 - val_acc: 0.2358
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc improved from 0.23580 to 0.24500, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 16.2966 - acc: 0.2472 - val_loss: 16.2820 - val_acc: 0.2450
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc improved from 0.24500 to 0.24600, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 16.2431 - acc: 0.2550 - val_loss: 16.2413 - val_acc: 0.2460
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc improved from 0.24600 to 0.25780, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 16.1918 - acc: 0.2613 - val_loss: 16.1702 - val_acc: 0.2578
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc improved from 0.25780 to 0.26220, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 16.1361 - acc: 0.2651 - val_loss: 16.1194 - val_acc: 0.2622
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc improved from 0.26220 to 0.26660, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 16.0752 - acc: 0.2713 - val_loss: 16.0642 - val_acc: 0.2666
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc improved from 0.26660 to 0.26840, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 16.0081 - acc: 0.2796 - val_loss: 15.9942 - val_acc: 0.2684
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc improved from 0.26840 to 0.28600, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 15.9538 - acc: 0.2896 - val_loss: 15.9366 - val_acc: 0.2860
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc improved from 0.28600 to 0.29720, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 15.8960 - acc: 0.2987 - val_loss: 15.8642 - val_acc: 0.2972
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 37s - loss: 15.8537 - acc: 0.3035 - val_loss: 15.8378 - val_acc: 0.2892
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc improved from 0.29720 to 0.30500, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 15.8022 - acc: 0.3081 - val_loss: 15.7906 - val_acc: 0.3050
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc improved from 0.30500 to 0.31580, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 15.7495 - acc: 0.3200 - val_loss: 15.7286 - val_acc: 0.3158
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc improved from 0.31580 to 0.32420, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 15.6971 - acc: 0.3304 - val_loss: 15.6900 - val_acc: 0.3242
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc improved from 0.32420 to 0.34360, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 15.6476 - acc: 0.3387 - val_loss: 15.6304 - val_acc: 0.3436
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 37s - loss: 15.5994 - acc: 0.3509 - val_loss: 15.5895 - val_acc: 0.3424
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc improved from 0.34360 to 0.35560, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 15.5469 - acc: 0.3601 - val_loss: 15.5234 - val_acc: 0.3556
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc improved from 0.35560 to 0.36880, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 15.4998 - acc: 0.3701 - val_loss: 15.4766 - val_acc: 0.3688
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 37s - loss: 15.4626 - acc: 0.3751 - val_loss: 15.4695 - val_acc: 0.3548
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc improved from 0.36880 to 0.38580, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 15.4119 - acc: 0.3854 - val_loss: 15.3917 - val_acc: 0.3858
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 37s - loss: 15.3685 - acc: 0.3925 - val_loss: 15.3614 - val_acc: 0.3814
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc improved from 0.38580 to 0.38760, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 15.3257 - acc: 0.4025 - val_loss: 15.3291 - val_acc: 0.3876
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc improved from 0.38760 to 0.40480, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 15.2818 - acc: 0.4091 - val_loss: 15.2644 - val_acc: 0.4048
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc improved from 0.40480 to 0.41580, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 15.2487 - acc: 0.4155 - val_loss: 15.2179 - val_acc: 0.4158
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 38s - loss: 15.2107 - acc: 0.4240 - val_loss: 15.2593 - val_acc: 0.3970
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 37s - loss: 15.1756 - acc: 0.4278 - val_loss: 15.1798 - val_acc: 0.4138
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc improved from 0.41580 to 0.42740, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 15.1378 - acc: 0.4347 - val_loss: 15.1262 - val_acc: 0.4274
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 38s - loss: 15.1041 - acc: 0.4415 - val_loss: 15.1537 - val_acc: 0.4202
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 38s - loss: 15.0743 - acc: 0.4459 - val_loss: 15.1047 - val_acc: 0.4258
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc improved from 0.42740 to 0.44000, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 15.0451 - acc: 0.4499 - val_loss: 15.0618 - val_acc: 0.4400
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc improved from 0.44000 to 0.44800, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 15.0087 - acc: 0.4572 - val_loss: 15.0301 - val_acc: 0.4480
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc improved from 0.44800 to 0.45420, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.9807 - acc: 0.4640 - val_loss: 14.9893 - val_acc: 0.4542
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc improved from 0.45420 to 0.46980, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.9485 - acc: 0.4670 - val_loss: 14.9349 - val_acc: 0.4698
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc improved from 0.46980 to 0.47380, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.9181 - acc: 0.4732 - val_loss: 14.9129 - val_acc: 0.4738
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 37s - loss: 14.8868 - acc: 0.4816 - val_loss: 15.0328 - val_acc: 0.4286
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 38s - loss: 14.8626 - acc: 0.4801 - val_loss: 14.8987 - val_acc: 0.4636
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 37s - loss: 14.8331 - acc: 0.4884 - val_loss: 14.8763 - val_acc: 0.4662
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc improved from 0.47380 to 0.48100, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.8024 - acc: 0.4917 - val_loss: 14.8274 - val_acc: 0.4810
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 37s - loss: 14.7836 - acc: 0.4944 - val_loss: 14.8596 - val_acc: 0.4564
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc improved from 0.48100 to 0.48180, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.7554 - acc: 0.5004 - val_loss: 14.7780 - val_acc: 0.4818
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc improved from 0.48180 to 0.49940, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.7293 - acc: 0.5045 - val_loss: 14.7461 - val_acc: 0.4994
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 38s - loss: 14.7032 - acc: 0.5109 - val_loss: 14.7257 - val_acc: 0.4946
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 37s - loss: 14.6803 - acc: 0.5120 - val_loss: 14.8329 - val_acc: 0.4548
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 38s - loss: 14.6477 - acc: 0.5218 - val_loss: 14.7043 - val_acc: 0.4934
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc improved from 0.49940 to 0.50260, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.6308 - acc: 0.5208 - val_loss: 14.6701 - val_acc: 0.5026
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 37s - loss: 14.6071 - acc: 0.5266 - val_loss: 14.6813 - val_acc: 0.4990
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc improved from 0.50260 to 0.50600, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.5799 - acc: 0.5347 - val_loss: 14.6312 - val_acc: 0.5060
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc improved from 0.50600 to 0.51080, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.5559 - acc: 0.5363 - val_loss: 14.6022 - val_acc: 0.5108
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc improved from 0.51080 to 0.52000, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.5353 - acc: 0.5372 - val_loss: 14.5922 - val_acc: 0.5200
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 37s - loss: 14.5155 - acc: 0.5409 - val_loss: 14.6180 - val_acc: 0.5010
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc improved from 0.52000 to 0.52200, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.4930 - acc: 0.5450 - val_loss: 14.5385 - val_acc: 0.5220
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 37s - loss: 14.4658 - acc: 0.5512 - val_loss: 14.6010 - val_acc: 0.5014
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc improved from 0.52200 to 0.53680, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.4474 - acc: 0.5518 - val_loss: 14.4815 - val_acc: 0.5368
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 37s - loss: 14.4260 - acc: 0.5556 - val_loss: 14.5836 - val_acc: 0.4964
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 37s - loss: 14.4014 - acc: 0.5594 - val_loss: 14.4705 - val_acc: 0.5308
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 38s - loss: 14.3843 - acc: 0.5604 - val_loss: 14.4862 - val_acc: 0.5238
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc improved from 0.53680 to 0.54860, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.3650 - acc: 0.5656 - val_loss: 14.3882 - val_acc: 0.5486
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.54860 to 0.56420, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.3238 - acc: 0.5777 - val_loss: 14.3682 - val_acc: 0.5642
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.56420 to 0.57280, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.3175 - acc: 0.5838 - val_loss: 14.3353 - val_acc: 0.5728
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc did not improve
 - 38s - loss: 14.3105 - acc: 0.5828 - val_loss: 14.3978 - val_acc: 0.5518
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 38s - loss: 14.3078 - acc: 0.5832 - val_loss: 14.3399 - val_acc: 0.5664
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 38s - loss: 14.3044 - acc: 0.5815 - val_loss: 14.3255 - val_acc: 0.5668
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 37s - loss: 14.2996 - acc: 0.5816 - val_loss: 14.3437 - val_acc: 0.5668
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 37s - loss: 14.2926 - acc: 0.5825 - val_loss: 14.3382 - val_acc: 0.5658
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 37s - loss: 14.2924 - acc: 0.5816 - val_loss: 14.3371 - val_acc: 0.5670
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc improved from 0.57280 to 0.57420, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.2899 - acc: 0.5832 - val_loss: 14.3166 - val_acc: 0.5742
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 37s - loss: 14.2830 - acc: 0.5840 - val_loss: 14.3496 - val_acc: 0.5614
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 37s - loss: 14.2754 - acc: 0.5855 - val_loss: 14.3137 - val_acc: 0.5742
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 37s - loss: 14.2711 - acc: 0.5862 - val_loss: 14.3034 - val_acc: 0.5736
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc improved from 0.57420 to 0.57780, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.2646 - acc: 0.5875 - val_loss: 14.2925 - val_acc: 0.5778
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc improved from 0.57780 to 0.58140, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.2667 - acc: 0.5873 - val_loss: 14.2966 - val_acc: 0.5814
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 37s - loss: 14.2602 - acc: 0.5835 - val_loss: 14.3133 - val_acc: 0.5688
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 37s - loss: 14.2591 - acc: 0.5849 - val_loss: 14.3389 - val_acc: 0.5602
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 38s - loss: 14.2502 - acc: 0.5869 - val_loss: 14.2716 - val_acc: 0.5788
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 37s - loss: 14.2465 - acc: 0.5868 - val_loss: 14.3544 - val_acc: 0.5446
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 37s - loss: 14.2453 - acc: 0.5859 - val_loss: 14.4320 - val_acc: 0.5222
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 38s - loss: 14.2422 - acc: 0.5866 - val_loss: 14.2932 - val_acc: 0.5614
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 37s - loss: 14.2355 - acc: 0.5863 - val_loss: 14.2774 - val_acc: 0.5760
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 38s - loss: 14.2276 - acc: 0.5900 - val_loss: 14.2686 - val_acc: 0.5728
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 38s - loss: 14.2258 - acc: 0.5905 - val_loss: 14.2560 - val_acc: 0.5746
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 38s - loss: 14.2251 - acc: 0.5886 - val_loss: 14.2642 - val_acc: 0.5778
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc improved from 0.58140 to 0.58320, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.2220 - acc: 0.5903 - val_loss: 14.2484 - val_acc: 0.5832
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 37s - loss: 14.2103 - acc: 0.5927 - val_loss: 14.2504 - val_acc: 0.5772
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 38s - loss: 14.2099 - acc: 0.5905 - val_loss: 14.2987 - val_acc: 0.5574
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 38s - loss: 14.2094 - acc: 0.5907 - val_loss: 14.2688 - val_acc: 0.5686
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 37s - loss: 14.2047 - acc: 0.5930 - val_loss: 14.2935 - val_acc: 0.5554
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 37s - loss: 14.1981 - acc: 0.5912 - val_loss: 14.2366 - val_acc: 0.5780
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 38s - loss: 14.2018 - acc: 0.5896 - val_loss: 14.2281 - val_acc: 0.5798
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc improved from 0.58320 to 0.58460, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.1921 - acc: 0.5937 - val_loss: 14.2279 - val_acc: 0.5846
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 37s - loss: 14.1882 - acc: 0.5901 - val_loss: 14.2793 - val_acc: 0.5608
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 38s - loss: 14.1851 - acc: 0.5929 - val_loss: 14.2274 - val_acc: 0.5790
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 37s - loss: 14.1842 - acc: 0.5921 - val_loss: 14.2126 - val_acc: 0.5834
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc improved from 0.58460 to 0.58520, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.1803 - acc: 0.5931 - val_loss: 14.2109 - val_acc: 0.5852
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc improved from 0.58520 to 0.59180, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.1737 - acc: 0.5960 - val_loss: 14.2039 - val_acc: 0.5918
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 37s - loss: 14.1662 - acc: 0.5993 - val_loss: 14.2078 - val_acc: 0.5878
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 38s - loss: 14.1640 - acc: 0.5967 - val_loss: 14.2051 - val_acc: 0.5846
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 37s - loss: 14.1654 - acc: 0.5959 - val_loss: 14.1958 - val_acc: 0.5878
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc did not improve
 - 37s - loss: 14.1586 - acc: 0.5992 - val_loss: 14.2077 - val_acc: 0.5804
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 37s - loss: 14.1583 - acc: 0.5987 - val_loss: 14.1980 - val_acc: 0.5846
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 37s - loss: 14.1548 - acc: 0.6005 - val_loss: 14.1934 - val_acc: 0.5826
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 38s - loss: 14.1579 - acc: 0.5987 - val_loss: 14.1955 - val_acc: 0.5820
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 37s - loss: 14.1571 - acc: 0.5978 - val_loss: 14.2005 - val_acc: 0.5788
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 38s - loss: 14.1579 - acc: 0.5975 - val_loss: 14.1928 - val_acc: 0.5892
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 38s - loss: 14.1524 - acc: 0.5999 - val_loss: 14.1903 - val_acc: 0.5874
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 38s - loss: 14.1538 - acc: 0.5978 - val_loss: 14.2020 - val_acc: 0.5872
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 37s - loss: 14.1584 - acc: 0.5970 - val_loss: 14.1865 - val_acc: 0.5854
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 37s - loss: 14.1543 - acc: 0.5985 - val_loss: 14.1895 - val_acc: 0.5908
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 37s - loss: 14.1521 - acc: 0.5992 - val_loss: 14.1973 - val_acc: 0.5870
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 37s - loss: 14.1520 - acc: 0.5982 - val_loss: 14.2067 - val_acc: 0.5716
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 37s - loss: 14.1536 - acc: 0.6000 - val_loss: 14.1882 - val_acc: 0.5878
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 37s - loss: 14.1519 - acc: 0.5971 - val_loss: 14.2287 - val_acc: 0.5680
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 37s - loss: 14.1482 - acc: 0.5992 - val_loss: 14.1854 - val_acc: 0.5858
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc improved from 0.59180 to 0.59520, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 38s - loss: 14.1507 - acc: 0.5990 - val_loss: 14.1829 - val_acc: 0.5952
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 37s - loss: 14.1460 - acc: 0.6020 - val_loss: 14.1803 - val_acc: 0.5830
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 38s - loss: 14.1472 - acc: 0.5976 - val_loss: 14.1942 - val_acc: 0.5824
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc improved from 0.59520 to 0.59700, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.1497 - acc: 0.5974 - val_loss: 14.1841 - val_acc: 0.5970
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 37s - loss: 14.1459 - acc: 0.6001 - val_loss: 14.2176 - val_acc: 0.5676
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 38s - loss: 14.1495 - acc: 0.5978 - val_loss: 14.2245 - val_acc: 0.5742
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 37s - loss: 14.1512 - acc: 0.5980 - val_loss: 14.2492 - val_acc: 0.5626
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 37s - loss: 14.1438 - acc: 0.6002 - val_loss: 14.1903 - val_acc: 0.5818
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 37s - loss: 14.1463 - acc: 0.6002 - val_loss: 14.1887 - val_acc: 0.5834
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 37s - loss: 14.1474 - acc: 0.5984 - val_loss: 14.1776 - val_acc: 0.5840
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 37s - loss: 14.1477 - acc: 0.5974 - val_loss: 14.2026 - val_acc: 0.5806
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 37s - loss: 14.1450 - acc: 0.6000 - val_loss: 14.1919 - val_acc: 0.5852
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 37s - loss: 14.1468 - acc: 0.5999 - val_loss: 14.1989 - val_acc: 0.5850
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 37s - loss: 14.1444 - acc: 0.5988 - val_loss: 14.1744 - val_acc: 0.5922
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 38s - loss: 14.1497 - acc: 0.5965 - val_loss: 14.1818 - val_acc: 0.5904
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 37s - loss: 14.1413 - acc: 0.6020 - val_loss: 14.1784 - val_acc: 0.5866
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 37s - loss: 14.1496 - acc: 0.5981 - val_loss: 14.1811 - val_acc: 0.5852
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc improved from 0.59700 to 0.59840, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_5.hdf5
 - 39s - loss: 14.1446 - acc: 0.5976 - val_loss: 14.1680 - val_acc: 0.5984
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 37s - loss: 14.1417 - acc: 0.5999 - val_loss: 14.1952 - val_acc: 0.5828
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 37s - loss: 14.1445 - acc: 0.5990 - val_loss: 14.1937 - val_acc: 0.5788
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 37s - loss: 14.1400 - acc: 0.6001 - val_loss: 14.1792 - val_acc: 0.5858
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 38s - loss: 14.1458 - acc: 0.5951 - val_loss: 14.1876 - val_acc: 0.5866
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 38s - loss: 14.1374 - acc: 0.6042 - val_loss: 14.1775 - val_acc: 0.5854
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 37s - loss: 14.1431 - acc: 0.5978 - val_loss: 14.1795 - val_acc: 0.5768
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 37s - loss: 14.1403 - acc: 0.5967 - val_loss: 14.1919 - val_acc: 0.5780
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 37s - loss: 14.1410 - acc: 0.5983 - val_loss: 14.1759 - val_acc: 0.5804
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 37s - loss: 14.1409 - acc: 0.5990 - val_loss: 14.1782 - val_acc: 0.5898
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 37s - loss: 14.1401 - acc: 0.5983 - val_loss: 14.1873 - val_acc: 0.5854
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 37s - loss: 14.1405 - acc: 0.6000 - val_loss: 14.1914 - val_acc: 0.5854
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 37s - loss: 14.1400 - acc: 0.6002 - val_loss: 14.1817 - val_acc: 0.5802
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 37s - loss: 14.1401 - acc: 0.5974 - val_loss: 14.1682 - val_acc: 0.5890
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 38s - loss: 14.1343 - acc: 0.6018 - val_loss: 14.1840 - val_acc: 0.5858
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 37s - loss: 14.1364 - acc: 0.6010 - val_loss: 14.2243 - val_acc: 0.5720
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 37s - loss: 14.1394 - acc: 0.5972 - val_loss: 14.2052 - val_acc: 0.5734
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 38s - loss: 14.1398 - acc: 0.5990 - val_loss: 14.2253 - val_acc: 0.5772
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 37s - loss: 14.1364 - acc: 0.6020 - val_loss: 14.1873 - val_acc: 0.5852
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 38s - loss: 14.1369 - acc: 0.5999 - val_loss: 14.1775 - val_acc: 0.5862
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 37s - loss: 14.1390 - acc: 0.5972 - val_loss: 14.1701 - val_acc: 0.5842
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 38s - loss: 14.1404 - acc: 0.5982 - val_loss: 14.2210 - val_acc: 0.5728
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 37s - loss: 14.1398 - acc: 0.6014 - val_loss: 14.1658 - val_acc: 0.5904
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 37s - loss: 14.1372 - acc: 0.6017 - val_loss: 14.1683 - val_acc: 0.5904
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 37s - loss: 14.1410 - acc: 0.6000 - val_loss: 14.1788 - val_acc: 0.5816
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 37s - loss: 14.1353 - acc: 0.5990 - val_loss: 14.1960 - val_acc: 0.5860
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 38s - loss: 14.1402 - acc: 0.5993 - val_loss: 14.1803 - val_acc: 0.5894
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 37s - loss: 14.1371 - acc: 0.6012 - val_loss: 14.1870 - val_acc: 0.5880
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 38s - loss: 14.1384 - acc: 0.5986 - val_loss: 14.1988 - val_acc: 0.5758
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 38s - loss: 14.1382 - acc: 0.5997 - val_loss: 14.1789 - val_acc: 0.5858
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 38s - loss: 14.1369 - acc: 0.5989 - val_loss: 14.1729 - val_acc: 0.5966
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 38s - loss: 14.1363 - acc: 0.5989 - val_loss: 14.1721 - val_acc: 0.5792
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 37s - loss: 14.1391 - acc: 0.5990 - val_loss: 14.1779 - val_acc: 0.5866
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 38s - loss: 14.1383 - acc: 0.5995 - val_loss: 14.1877 - val_acc: 0.5858
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 37s - loss: 14.1339 - acc: 0.6015 - val_loss: 14.2057 - val_acc: 0.5734
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 37s - loss: 14.1375 - acc: 0.5988 - val_loss: 14.1919 - val_acc: 0.5858
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 38s - loss: 14.1399 - acc: 0.5982 - val_loss: 14.2359 - val_acc: 0.5628
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 38s - loss: 14.1384 - acc: 0.6012 - val_loss: 14.1915 - val_acc: 0.5790
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 37s - loss: 14.1366 - acc: 0.6011 - val_loss: 14.2133 - val_acc: 0.5792
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 38s - loss: 14.1395 - acc: 0.5979 - val_loss: 14.1777 - val_acc: 0.5796
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 38s - loss: 14.1377 - acc: 0.6003 - val_loss: 14.1798 - val_acc: 0.5912
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 38s - loss: 14.1375 - acc: 0.6000 - val_loss: 14.1758 - val_acc: 0.5884
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 38s - loss: 14.1356 - acc: 0.6006 - val_loss: 14.2249 - val_acc: 0.5654
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 38s - loss: 14.1373 - acc: 0.5999 - val_loss: 14.2329 - val_acc: 0.5668
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 38s - loss: 14.1379 - acc: 0.5987 - val_loss: 14.1781 - val_acc: 0.5832
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 39s - loss: 14.1389 - acc: 0.6006 - val_loss: 14.1983 - val_acc: 0.5766
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 38s - loss: 14.1388 - acc: 0.6007 - val_loss: 14.1894 - val_acc: 0.5820
Done

