Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
quantized_conv2d_1 (QuantizedCo (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_1[0][0]         
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_2 (QuantizedCo (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_2[0][0]         
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_3 (QuantizedCo (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_3[0][0]         
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_4 (QuantizedCo (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_4[0][0]         
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_5 (QuantizedCo (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_5[0][0]         
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_6 (QuantizedCo (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_6[0][0]         
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_7 (QuantizedCo (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_7[0][0]         
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_8 (QuantizedCo (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_8[0][0]         
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_9 (QuantizedCo (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_9[0][0]         
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_10 (QuantizedC (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          quantized_conv2d_10[0][0]        
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_11 (QuantizedC (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          quantized_conv2d_11[0][0]        
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_12 (QuantizedC (None, 16, 16, 32)   4640        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_12[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_13 (QuantizedC (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
quantized_conv2d_14 (QuantizedC (None, 16, 16, 32)   544         activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_13[0][0]        
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           quantized_conv2d_14[0][0]        
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_15 (QuantizedC (None, 16, 16, 32)   9248        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_15[0][0]        
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_16 (QuantizedC (None, 16, 16, 32)   9248        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_16[0][0]        
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 32)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 32)   0           add_7[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_17 (QuantizedC (None, 16, 16, 32)   9248        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_17[0][0]        
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_18 (QuantizedC (None, 16, 16, 32)   9248        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_18[0][0]        
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 32)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 32)   0           add_8[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_19 (QuantizedC (None, 16, 16, 32)   9248        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_19[0][0]        
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_20 (QuantizedC (None, 16, 16, 32)   9248        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_20[0][0]        
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 32)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_21 (QuantizedC (None, 16, 16, 32)   9248        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_21[0][0]        
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_22 (QuantizedC (None, 16, 16, 32)   9248        activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_22[0][0]        
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           activation_19[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
quantized_conv2d_23 (QuantizedC (None, 8, 8, 64)     18496       activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_23[0][0]        
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 64)     0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_24 (QuantizedC (None, 8, 8, 64)     36928       activation_22[0][0]              
__________________________________________________________________________________________________
quantized_conv2d_25 (QuantizedC (None, 8, 8, 64)     2112        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_24[0][0]        
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 64)     0           quantized_conv2d_25[0][0]        
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 64)     0           add_11[0][0]                     
__________________________________________________________________________________________________
quantized_conv2d_26 (QuantizedC (None, 8, 8, 64)     36928       activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_26[0][0]        
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 64)     0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_27 (QuantizedC (None, 8, 8, 64)     36928       activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_27[0][0]        
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 64)     0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     
__________________________________________________________________________________________________
quantized_conv2d_28 (QuantizedC (None, 8, 8, 64)     36928       activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_28[0][0]        
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_29 (QuantizedC (None, 8, 8, 64)     36928       activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_29[0][0]        
__________________________________________________________________________________________________
add_13 (Add)                    (None, 8, 8, 64)     0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     
__________________________________________________________________________________________________
quantized_conv2d_30 (QuantizedC (None, 8, 8, 64)     36928       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_30[0][0]        
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_31 (QuantizedC (None, 8, 8, 64)     36928       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_31[0][0]        
__________________________________________________________________________________________________
add_14 (Add)                    (None, 8, 8, 64)     0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     
__________________________________________________________________________________________________
quantized_conv2d_32 (QuantizedC (None, 8, 8, 64)     36928       activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_32[0][0]        
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_33 (QuantizedC (None, 8, 8, 64)     36928       activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_33[0][0]        
__________________________________________________________________________________________________
add_15 (Add)                    (None, 8, 8, 64)     0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_31[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
quantized_dense_2 (QuantizedDen (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 470,218
Trainable params: 467,946
Non-trainable params: 2,272
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.10880, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 56s - loss: 17.7157 - acc: 0.1028 - val_loss: 17.6272 - val_acc: 0.1088
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc did not improve
 - 37s - loss: 17.5823 - acc: 0.1017 - val_loss: 17.5429 - val_acc: 0.1040
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc did not improve
 - 37s - loss: 17.5052 - acc: 0.1064 - val_loss: 17.5190 - val_acc: 0.0994
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.10880 to 0.13520, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 17.4045 - acc: 0.1289 - val_loss: 17.3399 - val_acc: 0.1352
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc improved from 0.13520 to 0.17420, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 17.2498 - acc: 0.1668 - val_loss: 17.2201 - val_acc: 0.1742
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc improved from 0.17420 to 0.19060, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 17.1257 - acc: 0.1922 - val_loss: 17.0724 - val_acc: 0.1906
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.19060 to 0.22080, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 17.0173 - acc: 0.2114 - val_loss: 16.9681 - val_acc: 0.2208
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc improved from 0.22080 to 0.25080, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 16.9117 - acc: 0.2308 - val_loss: 16.8443 - val_acc: 0.2508
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 37s - loss: 16.8086 - acc: 0.2451 - val_loss: 16.8140 - val_acc: 0.2330
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc improved from 0.25080 to 0.25200, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 39s - loss: 16.7098 - acc: 0.2586 - val_loss: 16.6748 - val_acc: 0.2520
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc improved from 0.25200 to 0.26740, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 16.6054 - acc: 0.2693 - val_loss: 16.5775 - val_acc: 0.2674
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 37s - loss: 16.5019 - acc: 0.2788 - val_loss: 16.4709 - val_acc: 0.2634
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc improved from 0.26740 to 0.28660, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 16.3957 - acc: 0.2857 - val_loss: 16.3500 - val_acc: 0.2866
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc improved from 0.28660 to 0.29480, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 16.2946 - acc: 0.2950 - val_loss: 16.2723 - val_acc: 0.2948
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc improved from 0.29480 to 0.30300, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 16.1819 - acc: 0.3047 - val_loss: 16.1656 - val_acc: 0.3030
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 37s - loss: 16.0806 - acc: 0.3134 - val_loss: 16.0603 - val_acc: 0.2996
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc improved from 0.30300 to 0.30560, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 15.9850 - acc: 0.3184 - val_loss: 15.9879 - val_acc: 0.3056
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc improved from 0.30560 to 0.33780, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 15.8998 - acc: 0.3201 - val_loss: 15.8257 - val_acc: 0.3378
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 37s - loss: 15.7949 - acc: 0.3299 - val_loss: 15.7822 - val_acc: 0.3242
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc improved from 0.33780 to 0.34680, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 15.6972 - acc: 0.3352 - val_loss: 15.6391 - val_acc: 0.3468
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 37s - loss: 15.5770 - acc: 0.3511 - val_loss: 15.5435 - val_acc: 0.3428
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 37s - loss: 15.4736 - acc: 0.3583 - val_loss: 15.4563 - val_acc: 0.3448
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc improved from 0.34680 to 0.36680, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 15.3995 - acc: 0.3567 - val_loss: 15.3311 - val_acc: 0.3668
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 37s - loss: 15.2933 - acc: 0.3669 - val_loss: 15.3269 - val_acc: 0.3494
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc improved from 0.36680 to 0.37320, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 15.2042 - acc: 0.3690 - val_loss: 15.1433 - val_acc: 0.3732
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 37s - loss: 15.1009 - acc: 0.3766 - val_loss: 15.0794 - val_acc: 0.3658
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 37s - loss: 15.0224 - acc: 0.3755 - val_loss: 15.0970 - val_acc: 0.3328
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc improved from 0.37320 to 0.38980, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 14.9363 - acc: 0.3753 - val_loss: 14.8626 - val_acc: 0.3898
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 37s - loss: 14.8141 - acc: 0.3917 - val_loss: 14.7809 - val_acc: 0.3866
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 37s - loss: 14.7214 - acc: 0.3954 - val_loss: 14.7138 - val_acc: 0.3860
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 37s - loss: 14.6345 - acc: 0.3977 - val_loss: 14.6507 - val_acc: 0.3794
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 37s - loss: 14.5214 - acc: 0.4101 - val_loss: 14.5324 - val_acc: 0.3870
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc improved from 0.38980 to 0.40280, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 14.4246 - acc: 0.4175 - val_loss: 14.4218 - val_acc: 0.4028
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc improved from 0.40280 to 0.40920, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 14.3257 - acc: 0.4236 - val_loss: 14.3037 - val_acc: 0.4092
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc improved from 0.40920 to 0.42040, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 14.2510 - acc: 0.4229 - val_loss: 14.2327 - val_acc: 0.4204
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 37s - loss: 14.1549 - acc: 0.4351 - val_loss: 14.1401 - val_acc: 0.4198
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 37s - loss: 14.0670 - acc: 0.4418 - val_loss: 14.1447 - val_acc: 0.3940
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc improved from 0.42040 to 0.43200, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 13.9899 - acc: 0.4446 - val_loss: 14.0001 - val_acc: 0.4320
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 37s - loss: 13.9095 - acc: 0.4465 - val_loss: 13.9157 - val_acc: 0.4274
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 37s - loss: 13.8350 - acc: 0.4504 - val_loss: 13.9542 - val_acc: 0.4024
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 37s - loss: 13.7594 - acc: 0.4577 - val_loss: 13.8405 - val_acc: 0.4166
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc improved from 0.43200 to 0.44960, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 13.6853 - acc: 0.4600 - val_loss: 13.6901 - val_acc: 0.4496
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 37s - loss: 13.6078 - acc: 0.4654 - val_loss: 13.6298 - val_acc: 0.4452
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc improved from 0.44960 to 0.45600, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 13.5261 - acc: 0.4756 - val_loss: 13.5411 - val_acc: 0.4560
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 37s - loss: 13.4493 - acc: 0.4796 - val_loss: 13.5259 - val_acc: 0.4364
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 37s - loss: 13.3825 - acc: 0.4810 - val_loss: 13.4285 - val_acc: 0.4510
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc improved from 0.45600 to 0.45640, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 13.3166 - acc: 0.4850 - val_loss: 13.3701 - val_acc: 0.4564
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 37s - loss: 13.2471 - acc: 0.4912 - val_loss: 13.3294 - val_acc: 0.4518
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc improved from 0.45640 to 0.46660, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 13.1685 - acc: 0.4997 - val_loss: 13.2172 - val_acc: 0.4666
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 37s - loss: 13.0885 - acc: 0.5102 - val_loss: 13.1931 - val_acc: 0.4642
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc improved from 0.46660 to 0.47080, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 13.0258 - acc: 0.5130 - val_loss: 13.1281 - val_acc: 0.4708
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc improved from 0.47080 to 0.47440, saving model to ./weights/RESNET_CIFAR-10_full-qnn_4b_4b_5.hdf5
 - 38s - loss: 12.9615 - acc: 0.5188 - val_loss: 13.0339 - val_acc: 0.4744
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 37s - loss: 12.9027 - acc: 0.5199 - val_loss: 13.0209 - val_acc: 0.4734
