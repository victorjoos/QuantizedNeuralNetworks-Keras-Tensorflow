Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
ternary_conv2d_1 (TernaryConv2D (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_2 (TernaryConv2D (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_2[0][0]           
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_3 (TernaryConv2D (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_3[0][0]           
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_4 (TernaryConv2D (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_4[0][0]           
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_5 (TernaryConv2D (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_5[0][0]           
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_6 (TernaryConv2D (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_6[0][0]           
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_7 (TernaryConv2D (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_7[0][0]           
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_8 (TernaryConv2D (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_8[0][0]           
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_9 (TernaryConv2D (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_9[0][0]           
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_10 (TernaryConv2 (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_10[0][0]          
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_11 (TernaryConv2 (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_11[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_12 (TernaryConv2 (None, 32, 32, 16)   2320        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_12[0][0]          
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_13 (TernaryConv2 (None, 32, 32, 16)   2320        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_13[0][0]          
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 16)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_14 (TernaryConv2 (None, 32, 32, 16)   2320        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_14[0][0]          
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_15 (TernaryConv2 (None, 32, 32, 16)   2320        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_15[0][0]          
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 16)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_16 (TernaryConv2 (None, 32, 32, 16)   2320        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_16[0][0]          
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_17 (TernaryConv2 (None, 32, 32, 16)   2320        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_17[0][0]          
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 16)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_18 (TernaryConv2 (None, 32, 32, 16)   2320        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_18[0][0]          
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_19 (TernaryConv2 (None, 32, 32, 16)   2320        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_19[0][0]          
__________________________________________________________________________________________________
add_9 (Add)                     (None, 32, 32, 16)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 32, 32, 16)   0           add_9[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_20 (TernaryConv2 (None, 32, 32, 16)   2320        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_20[0][0]          
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_21 (TernaryConv2 (None, 32, 32, 16)   2320        activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_21[0][0]          
__________________________________________________________________________________________________
add_10 (Add)                    (None, 32, 32, 16)   0           activation_19[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 16)   0           add_10[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_22 (TernaryConv2 (None, 16, 16, 32)   4640        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_22[0][0]          
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_23 (TernaryConv2 (None, 16, 16, 32)   9248        activation_22[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_24 (TernaryConv2 (None, 16, 16, 32)   544         activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_23[0][0]          
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 32)   0           ternary_conv2d_24[0][0]          
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_25 (TernaryConv2 (None, 16, 16, 32)   9248        activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_25[0][0]          
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_26 (TernaryConv2 (None, 16, 16, 32)   9248        activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_26[0][0]          
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 32)   0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 16, 16, 32)   0           add_12[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_27 (TernaryConv2 (None, 16, 16, 32)   9248        activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_27[0][0]          
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_28 (TernaryConv2 (None, 16, 16, 32)   9248        activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_28[0][0]          
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 32)   0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_29 (TernaryConv2 (None, 16, 16, 32)   9248        activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_29[0][0]          
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_30 (TernaryConv2 (None, 16, 16, 32)   9248        activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_30[0][0]          
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 32)   0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_31 (TernaryConv2 (None, 16, 16, 32)   9248        activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_31[0][0]          
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_32 (TernaryConv2 (None, 16, 16, 32)   9248        activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_32[0][0]          
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 32)   0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_33 (TernaryConv2 (None, 16, 16, 32)   9248        activation_31[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_33[0][0]          
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_34 (TernaryConv2 (None, 16, 16, 32)   9248        activation_32[0][0]              
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_34[0][0]          
__________________________________________________________________________________________________
add_16 (Add)                    (None, 16, 16, 32)   0           activation_31[0][0]              
                                                                 batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 16, 16, 32)   0           add_16[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_35 (TernaryConv2 (None, 16, 16, 32)   9248        activation_33[0][0]              
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_35[0][0]          
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_36 (TernaryConv2 (None, 16, 16, 32)   9248        activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_36[0][0]          
__________________________________________________________________________________________________
add_17 (Add)                    (None, 16, 16, 32)   0           activation_33[0][0]              
                                                                 batch_normalization_35[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 16, 16, 32)   0           add_17[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_37 (TernaryConv2 (None, 16, 16, 32)   9248        activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_37[0][0]          
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_38 (TernaryConv2 (None, 16, 16, 32)   9248        activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_38[0][0]          
__________________________________________________________________________________________________
add_18 (Add)                    (None, 16, 16, 32)   0           activation_35[0][0]              
                                                                 batch_normalization_37[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 16, 16, 32)   0           add_18[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_39 (TernaryConv2 (None, 16, 16, 32)   9248        activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_39[0][0]          
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 16, 16, 32)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_40 (TernaryConv2 (None, 16, 16, 32)   9248        activation_38[0][0]              
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_40[0][0]          
__________________________________________________________________________________________________
add_19 (Add)                    (None, 16, 16, 32)   0           activation_37[0][0]              
                                                                 batch_normalization_39[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 16, 16, 32)   0           add_19[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_41 (TernaryConv2 (None, 16, 16, 32)   9248        activation_39[0][0]              
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_41[0][0]          
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 16, 16, 32)   0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_42 (TernaryConv2 (None, 16, 16, 32)   9248        activation_40[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_42[0][0]          
__________________________________________________________________________________________________
add_20 (Add)                    (None, 16, 16, 32)   0           activation_39[0][0]              
                                                                 batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 16, 16, 32)   0           add_20[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_43 (TernaryConv2 (None, 8, 8, 64)     18496       activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_43[0][0]          
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_44 (TernaryConv2 (None, 8, 8, 64)     36928       activation_42[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_45 (TernaryConv2 (None, 8, 8, 64)     2112        activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_44[0][0]          
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 8, 64)     0           ternary_conv2d_45[0][0]          
                                                                 batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 8, 8, 64)     0           add_21[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_46 (TernaryConv2 (None, 8, 8, 64)     36928       activation_43[0][0]              
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_46[0][0]          
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_47 (TernaryConv2 (None, 8, 8, 64)     36928       activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_47[0][0]          
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 8, 64)     0           activation_43[0][0]              
                                                                 batch_normalization_45[0][0]     
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 8, 8, 64)     0           add_22[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_48 (TernaryConv2 (None, 8, 8, 64)     36928       activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_48[0][0]          
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_49 (TernaryConv2 (None, 8, 8, 64)     36928       activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_49[0][0]          
__________________________________________________________________________________________________
add_23 (Add)                    (None, 8, 8, 64)     0           activation_45[0][0]              
                                                                 batch_normalization_47[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 8, 8, 64)     0           add_23[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_50 (TernaryConv2 (None, 8, 8, 64)     36928       activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_50[0][0]          
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_51 (TernaryConv2 (None, 8, 8, 64)     36928       activation_48[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_51[0][0]          
__________________________________________________________________________________________________
add_24 (Add)                    (None, 8, 8, 64)     0           activation_47[0][0]              
                                                                 batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 8, 8, 64)     0           add_24[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_52 (TernaryConv2 (None, 8, 8, 64)     36928       activation_49[0][0]              
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_52[0][0]          
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_53 (TernaryConv2 (None, 8, 8, 64)     36928       activation_50[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_53[0][0]          
__________________________________________________________________________________________________
add_25 (Add)                    (None, 8, 8, 64)     0           activation_49[0][0]              
                                                                 batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_54 (TernaryConv2 (None, 8, 8, 64)     36928       activation_51[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_54[0][0]          
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_55 (TernaryConv2 (None, 8, 8, 64)     36928       activation_52[0][0]              
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_55[0][0]          
__________________________________________________________________________________________________
add_26 (Add)                    (None, 8, 8, 64)     0           activation_51[0][0]              
                                                                 batch_normalization_53[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_56 (TernaryConv2 (None, 8, 8, 64)     36928       activation_53[0][0]              
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_56[0][0]          
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_57 (TernaryConv2 (None, 8, 8, 64)     36928       activation_54[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_57[0][0]          
__________________________________________________________________________________________________
add_27 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              
                                                                 batch_normalization_55[0][0]     
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 8, 8, 64)     0           add_27[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_58 (TernaryConv2 (None, 8, 8, 64)     36928       activation_55[0][0]              
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_58[0][0]          
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_59 (TernaryConv2 (None, 8, 8, 64)     36928       activation_56[0][0]              
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_59[0][0]          
__________________________________________________________________________________________________
add_28 (Add)                    (None, 8, 8, 64)     0           activation_55[0][0]              
                                                                 batch_normalization_57[0][0]     
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 8, 8, 64)     0           add_28[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_60 (TernaryConv2 (None, 8, 8, 64)     36928       activation_57[0][0]              
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_60[0][0]          
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 8, 8, 64)     0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_61 (TernaryConv2 (None, 8, 8, 64)     36928       activation_58[0][0]              
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_61[0][0]          
__________________________________________________________________________________________________
add_29 (Add)                    (None, 8, 8, 64)     0           activation_57[0][0]              
                                                                 batch_normalization_59[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 8, 8, 64)     0           add_29[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_62 (TernaryConv2 (None, 8, 8, 64)     36928       activation_59[0][0]              
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_62[0][0]          
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 8, 8, 64)     0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_63 (TernaryConv2 (None, 8, 8, 64)     36928       activation_60[0][0]              
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_63[0][0]          
__________________________________________________________________________________________________
add_30 (Add)                    (None, 8, 8, 64)     0           activation_59[0][0]              
                                                                 batch_normalization_61[0][0]     
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 8, 8, 64)     0           add_30[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_61[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
ternary_dense_1 (TernaryDense)  (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 959,658
Trainable params: 955,146
Non-trainable params: 4,512
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.10220, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 141s - loss: 33.4771 - acc: 0.1002 - val_loss: 32.0331 - val_acc: 0.1022
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc did not improve
 - 59s - loss: 31.1369 - acc: 0.0987 - val_loss: 30.2759 - val_acc: 0.1000
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc did not improve
 - 59s - loss: 29.5434 - acc: 0.0983 - val_loss: 28.8686 - val_acc: 0.1006
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.10220 to 0.10820, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 28.2345 - acc: 0.1013 - val_loss: 27.6696 - val_acc: 0.1082
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc did not improve
 - 59s - loss: 27.1526 - acc: 0.0972 - val_loss: 26.6871 - val_acc: 0.1080
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc did not improve
 - 59s - loss: 26.2303 - acc: 0.1008 - val_loss: 25.8696 - val_acc: 0.1066
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc did not improve
 - 59s - loss: 25.4262 - acc: 0.1016 - val_loss: 25.0772 - val_acc: 0.1050
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc did not improve
 - 59s - loss: 24.6876 - acc: 0.1004 - val_loss: 24.3783 - val_acc: 0.1048
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc improved from 0.10820 to 0.11040, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 24.0093 - acc: 0.1003 - val_loss: 23.6925 - val_acc: 0.1104
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 59s - loss: 23.3647 - acc: 0.0986 - val_loss: 23.0533 - val_acc: 0.0942
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 59s - loss: 22.7409 - acc: 0.1009 - val_loss: 22.4579 - val_acc: 0.0984
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 59s - loss: 22.1399 - acc: 0.0995 - val_loss: 21.8465 - val_acc: 0.0986
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc did not improve
 - 59s - loss: 21.5475 - acc: 0.0996 - val_loss: 21.2489 - val_acc: 0.0980
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 59s - loss: 20.9574 - acc: 0.1009 - val_loss: 20.6617 - val_acc: 0.0982
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc did not improve
 - 59s - loss: 20.3747 - acc: 0.1001 - val_loss: 20.0871 - val_acc: 0.0972
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 59s - loss: 19.7976 - acc: 0.0975 - val_loss: 19.5451 - val_acc: 0.0976
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 59s - loss: 19.2200 - acc: 0.0987 - val_loss: 18.9285 - val_acc: 0.0950
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 59s - loss: 18.6402 - acc: 0.1010 - val_loss: 18.3538 - val_acc: 0.1066
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 59s - loss: 18.0640 - acc: 0.1009 - val_loss: 17.7694 - val_acc: 0.0986
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 59s - loss: 17.4972 - acc: 0.0987 - val_loss: 17.2803 - val_acc: 0.0950
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 59s - loss: 16.9278 - acc: 0.1001 - val_loss: 16.6701 - val_acc: 0.1022
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 59s - loss: 16.3723 - acc: 0.0978 - val_loss: 16.1174 - val_acc: 0.1032
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 59s - loss: 15.8131 - acc: 0.1004 - val_loss: 15.5824 - val_acc: 0.1054
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 59s - loss: 15.2702 - acc: 0.0971 - val_loss: 15.3148 - val_acc: 0.1058
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 59s - loss: 14.7362 - acc: 0.0984 - val_loss: 14.7541 - val_acc: 0.0982
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 59s - loss: 14.2152 - acc: 0.1007 - val_loss: 14.4633 - val_acc: 0.1024
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 59s - loss: 13.7126 - acc: 0.0989 - val_loss: 13.6032 - val_acc: 0.1024
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 59s - loss: 13.2317 - acc: 0.0988 - val_loss: 13.1767 - val_acc: 0.0958
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 59s - loss: 12.7588 - acc: 0.0991 - val_loss: 13.1275 - val_acc: 0.0946
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 59s - loss: 12.3126 - acc: 0.0998 - val_loss: 12.4186 - val_acc: 0.0976
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 60s - loss: 11.8868 - acc: 0.1006 - val_loss: 12.0355 - val_acc: 0.0950
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 59s - loss: 11.5049 - acc: 0.0983 - val_loss: 11.4231 - val_acc: 0.0970
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 59s - loss: 11.1475 - acc: 0.0987 - val_loss: 11.6345 - val_acc: 0.1058
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 59s - loss: 10.8238 - acc: 0.1009 - val_loss: 10.8337 - val_acc: 0.0950
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 59s - loss: 10.5334 - acc: 0.1027 - val_loss: 10.6987 - val_acc: 0.1024
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 59s - loss: 10.2768 - acc: 0.1013 - val_loss: 11.0227 - val_acc: 0.1064
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 59s - loss: 10.0539 - acc: 0.0993 - val_loss: 10.6038 - val_acc: 0.0958
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 59s - loss: 9.8631 - acc: 0.0996 - val_loss: 10.8204 - val_acc: 0.1064
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 59s - loss: 9.6919 - acc: 0.1026 - val_loss: 9.8112 - val_acc: 0.1068
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 59s - loss: 9.5383 - acc: 0.1000 - val_loss: 10.0693 - val_acc: 0.0976
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 60s - loss: 9.4037 - acc: 0.0992 - val_loss: 9.6322 - val_acc: 0.0958
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 59s - loss: 9.2755 - acc: 0.1001 - val_loss: 9.4405 - val_acc: 0.1064
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 59s - loss: 9.1437 - acc: 0.1006 - val_loss: 9.2589 - val_acc: 0.0950
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 59s - loss: 9.0216 - acc: 0.0995 - val_loss: 9.5674 - val_acc: 0.0950
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 59s - loss: 8.8917 - acc: 0.1026 - val_loss: 9.3535 - val_acc: 0.1024
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 59s - loss: 8.7625 - acc: 0.0973 - val_loss: 8.8115 - val_acc: 0.1022
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 59s - loss: 8.6271 - acc: 0.0996 - val_loss: 9.1455 - val_acc: 0.0976
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 59s - loss: 8.4912 - acc: 0.0971 - val_loss: 8.8851 - val_acc: 0.0970
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 60s - loss: 8.3455 - acc: 0.1012 - val_loss: 8.4010 - val_acc: 0.0976
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 59s - loss: 8.2036 - acc: 0.1016 - val_loss: 9.0274 - val_acc: 0.0958
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 59s - loss: 8.0656 - acc: 0.0991 - val_loss: 8.2940 - val_acc: 0.0976
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 60s - loss: 7.9233 - acc: 0.0992 - val_loss: 8.9896 - val_acc: 0.0986
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 60s - loss: 7.7833 - acc: 0.1014 - val_loss: 10.6795 - val_acc: 0.0986
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 59s - loss: 7.6489 - acc: 0.0981 - val_loss: 7.9780 - val_acc: 0.1036
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 59s - loss: 7.5160 - acc: 0.0980 - val_loss: 8.0885 - val_acc: 0.1064
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 59s - loss: 7.3797 - acc: 0.0998 - val_loss: 7.8361 - val_acc: 0.0992
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 59s - loss: 7.2626 - acc: 0.1000 - val_loss: 8.1478 - val_acc: 0.0958
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 59s - loss: 7.1364 - acc: 0.1021 - val_loss: 7.3944 - val_acc: 0.1064
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 59s - loss: 7.0163 - acc: 0.1006 - val_loss: 7.7958 - val_acc: 0.0958
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 59s - loss: 6.8923 - acc: 0.1001 - val_loss: 7.5264 - val_acc: 0.1058
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 59s - loss: 6.7666 - acc: 0.0999 - val_loss: 7.4715 - val_acc: 0.0950
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 59s - loss: 6.6425 - acc: 0.1005 - val_loss: 8.1654 - val_acc: 0.0970
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 59s - loss: 6.5156 - acc: 0.1005 - val_loss: 6.7367 - val_acc: 0.1064
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 59s - loss: 6.3898 - acc: 0.0990 - val_loss: 6.6200 - val_acc: 0.0958
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 59s - loss: 6.2618 - acc: 0.1006 - val_loss: 6.9470 - val_acc: 0.0958
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 59s - loss: 6.1384 - acc: 0.0964 - val_loss: 7.0785 - val_acc: 0.0976
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 60s - loss: 6.0096 - acc: 0.0995 - val_loss: 6.9180 - val_acc: 0.0976
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 59s - loss: 5.8889 - acc: 0.1001 - val_loss: 6.7182 - val_acc: 0.1058
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 59s - loss: 5.7723 - acc: 0.0984 - val_loss: 6.7460 - val_acc: 0.0958
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 59s - loss: 5.6575 - acc: 0.0993 - val_loss: 5.8756 - val_acc: 0.1064
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 59s - loss: 5.5524 - acc: 0.0988 - val_loss: 8.5811 - val_acc: 0.1064
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 59s - loss: 5.4448 - acc: 0.0981 - val_loss: 5.8181 - val_acc: 0.1058
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 59s - loss: 5.3364 - acc: 0.0979 - val_loss: 5.4952 - val_acc: 0.1038
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 59s - loss: 5.2277 - acc: 0.1000 - val_loss: 6.1865 - val_acc: 0.0986
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 59s - loss: 5.1240 - acc: 0.1001 - val_loss: 5.4157 - val_acc: 0.0976
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 59s - loss: 5.0225 - acc: 0.0986 - val_loss: 5.5310 - val_acc: 0.1064
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 59s - loss: 4.9191 - acc: 0.0989 - val_loss: 6.5279 - val_acc: 0.1064
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 59s - loss: 4.8179 - acc: 0.1016 - val_loss: 5.7929 - val_acc: 0.0958
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 59s - loss: 4.7284 - acc: 0.1027 - val_loss: 5.4362 - val_acc: 0.1058
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 59s - loss: 4.6361 - acc: 0.0990 - val_loss: 4.7768 - val_acc: 0.0950
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 59s - loss: 4.5623 - acc: 0.1020 - val_loss: 4.7600 - val_acc: 0.0970
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.11040 to 0.12880, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.4683 - acc: 0.1435 - val_loss: 4.6853 - val_acc: 0.1288
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.12880 to 0.14020, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.4377 - acc: 0.1640 - val_loss: 4.6410 - val_acc: 0.1402
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc improved from 0.14020 to 0.17680, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.4278 - acc: 0.1656 - val_loss: 4.4424 - val_acc: 0.1768
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 60s - loss: 4.4151 - acc: 0.1711 - val_loss: 4.6646 - val_acc: 0.1506
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 59s - loss: 4.3921 - acc: 0.1808 - val_loss: 4.4643 - val_acc: 0.1526
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 59s - loss: 4.3731 - acc: 0.1908 - val_loss: 4.5254 - val_acc: 0.1628
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 59s - loss: 4.3665 - acc: 0.1927 - val_loss: 4.4973 - val_acc: 0.1280
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc improved from 0.17680 to 0.19760, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.3654 - acc: 0.1920 - val_loss: 4.3794 - val_acc: 0.1976
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 60s - loss: 4.3602 - acc: 0.1918 - val_loss: 4.3746 - val_acc: 0.1942
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 59s - loss: 4.3532 - acc: 0.1952 - val_loss: 4.4627 - val_acc: 0.1490
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 60s - loss: 4.3478 - acc: 0.1968 - val_loss: 4.5180 - val_acc: 0.1454
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 59s - loss: 4.3469 - acc: 0.1938 - val_loss: 4.4186 - val_acc: 0.1524
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 59s - loss: 4.3453 - acc: 0.1958 - val_loss: 4.4804 - val_acc: 0.1468
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 59s - loss: 4.3354 - acc: 0.1936 - val_loss: 4.4703 - val_acc: 0.1098
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 59s - loss: 4.3515 - acc: 0.1865 - val_loss: 4.4797 - val_acc: 0.1378
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 59s - loss: 4.3191 - acc: 0.2025 - val_loss: 4.3863 - val_acc: 0.1762
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc improved from 0.19760 to 0.20660, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.3040 - acc: 0.2080 - val_loss: 4.3339 - val_acc: 0.2066
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 59s - loss: 4.3319 - acc: 0.1953 - val_loss: 4.4685 - val_acc: 0.1714
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 59s - loss: 4.3378 - acc: 0.1910 - val_loss: 4.4040 - val_acc: 0.1376
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 59s - loss: 4.3227 - acc: 0.1954 - val_loss: 4.3900 - val_acc: 0.1448
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 59s - loss: 4.3073 - acc: 0.2031 - val_loss: 4.4022 - val_acc: 0.1420
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 59s - loss: 4.3438 - acc: 0.1844 - val_loss: 4.4999 - val_acc: 0.1294
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 59s - loss: 4.3424 - acc: 0.1855 - val_loss: 4.4666 - val_acc: 0.1264
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 59s - loss: 4.3413 - acc: 0.1857 - val_loss: 4.4879 - val_acc: 0.1214
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 59s - loss: 4.3490 - acc: 0.1810 - val_loss: 4.4826 - val_acc: 0.1442
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 59s - loss: 4.3251 - acc: 0.1926 - val_loss: 4.5071 - val_acc: 0.1310
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 59s - loss: 4.3202 - acc: 0.1952 - val_loss: 4.6605 - val_acc: 0.1322
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 59s - loss: 4.3168 - acc: 0.1966 - val_loss: 4.3349 - val_acc: 0.1858
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 59s - loss: 4.3107 - acc: 0.1941 - val_loss: 4.3345 - val_acc: 0.1842
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 59s - loss: 4.3100 - acc: 0.1919 - val_loss: 4.3344 - val_acc: 0.1806
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 59s - loss: 4.3054 - acc: 0.1975 - val_loss: 4.4869 - val_acc: 0.1410
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 59s - loss: 4.3064 - acc: 0.1936 - val_loss: 4.4641 - val_acc: 0.1176
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 60s - loss: 4.3173 - acc: 0.1889 - val_loss: 4.4377 - val_acc: 0.1460
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 59s - loss: 4.2981 - acc: 0.1971 - val_loss: 4.3052 - val_acc: 0.1866
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 59s - loss: 4.2869 - acc: 0.2054 - val_loss: 4.5140 - val_acc: 0.1486
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 59s - loss: 4.2896 - acc: 0.2008 - val_loss: 4.4014 - val_acc: 0.1548
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 59s - loss: 4.2773 - acc: 0.2057 - val_loss: 4.3237 - val_acc: 0.1792
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 60s - loss: 4.2810 - acc: 0.2060 - val_loss: 4.3684 - val_acc: 0.1674
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 59s - loss: 4.2670 - acc: 0.2098 - val_loss: 4.3978 - val_acc: 0.1746
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc improved from 0.20660 to 0.21400, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.2581 - acc: 0.2131 - val_loss: 4.2630 - val_acc: 0.2140
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc improved from 0.21400 to 0.23520, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.2301 - acc: 0.2282 - val_loss: 4.2203 - val_acc: 0.2352
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 59s - loss: 4.2211 - acc: 0.2332 - val_loss: 4.2179 - val_acc: 0.2290
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc improved from 0.23520 to 0.23980, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.2209 - acc: 0.2318 - val_loss: 4.2094 - val_acc: 0.2398
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc improved from 0.23980 to 0.24160, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.2149 - acc: 0.2368 - val_loss: 4.2071 - val_acc: 0.2416
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 59s - loss: 4.2096 - acc: 0.2372 - val_loss: 4.2093 - val_acc: 0.2330
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc improved from 0.24160 to 0.24240, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.2077 - acc: 0.2377 - val_loss: 4.2011 - val_acc: 0.2424
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 59s - loss: 4.2035 - acc: 0.2406 - val_loss: 4.2016 - val_acc: 0.2418
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 59s - loss: 4.1976 - acc: 0.2442 - val_loss: 4.2049 - val_acc: 0.2394
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 59s - loss: 4.1939 - acc: 0.2466 - val_loss: 4.1925 - val_acc: 0.2392
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc improved from 0.24240 to 0.24900, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 62s - loss: 4.1915 - acc: 0.2493 - val_loss: 4.1933 - val_acc: 0.2490
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 59s - loss: 4.1913 - acc: 0.2455 - val_loss: 4.1856 - val_acc: 0.2472
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc improved from 0.24900 to 0.25480, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.1863 - acc: 0.2463 - val_loss: 4.1802 - val_acc: 0.2548
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 59s - loss: 4.1798 - acc: 0.2503 - val_loss: 4.1767 - val_acc: 0.2492
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 60s - loss: 4.1760 - acc: 0.2555 - val_loss: 4.1853 - val_acc: 0.2480
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 59s - loss: 4.1751 - acc: 0.2557 - val_loss: 4.1804 - val_acc: 0.2514
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 59s - loss: 4.1730 - acc: 0.2567 - val_loss: 4.1708 - val_acc: 0.2540
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc improved from 0.25480 to 0.25800, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.1667 - acc: 0.2565 - val_loss: 4.1701 - val_acc: 0.2580
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc improved from 0.25800 to 0.26400, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.1627 - acc: 0.2575 - val_loss: 4.1654 - val_acc: 0.2640
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc improved from 0.26400 to 0.26460, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 62s - loss: 4.1625 - acc: 0.2582 - val_loss: 4.1534 - val_acc: 0.2646
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 59s - loss: 4.1550 - acc: 0.2646 - val_loss: 4.1813 - val_acc: 0.2488
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc improved from 0.26460 to 0.26540, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.1512 - acc: 0.2639 - val_loss: 4.1532 - val_acc: 0.2654
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 59s - loss: 4.1472 - acc: 0.2659 - val_loss: 4.1583 - val_acc: 0.2584
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc improved from 0.26540 to 0.26640, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.1486 - acc: 0.2651 - val_loss: 4.1412 - val_acc: 0.2664
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 59s - loss: 4.1474 - acc: 0.2661 - val_loss: 4.1504 - val_acc: 0.2606
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 59s - loss: 4.1430 - acc: 0.2667 - val_loss: 4.1456 - val_acc: 0.2636
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 59s - loss: 4.1396 - acc: 0.2683 - val_loss: 4.1390 - val_acc: 0.2642
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 59s - loss: 4.1389 - acc: 0.2700 - val_loss: 4.1522 - val_acc: 0.2656
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc improved from 0.26640 to 0.26960, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.1348 - acc: 0.2711 - val_loss: 4.1344 - val_acc: 0.2696
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 59s - loss: 4.1357 - acc: 0.2716 - val_loss: 4.1366 - val_acc: 0.2678
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 59s - loss: 4.1303 - acc: 0.2748 - val_loss: 4.1786 - val_acc: 0.2546
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc improved from 0.26960 to 0.27120, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.1329 - acc: 0.2704 - val_loss: 4.1307 - val_acc: 0.2712
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 59s - loss: 4.1298 - acc: 0.2736 - val_loss: 4.1437 - val_acc: 0.2684
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 59s - loss: 4.1270 - acc: 0.2718 - val_loss: 4.1324 - val_acc: 0.2684
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 59s - loss: 4.1256 - acc: 0.2721 - val_loss: 4.1351 - val_acc: 0.2642
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 59s - loss: 4.1183 - acc: 0.2784 - val_loss: 4.1374 - val_acc: 0.2610
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc improved from 0.27120 to 0.27800, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.1192 - acc: 0.2748 - val_loss: 4.1193 - val_acc: 0.2780
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 59s - loss: 4.1196 - acc: 0.2733 - val_loss: 4.1187 - val_acc: 0.2744
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 59s - loss: 4.1173 - acc: 0.2762 - val_loss: 4.1552 - val_acc: 0.2648
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 59s - loss: 4.1189 - acc: 0.2766 - val_loss: 4.1369 - val_acc: 0.2702
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 59s - loss: 4.1177 - acc: 0.2777 - val_loss: 4.1493 - val_acc: 0.2614
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc improved from 0.27800 to 0.27960, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.1087 - acc: 0.2828 - val_loss: 4.1046 - val_acc: 0.2796
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc improved from 0.27960 to 0.29260, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.1029 - acc: 0.2830 - val_loss: 4.0963 - val_acc: 0.2926
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 59s - loss: 4.1008 - acc: 0.2837 - val_loss: 4.0868 - val_acc: 0.2876
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 59s - loss: 4.0970 - acc: 0.2864 - val_loss: 4.0971 - val_acc: 0.2872
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 59s - loss: 4.0939 - acc: 0.2861 - val_loss: 4.0853 - val_acc: 0.2914
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 59s - loss: 4.0889 - acc: 0.2882 - val_loss: 4.0894 - val_acc: 0.2828
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 59s - loss: 4.0937 - acc: 0.2848 - val_loss: 4.0836 - val_acc: 0.2910
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 59s - loss: 4.0923 - acc: 0.2895 - val_loss: 4.0890 - val_acc: 0.2918
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 59s - loss: 4.0936 - acc: 0.2852 - val_loss: 4.0905 - val_acc: 0.2902
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 60s - loss: 4.0944 - acc: 0.2870 - val_loss: 4.0897 - val_acc: 0.2906
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 59s - loss: 4.0936 - acc: 0.2869 - val_loss: 4.0900 - val_acc: 0.2818
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 59s - loss: 4.0886 - acc: 0.2881 - val_loss: 4.0908 - val_acc: 0.2874
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 59s - loss: 4.0871 - acc: 0.2891 - val_loss: 4.0830 - val_acc: 0.2884
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 59s - loss: 4.0905 - acc: 0.2864 - val_loss: 4.0835 - val_acc: 0.2916
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 59s - loss: 4.0861 - acc: 0.2893 - val_loss: 4.0874 - val_acc: 0.2876
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 59s - loss: 4.0870 - acc: 0.2890 - val_loss: 4.0768 - val_acc: 0.2894
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 60s - loss: 4.0871 - acc: 0.2886 - val_loss: 4.0918 - val_acc: 0.2842
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc improved from 0.29260 to 0.29480, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.0877 - acc: 0.2890 - val_loss: 4.0792 - val_acc: 0.2948
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 59s - loss: 4.0860 - acc: 0.2878 - val_loss: 4.0858 - val_acc: 0.2918
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 59s - loss: 4.0864 - acc: 0.2896 - val_loss: 4.0780 - val_acc: 0.2900
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 60s - loss: 4.0852 - acc: 0.2896 - val_loss: 4.0904 - val_acc: 0.2910
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 59s - loss: 4.0850 - acc: 0.2900 - val_loss: 4.0817 - val_acc: 0.2868
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 59s - loss: 4.0810 - acc: 0.2912 - val_loss: 4.0769 - val_acc: 0.2838
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 59s - loss: 4.0799 - acc: 0.2926 - val_loss: 4.0938 - val_acc: 0.2874
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 59s - loss: 4.0830 - acc: 0.2940 - val_loss: 4.0903 - val_acc: 0.2864
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 59s - loss: 4.0826 - acc: 0.2903 - val_loss: 4.0846 - val_acc: 0.2870
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 59s - loss: 4.0827 - acc: 0.2893 - val_loss: 4.0928 - val_acc: 0.2934
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 59s - loss: 4.0818 - acc: 0.2917 - val_loss: 4.0859 - val_acc: 0.2918
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 59s - loss: 4.0817 - acc: 0.2942 - val_loss: 4.0823 - val_acc: 0.2864
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 59s - loss: 4.0786 - acc: 0.2904 - val_loss: 4.0808 - val_acc: 0.2874
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 59s - loss: 4.0801 - acc: 0.2930 - val_loss: 4.0795 - val_acc: 0.2908
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 59s - loss: 4.0790 - acc: 0.2890 - val_loss: 4.0794 - val_acc: 0.2862
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 59s - loss: 4.0774 - acc: 0.2908 - val_loss: 4.0720 - val_acc: 0.2936
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 59s - loss: 4.0772 - acc: 0.2915 - val_loss: 4.0649 - val_acc: 0.2922
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 59s - loss: 4.0811 - acc: 0.2908 - val_loss: 4.0816 - val_acc: 0.2934
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 59s - loss: 4.0817 - acc: 0.2936 - val_loss: 4.0694 - val_acc: 0.2864
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 60s - loss: 4.0791 - acc: 0.2908 - val_loss: 4.0822 - val_acc: 0.2930
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc improved from 0.29480 to 0.29880, saving model to ./weights/CIFAR-10_qtnn_8b_4b_1_64_1_128_1_256.hdf5
 - 61s - loss: 4.0793 - acc: 0.2911 - val_loss: 4.0811 - val_acc: 0.2988
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 59s - loss: 4.0762 - acc: 0.2933 - val_loss: 4.0795 - val_acc: 0.2958
Done

