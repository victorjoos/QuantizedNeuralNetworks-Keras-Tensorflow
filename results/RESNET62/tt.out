Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
ternary_conv2d_1 (TernaryConv2D (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_2 (TernaryConv2D (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_2[0][0]           
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_3 (TernaryConv2D (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_3[0][0]           
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_4 (TernaryConv2D (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_4[0][0]           
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_5 (TernaryConv2D (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_5[0][0]           
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_6 (TernaryConv2D (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_6[0][0]           
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_7 (TernaryConv2D (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_7[0][0]           
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_8 (TernaryConv2D (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_8[0][0]           
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_9 (TernaryConv2D (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_9[0][0]           
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_10 (TernaryConv2 (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_10[0][0]          
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_11 (TernaryConv2 (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_11[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_12 (TernaryConv2 (None, 32, 32, 16)   2320        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_12[0][0]          
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_13 (TernaryConv2 (None, 32, 32, 16)   2320        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_13[0][0]          
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 16)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_14 (TernaryConv2 (None, 32, 32, 16)   2320        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_14[0][0]          
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_15 (TernaryConv2 (None, 32, 32, 16)   2320        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_15[0][0]          
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 16)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_16 (TernaryConv2 (None, 32, 32, 16)   2320        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_16[0][0]          
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_17 (TernaryConv2 (None, 32, 32, 16)   2320        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_17[0][0]          
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 16)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_18 (TernaryConv2 (None, 32, 32, 16)   2320        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_18[0][0]          
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_19 (TernaryConv2 (None, 32, 32, 16)   2320        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_19[0][0]          
__________________________________________________________________________________________________
add_9 (Add)                     (None, 32, 32, 16)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 32, 32, 16)   0           add_9[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_20 (TernaryConv2 (None, 32, 32, 16)   2320        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_20[0][0]          
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_21 (TernaryConv2 (None, 32, 32, 16)   2320        activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          ternary_conv2d_21[0][0]          
__________________________________________________________________________________________________
add_10 (Add)                    (None, 32, 32, 16)   0           activation_19[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 16)   0           add_10[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_22 (TernaryConv2 (None, 16, 16, 32)   4640        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_22[0][0]          
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_23 (TernaryConv2 (None, 16, 16, 32)   9248        activation_22[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_24 (TernaryConv2 (None, 16, 16, 32)   544         activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_23[0][0]          
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 32)   0           ternary_conv2d_24[0][0]          
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_25 (TernaryConv2 (None, 16, 16, 32)   9248        activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_25[0][0]          
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_26 (TernaryConv2 (None, 16, 16, 32)   9248        activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_26[0][0]          
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 32)   0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 16, 16, 32)   0           add_12[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_27 (TernaryConv2 (None, 16, 16, 32)   9248        activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_27[0][0]          
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_28 (TernaryConv2 (None, 16, 16, 32)   9248        activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_28[0][0]          
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 32)   0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_29 (TernaryConv2 (None, 16, 16, 32)   9248        activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_29[0][0]          
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_30 (TernaryConv2 (None, 16, 16, 32)   9248        activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_30[0][0]          
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 32)   0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_31 (TernaryConv2 (None, 16, 16, 32)   9248        activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_31[0][0]          
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_32 (TernaryConv2 (None, 16, 16, 32)   9248        activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_32[0][0]          
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 32)   0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_33 (TernaryConv2 (None, 16, 16, 32)   9248        activation_31[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_33[0][0]          
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_34 (TernaryConv2 (None, 16, 16, 32)   9248        activation_32[0][0]              
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_34[0][0]          
__________________________________________________________________________________________________
add_16 (Add)                    (None, 16, 16, 32)   0           activation_31[0][0]              
                                                                 batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 16, 16, 32)   0           add_16[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_35 (TernaryConv2 (None, 16, 16, 32)   9248        activation_33[0][0]              
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_35[0][0]          
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_36 (TernaryConv2 (None, 16, 16, 32)   9248        activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_36[0][0]          
__________________________________________________________________________________________________
add_17 (Add)                    (None, 16, 16, 32)   0           activation_33[0][0]              
                                                                 batch_normalization_35[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 16, 16, 32)   0           add_17[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_37 (TernaryConv2 (None, 16, 16, 32)   9248        activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_37[0][0]          
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_38 (TernaryConv2 (None, 16, 16, 32)   9248        activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_38[0][0]          
__________________________________________________________________________________________________
add_18 (Add)                    (None, 16, 16, 32)   0           activation_35[0][0]              
                                                                 batch_normalization_37[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 16, 16, 32)   0           add_18[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_39 (TernaryConv2 (None, 16, 16, 32)   9248        activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_39[0][0]          
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 16, 16, 32)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_40 (TernaryConv2 (None, 16, 16, 32)   9248        activation_38[0][0]              
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_40[0][0]          
__________________________________________________________________________________________________
add_19 (Add)                    (None, 16, 16, 32)   0           activation_37[0][0]              
                                                                 batch_normalization_39[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 16, 16, 32)   0           add_19[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_41 (TernaryConv2 (None, 16, 16, 32)   9248        activation_39[0][0]              
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_41[0][0]          
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 16, 16, 32)   0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_42 (TernaryConv2 (None, 16, 16, 32)   9248        activation_40[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_42[0][0]          
__________________________________________________________________________________________________
add_20 (Add)                    (None, 16, 16, 32)   0           activation_39[0][0]              
                                                                 batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 16, 16, 32)   0           add_20[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_43 (TernaryConv2 (None, 8, 8, 64)     18496       activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_43[0][0]          
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_44 (TernaryConv2 (None, 8, 8, 64)     36928       activation_42[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_45 (TernaryConv2 (None, 8, 8, 64)     2112        activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_44[0][0]          
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 8, 64)     0           ternary_conv2d_45[0][0]          
                                                                 batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 8, 8, 64)     0           add_21[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_46 (TernaryConv2 (None, 8, 8, 64)     36928       activation_43[0][0]              
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_46[0][0]          
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_47 (TernaryConv2 (None, 8, 8, 64)     36928       activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_47[0][0]          
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 8, 64)     0           activation_43[0][0]              
                                                                 batch_normalization_45[0][0]     
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 8, 8, 64)     0           add_22[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_48 (TernaryConv2 (None, 8, 8, 64)     36928       activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_48[0][0]          
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_49 (TernaryConv2 (None, 8, 8, 64)     36928       activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_49[0][0]          
__________________________________________________________________________________________________
add_23 (Add)                    (None, 8, 8, 64)     0           activation_45[0][0]              
                                                                 batch_normalization_47[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 8, 8, 64)     0           add_23[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_50 (TernaryConv2 (None, 8, 8, 64)     36928       activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_50[0][0]          
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_51 (TernaryConv2 (None, 8, 8, 64)     36928       activation_48[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_51[0][0]          
__________________________________________________________________________________________________
add_24 (Add)                    (None, 8, 8, 64)     0           activation_47[0][0]              
                                                                 batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 8, 8, 64)     0           add_24[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_52 (TernaryConv2 (None, 8, 8, 64)     36928       activation_49[0][0]              
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_52[0][0]          
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_53 (TernaryConv2 (None, 8, 8, 64)     36928       activation_50[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_53[0][0]          
__________________________________________________________________________________________________
add_25 (Add)                    (None, 8, 8, 64)     0           activation_49[0][0]              
                                                                 batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_54 (TernaryConv2 (None, 8, 8, 64)     36928       activation_51[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_54[0][0]          
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_55 (TernaryConv2 (None, 8, 8, 64)     36928       activation_52[0][0]              
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_55[0][0]          
__________________________________________________________________________________________________
add_26 (Add)                    (None, 8, 8, 64)     0           activation_51[0][0]              
                                                                 batch_normalization_53[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_56 (TernaryConv2 (None, 8, 8, 64)     36928       activation_53[0][0]              
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_56[0][0]          
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_57 (TernaryConv2 (None, 8, 8, 64)     36928       activation_54[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_57[0][0]          
__________________________________________________________________________________________________
add_27 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              
                                                                 batch_normalization_55[0][0]     
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 8, 8, 64)     0           add_27[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_58 (TernaryConv2 (None, 8, 8, 64)     36928       activation_55[0][0]              
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_58[0][0]          
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_59 (TernaryConv2 (None, 8, 8, 64)     36928       activation_56[0][0]              
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_59[0][0]          
__________________________________________________________________________________________________
add_28 (Add)                    (None, 8, 8, 64)     0           activation_55[0][0]              
                                                                 batch_normalization_57[0][0]     
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 8, 8, 64)     0           add_28[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_60 (TernaryConv2 (None, 8, 8, 64)     36928       activation_57[0][0]              
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_60[0][0]          
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 8, 8, 64)     0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_61 (TernaryConv2 (None, 8, 8, 64)     36928       activation_58[0][0]              
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_61[0][0]          
__________________________________________________________________________________________________
add_29 (Add)                    (None, 8, 8, 64)     0           activation_57[0][0]              
                                                                 batch_normalization_59[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 8, 8, 64)     0           add_29[0][0]                     
__________________________________________________________________________________________________
ternary_conv2d_62 (TernaryConv2 (None, 8, 8, 64)     36928       activation_59[0][0]              
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_62[0][0]          
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 8, 8, 64)     0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_63 (TernaryConv2 (None, 8, 8, 64)     36928       activation_60[0][0]              
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_63[0][0]          
__________________________________________________________________________________________________
add_30 (Add)                    (None, 8, 8, 64)     0           activation_59[0][0]              
                                                                 batch_normalization_61[0][0]     
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 8, 8, 64)     0           add_30[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_61[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
ternary_dense_1 (TernaryDense)  (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 959,658
Trainable params: 955,146
Non-trainable params: 4,512
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.10240, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 134s - loss: 31.4758 - acc: 0.0998 - val_loss: 28.9481 - val_acc: 0.1024
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc did not improve
 - 55s - loss: 26.7689 - acc: 0.1000 - val_loss: 24.7179 - val_acc: 0.1002
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc did not improve
 - 55s - loss: 22.9517 - acc: 0.1024 - val_loss: 21.3090 - val_acc: 0.0996
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc did not improve
 - 56s - loss: 19.9176 - acc: 0.1002 - val_loss: 18.6180 - val_acc: 0.0954
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc did not improve
 - 56s - loss: 17.5111 - acc: 0.1010 - val_loss: 16.4845 - val_acc: 0.0958
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc did not improve
 - 56s - loss: 15.6125 - acc: 0.1001 - val_loss: 14.8042 - val_acc: 0.0938
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc did not improve
 - 56s - loss: 14.1047 - acc: 0.1004 - val_loss: 13.4572 - val_acc: 0.1022
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc improved from 0.10240 to 0.10480, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 12.9045 - acc: 0.1004 - val_loss: 12.3924 - val_acc: 0.1048
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 56s - loss: 11.9399 - acc: 0.0999 - val_loss: 11.5223 - val_acc: 0.0960
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 56s - loss: 11.1543 - acc: 0.0994 - val_loss: 10.8030 - val_acc: 0.1042
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 56s - loss: 10.5087 - acc: 0.1020 - val_loss: 10.2192 - val_acc: 0.0972
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc improved from 0.10480 to 0.10620, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 9.9652 - acc: 0.1018 - val_loss: 9.7113 - val_acc: 0.1062
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc did not improve
 - 56s - loss: 9.4977 - acc: 0.1016 - val_loss: 9.2840 - val_acc: 0.1054
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 56s - loss: 9.0916 - acc: 0.1026 - val_loss: 8.9004 - val_acc: 0.1002
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc improved from 0.10620 to 0.13240, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 8.7236 - acc: 0.1124 - val_loss: 8.5265 - val_acc: 0.1324
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc improved from 0.13240 to 0.15500, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 8.3522 - acc: 0.1399 - val_loss: 8.1684 - val_acc: 0.1550
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc improved from 0.15500 to 0.17940, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 7.9845 - acc: 0.1733 - val_loss: 7.8672 - val_acc: 0.1794
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc improved from 0.17940 to 0.21060, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 7.6561 - acc: 0.2006 - val_loss: 7.5040 - val_acc: 0.2106
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 55s - loss: 7.3698 - acc: 0.2185 - val_loss: 7.3186 - val_acc: 0.1732
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 56s - loss: 7.1070 - acc: 0.2241 - val_loss: 7.0196 - val_acc: 0.2010
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc improved from 0.21060 to 0.23960, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 6.8351 - acc: 0.2287 - val_loss: 6.6997 - val_acc: 0.2396
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 56s - loss: 6.5696 - acc: 0.2329 - val_loss: 6.4865 - val_acc: 0.2306
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 56s - loss: 6.2877 - acc: 0.2376 - val_loss: 6.1719 - val_acc: 0.2224
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 56s - loss: 6.0378 - acc: 0.2334 - val_loss: 5.9422 - val_acc: 0.2246
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc improved from 0.23960 to 0.25620, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 5.7762 - acc: 0.2418 - val_loss: 5.6430 - val_acc: 0.2562
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 56s - loss: 5.5033 - acc: 0.2504 - val_loss: 5.4638 - val_acc: 0.2232
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 56s - loss: 5.2451 - acc: 0.2575 - val_loss: 5.2162 - val_acc: 0.2432
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 56s - loss: 4.9977 - acc: 0.2663 - val_loss: 4.9942 - val_acc: 0.2440
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc improved from 0.25620 to 0.25860, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 4.7690 - acc: 0.2729 - val_loss: 4.6860 - val_acc: 0.2586
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 56s - loss: 4.5392 - acc: 0.2836 - val_loss: 4.4944 - val_acc: 0.2474
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc improved from 0.25860 to 0.28620, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 4.3209 - acc: 0.2865 - val_loss: 4.2267 - val_acc: 0.2862
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 55s - loss: 4.1138 - acc: 0.2893 - val_loss: 4.0573 - val_acc: 0.2652
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc improved from 0.28620 to 0.30020, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 3.9169 - acc: 0.2922 - val_loss: 3.8413 - val_acc: 0.3002
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 56s - loss: 3.7244 - acc: 0.2952 - val_loss: 3.6965 - val_acc: 0.2868
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 56s - loss: 3.5464 - acc: 0.3035 - val_loss: 3.5496 - val_acc: 0.2612
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc improved from 0.30020 to 0.30440, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 3.3925 - acc: 0.3071 - val_loss: 3.3567 - val_acc: 0.3044
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc improved from 0.30440 to 0.33120, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 3.2408 - acc: 0.3131 - val_loss: 3.1549 - val_acc: 0.3312
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 56s - loss: 3.1164 - acc: 0.3185 - val_loss: 3.1024 - val_acc: 0.2894
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 56s - loss: 3.0122 - acc: 0.3162 - val_loss: 3.1563 - val_acc: 0.2646
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 56s - loss: 2.9127 - acc: 0.3196 - val_loss: 2.8996 - val_acc: 0.3156
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 56s - loss: 2.8112 - acc: 0.3242 - val_loss: 3.0178 - val_acc: 0.2742
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 56s - loss: 2.7121 - acc: 0.3299 - val_loss: 2.8302 - val_acc: 0.2828
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 56s - loss: 2.6361 - acc: 0.3264 - val_loss: 2.8748 - val_acc: 0.2122
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 56s - loss: 2.5472 - acc: 0.3268 - val_loss: 2.7564 - val_acc: 0.2560
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 56s - loss: 2.4588 - acc: 0.3387 - val_loss: 2.5906 - val_acc: 0.2830
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc improved from 0.33120 to 0.33680, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 2.3776 - acc: 0.3401 - val_loss: 2.3693 - val_acc: 0.3368
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 56s - loss: 2.3038 - acc: 0.3402 - val_loss: 2.6898 - val_acc: 0.2188
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 56s - loss: 2.2359 - acc: 0.3436 - val_loss: 2.4958 - val_acc: 0.2590
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 56s - loss: 2.1561 - acc: 0.3490 - val_loss: 2.5467 - val_acc: 0.2494
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 56s - loss: 2.1034 - acc: 0.3503 - val_loss: 2.2685 - val_acc: 0.2868
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 56s - loss: 2.0472 - acc: 0.3530 - val_loss: 2.2745 - val_acc: 0.2604
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 56s - loss: 1.9811 - acc: 0.3609 - val_loss: 2.5842 - val_acc: 0.2184
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 56s - loss: 1.9425 - acc: 0.3637 - val_loss: 2.5754 - val_acc: 0.2006
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 56s - loss: 1.8865 - acc: 0.3725 - val_loss: 2.0823 - val_acc: 0.3218
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 56s - loss: 1.8317 - acc: 0.3776 - val_loss: 2.0748 - val_acc: 0.3088
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 56s - loss: 1.7938 - acc: 0.3872 - val_loss: 2.0115 - val_acc: 0.3164
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 56s - loss: 1.7420 - acc: 0.3945 - val_loss: 2.0602 - val_acc: 0.2856
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 56s - loss: 1.7053 - acc: 0.4015 - val_loss: 1.9833 - val_acc: 0.2952
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 56s - loss: 1.6823 - acc: 0.4096 - val_loss: 2.7074 - val_acc: 0.1902
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 56s - loss: 1.6488 - acc: 0.4165 - val_loss: 2.5150 - val_acc: 0.1970
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 56s - loss: 1.6280 - acc: 0.4205 - val_loss: 2.3981 - val_acc: 0.2344
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 56s - loss: 1.5923 - acc: 0.4272 - val_loss: 1.9584 - val_acc: 0.3126
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 56s - loss: 1.5718 - acc: 0.4326 - val_loss: 2.3216 - val_acc: 0.2940
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 56s - loss: 1.5485 - acc: 0.4451 - val_loss: 2.0151 - val_acc: 0.2964
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 56s - loss: 1.5186 - acc: 0.4559 - val_loss: 2.2305 - val_acc: 0.2728
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 56s - loss: 1.4988 - acc: 0.4607 - val_loss: 1.9947 - val_acc: 0.3172
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 56s - loss: 1.4692 - acc: 0.4738 - val_loss: 2.5764 - val_acc: 0.1998
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 56s - loss: 1.4593 - acc: 0.4739 - val_loss: 2.9732 - val_acc: 0.1846
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 56s - loss: 1.4424 - acc: 0.4802 - val_loss: 1.7650 - val_acc: 0.3298
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 56s - loss: 1.4392 - acc: 0.4830 - val_loss: 2.1373 - val_acc: 0.2316
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 56s - loss: 1.4327 - acc: 0.4822 - val_loss: 2.6358 - val_acc: 0.1926
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 56s - loss: 1.4158 - acc: 0.4921 - val_loss: 2.3281 - val_acc: 0.2458
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 56s - loss: 1.4051 - acc: 0.4945 - val_loss: 2.5949 - val_acc: 0.2940
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc improved from 0.33680 to 0.34440, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 1.4061 - acc: 0.4944 - val_loss: 1.8033 - val_acc: 0.3444
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 56s - loss: 1.3966 - acc: 0.4958 - val_loss: 3.6147 - val_acc: 0.1548
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 56s - loss: 1.4054 - acc: 0.4943 - val_loss: 2.0174 - val_acc: 0.3178
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc improved from 0.34440 to 0.44340, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 1.3870 - acc: 0.4974 - val_loss: 1.5396 - val_acc: 0.4434
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 56s - loss: 1.3886 - acc: 0.5009 - val_loss: 2.1711 - val_acc: 0.2880
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 56s - loss: 1.3868 - acc: 0.5045 - val_loss: 2.8972 - val_acc: 0.1378
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 56s - loss: 1.3834 - acc: 0.4996 - val_loss: 3.2505 - val_acc: 0.2178
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 56s - loss: 1.3631 - acc: 0.5113 - val_loss: 1.8943 - val_acc: 0.3340
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.44340 to 0.44500, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 1.2445 - acc: 0.5564 - val_loss: 1.5264 - val_acc: 0.4450
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.44500 to 0.52580, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 1.2032 - acc: 0.5702 - val_loss: 1.3216 - val_acc: 0.5258
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc did not improve
 - 56s - loss: 1.1821 - acc: 0.5806 - val_loss: 1.6439 - val_acc: 0.4422
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 56s - loss: 1.1709 - acc: 0.5853 - val_loss: 1.3995 - val_acc: 0.5012
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 56s - loss: 1.1571 - acc: 0.5880 - val_loss: 1.6126 - val_acc: 0.4346
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 56s - loss: 1.1456 - acc: 0.5940 - val_loss: 1.4140 - val_acc: 0.5078
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 56s - loss: 1.1362 - acc: 0.5964 - val_loss: 1.5763 - val_acc: 0.4614
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 56s - loss: 1.1290 - acc: 0.6005 - val_loss: 1.4544 - val_acc: 0.4894
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 56s - loss: 1.1252 - acc: 0.5996 - val_loss: 1.4935 - val_acc: 0.4916
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc improved from 0.52580 to 0.53780, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 1.1153 - acc: 0.6055 - val_loss: 1.3642 - val_acc: 0.5378
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 56s - loss: 1.1100 - acc: 0.6053 - val_loss: 1.5473 - val_acc: 0.4698
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 56s - loss: 1.1061 - acc: 0.6080 - val_loss: 1.4774 - val_acc: 0.4708
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 56s - loss: 1.0948 - acc: 0.6116 - val_loss: 1.7510 - val_acc: 0.4224
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 56s - loss: 1.0910 - acc: 0.6139 - val_loss: 1.3535 - val_acc: 0.5368
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 56s - loss: 1.0856 - acc: 0.6164 - val_loss: 1.6562 - val_acc: 0.4512
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 56s - loss: 1.0770 - acc: 0.6188 - val_loss: 2.3142 - val_acc: 0.3382
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 56s - loss: 1.0748 - acc: 0.6210 - val_loss: 1.4176 - val_acc: 0.5176
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 56s - loss: 1.0653 - acc: 0.6230 - val_loss: 1.6204 - val_acc: 0.4520
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 56s - loss: 1.0623 - acc: 0.6233 - val_loss: 1.6185 - val_acc: 0.4502
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 56s - loss: 1.0607 - acc: 0.6243 - val_loss: 1.6131 - val_acc: 0.4340
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 56s - loss: 1.0520 - acc: 0.6291 - val_loss: 1.3880 - val_acc: 0.5342
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 56s - loss: 1.0508 - acc: 0.6270 - val_loss: 1.7463 - val_acc: 0.4384
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc improved from 0.53780 to 0.55660, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 1.0423 - acc: 0.6338 - val_loss: 1.2665 - val_acc: 0.5566
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 56s - loss: 1.0414 - acc: 0.6329 - val_loss: 1.6297 - val_acc: 0.4734
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 56s - loss: 1.0388 - acc: 0.6333 - val_loss: 2.0218 - val_acc: 0.3898
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 56s - loss: 1.0376 - acc: 0.6355 - val_loss: 1.7189 - val_acc: 0.4128
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 56s - loss: 1.0289 - acc: 0.6374 - val_loss: 1.4928 - val_acc: 0.5094
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 56s - loss: 1.0190 - acc: 0.6418 - val_loss: 2.0288 - val_acc: 0.3574
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 56s - loss: 1.0225 - acc: 0.6390 - val_loss: 1.7974 - val_acc: 0.4316
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 56s - loss: 1.0059 - acc: 0.6442 - val_loss: 1.4020 - val_acc: 0.5268
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 56s - loss: 1.0095 - acc: 0.6438 - val_loss: 1.8236 - val_acc: 0.4412
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 56s - loss: 1.0092 - acc: 0.6426 - val_loss: 1.3952 - val_acc: 0.5236
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 56s - loss: 1.0058 - acc: 0.6464 - val_loss: 1.7059 - val_acc: 0.4680
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 56s - loss: 1.0084 - acc: 0.6429 - val_loss: 1.7652 - val_acc: 0.4532
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 56s - loss: 1.0058 - acc: 0.6458 - val_loss: 1.6325 - val_acc: 0.4788
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 56s - loss: 0.9958 - acc: 0.6484 - val_loss: 1.3154 - val_acc: 0.5402
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 56s - loss: 0.9997 - acc: 0.6455 - val_loss: 1.3533 - val_acc: 0.5346
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 56s - loss: 0.9961 - acc: 0.6504 - val_loss: 1.2873 - val_acc: 0.5464
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 56s - loss: 0.9968 - acc: 0.6497 - val_loss: 1.7159 - val_acc: 0.4688
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 56s - loss: 0.9935 - acc: 0.6480 - val_loss: 1.7335 - val_acc: 0.4518
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc improved from 0.55660 to 0.61560, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.9199 - acc: 0.6752 - val_loss: 1.0962 - val_acc: 0.6156
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc improved from 0.61560 to 0.64740, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.8854 - acc: 0.6880 - val_loss: 1.0158 - val_acc: 0.6474
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 55s - loss: 0.8741 - acc: 0.6919 - val_loss: 1.1841 - val_acc: 0.6000
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc improved from 0.64740 to 0.66100, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.8684 - acc: 0.6945 - val_loss: 0.9963 - val_acc: 0.6610
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 56s - loss: 0.8587 - acc: 0.6990 - val_loss: 1.0533 - val_acc: 0.6338
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 56s - loss: 0.8515 - acc: 0.6978 - val_loss: 1.0285 - val_acc: 0.6536
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 56s - loss: 0.8530 - acc: 0.6998 - val_loss: 1.0458 - val_acc: 0.6338
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc improved from 0.66100 to 0.66500, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.8418 - acc: 0.7044 - val_loss: 0.9765 - val_acc: 0.6650
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 56s - loss: 0.8436 - acc: 0.7045 - val_loss: 0.9928 - val_acc: 0.6566
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 56s - loss: 0.8397 - acc: 0.7026 - val_loss: 1.0095 - val_acc: 0.6470
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 56s - loss: 0.8406 - acc: 0.7041 - val_loss: 1.0723 - val_acc: 0.6294
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 56s - loss: 0.8355 - acc: 0.7054 - val_loss: 0.9964 - val_acc: 0.6580
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 56s - loss: 0.8347 - acc: 0.7069 - val_loss: 1.1273 - val_acc: 0.6228
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 56s - loss: 0.8304 - acc: 0.7096 - val_loss: 1.0789 - val_acc: 0.6268
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc improved from 0.66500 to 0.67060, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.8250 - acc: 0.7095 - val_loss: 0.9469 - val_acc: 0.6706
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 56s - loss: 0.8291 - acc: 0.7075 - val_loss: 1.0376 - val_acc: 0.6452
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 56s - loss: 0.8222 - acc: 0.7101 - val_loss: 1.0185 - val_acc: 0.6504
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 56s - loss: 0.8230 - acc: 0.7113 - val_loss: 1.0282 - val_acc: 0.6502
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc improved from 0.67060 to 0.67140, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.8155 - acc: 0.7121 - val_loss: 0.9380 - val_acc: 0.6714
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc improved from 0.67140 to 0.67380, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.8178 - acc: 0.7105 - val_loss: 0.9453 - val_acc: 0.6738
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 56s - loss: 0.8168 - acc: 0.7128 - val_loss: 1.0763 - val_acc: 0.6294
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 56s - loss: 0.8106 - acc: 0.7163 - val_loss: 1.1326 - val_acc: 0.6222
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 56s - loss: 0.8028 - acc: 0.7187 - val_loss: 1.0331 - val_acc: 0.6416
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 56s - loss: 0.8077 - acc: 0.7144 - val_loss: 1.0580 - val_acc: 0.6424
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 56s - loss: 0.8063 - acc: 0.7179 - val_loss: 1.0064 - val_acc: 0.6496
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 56s - loss: 0.8070 - acc: 0.7159 - val_loss: 1.1014 - val_acc: 0.6266
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 56s - loss: 0.8038 - acc: 0.7187 - val_loss: 1.2710 - val_acc: 0.5940
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 56s - loss: 0.8017 - acc: 0.7160 - val_loss: 1.6022 - val_acc: 0.5068
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 56s - loss: 0.8060 - acc: 0.7164 - val_loss: 0.9573 - val_acc: 0.6692
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 56s - loss: 0.7957 - acc: 0.7207 - val_loss: 1.1025 - val_acc: 0.6316
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 56s - loss: 0.7892 - acc: 0.7211 - val_loss: 1.0392 - val_acc: 0.6514
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 56s - loss: 0.7923 - acc: 0.7219 - val_loss: 1.1415 - val_acc: 0.6070
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 56s - loss: 0.7937 - acc: 0.7209 - val_loss: 1.0406 - val_acc: 0.6414
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 56s - loss: 0.7934 - acc: 0.7214 - val_loss: 0.9858 - val_acc: 0.6548
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 56s - loss: 0.7897 - acc: 0.7216 - val_loss: 1.1416 - val_acc: 0.6252
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 56s - loss: 0.7790 - acc: 0.7265 - val_loss: 0.9952 - val_acc: 0.6626
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc improved from 0.67380 to 0.67420, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.7737 - acc: 0.7282 - val_loss: 0.9357 - val_acc: 0.6742
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 56s - loss: 0.7789 - acc: 0.7267 - val_loss: 1.1634 - val_acc: 0.6138
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 56s - loss: 0.7855 - acc: 0.7249 - val_loss: 1.0247 - val_acc: 0.6540
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 56s - loss: 0.7714 - acc: 0.7278 - val_loss: 1.0361 - val_acc: 0.6512
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc improved from 0.67420 to 0.69380, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.7397 - acc: 0.7398 - val_loss: 0.8940 - val_acc: 0.6938
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc improved from 0.69380 to 0.69680, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.7327 - acc: 0.7404 - val_loss: 0.8955 - val_acc: 0.6968
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 56s - loss: 0.7231 - acc: 0.7464 - val_loss: 0.9402 - val_acc: 0.6798
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 56s - loss: 0.7279 - acc: 0.7446 - val_loss: 0.9018 - val_acc: 0.6902
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 56s - loss: 0.7292 - acc: 0.7431 - val_loss: 0.9157 - val_acc: 0.6814
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc improved from 0.69680 to 0.69700, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.7196 - acc: 0.7502 - val_loss: 0.8878 - val_acc: 0.6970
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 56s - loss: 0.7232 - acc: 0.7462 - val_loss: 0.9500 - val_acc: 0.6776
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 56s - loss: 0.7219 - acc: 0.7454 - val_loss: 0.9316 - val_acc: 0.6850
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 56s - loss: 0.7244 - acc: 0.7460 - val_loss: 0.9493 - val_acc: 0.6670
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 56s - loss: 0.7223 - acc: 0.7472 - val_loss: 0.9479 - val_acc: 0.6820
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 56s - loss: 0.7221 - acc: 0.7481 - val_loss: 0.9332 - val_acc: 0.6830
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 56s - loss: 0.7160 - acc: 0.7504 - val_loss: 0.9625 - val_acc: 0.6752
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 56s - loss: 0.7115 - acc: 0.7500 - val_loss: 0.9317 - val_acc: 0.6854
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 56s - loss: 0.7171 - acc: 0.7494 - val_loss: 0.9501 - val_acc: 0.6706
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 56s - loss: 0.7235 - acc: 0.7458 - val_loss: 1.0211 - val_acc: 0.6530
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 56s - loss: 0.7219 - acc: 0.7453 - val_loss: 0.9587 - val_acc: 0.6704
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 56s - loss: 0.7191 - acc: 0.7457 - val_loss: 1.0040 - val_acc: 0.6592
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 56s - loss: 0.7172 - acc: 0.7460 - val_loss: 0.8982 - val_acc: 0.6928
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 56s - loss: 0.7128 - acc: 0.7486 - val_loss: 0.9265 - val_acc: 0.6844
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 56s - loss: 0.7103 - acc: 0.7492 - val_loss: 0.9525 - val_acc: 0.6774
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 56s - loss: 0.7067 - acc: 0.7529 - val_loss: 0.9693 - val_acc: 0.6756
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 56s - loss: 0.7073 - acc: 0.7512 - val_loss: 0.9306 - val_acc: 0.6858
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 56s - loss: 0.7067 - acc: 0.7516 - val_loss: 0.9138 - val_acc: 0.6854
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 56s - loss: 0.7036 - acc: 0.7545 - val_loss: 0.9113 - val_acc: 0.6880
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 56s - loss: 0.7059 - acc: 0.7534 - val_loss: 0.9207 - val_acc: 0.6842
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 56s - loss: 0.7084 - acc: 0.7519 - val_loss: 0.9115 - val_acc: 0.6940
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 56s - loss: 0.7074 - acc: 0.7519 - val_loss: 0.8968 - val_acc: 0.6930
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 56s - loss: 0.7091 - acc: 0.7501 - val_loss: 0.9565 - val_acc: 0.6642
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 56s - loss: 0.7097 - acc: 0.7513 - val_loss: 0.9581 - val_acc: 0.6728
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 56s - loss: 0.7062 - acc: 0.7529 - val_loss: 0.9672 - val_acc: 0.6724
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 56s - loss: 0.7046 - acc: 0.7516 - val_loss: 1.0303 - val_acc: 0.6614
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 56s - loss: 0.7073 - acc: 0.7525 - val_loss: 0.9648 - val_acc: 0.6744
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 56s - loss: 0.7089 - acc: 0.7493 - val_loss: 1.0163 - val_acc: 0.6554
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 56s - loss: 0.7087 - acc: 0.7507 - val_loss: 0.9574 - val_acc: 0.6748
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 56s - loss: 0.6996 - acc: 0.7544 - val_loss: 0.8914 - val_acc: 0.6968
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 56s - loss: 0.7032 - acc: 0.7537 - val_loss: 0.9537 - val_acc: 0.6716
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 56s - loss: 0.7006 - acc: 0.7523 - val_loss: 0.9564 - val_acc: 0.6748
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc improved from 0.69700 to 0.70060, saving model to ./weights/CIFAR-10_full-tnn_4b_4b_1_64_1_128_1_256.hdf5
 - 58s - loss: 0.7054 - acc: 0.7517 - val_loss: 0.8943 - val_acc: 0.7006
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 56s - loss: 0.7034 - acc: 0.7544 - val_loss: 0.9937 - val_acc: 0.6708
Done

