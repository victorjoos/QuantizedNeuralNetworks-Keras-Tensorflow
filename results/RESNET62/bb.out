Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
binary_conv2d_1 (BinaryConv2D)  (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_1[0][0]            
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
binary_conv2d_2 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_2[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
binary_conv2d_3 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_3[0][0]            
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_4 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_4[0][0]            
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
binary_conv2d_5 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_5[0][0]            
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_6 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_6[0][0]            
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
binary_conv2d_7 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_7[0][0]            
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_8 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_8[0][0]            
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
binary_conv2d_9 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_9[0][0]            
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_10 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_10[0][0]           
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
binary_conv2d_11 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_11[0][0]           
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_12 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_12[0][0]           
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
binary_conv2d_13 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_13[0][0]           
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 16)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_14 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_14[0][0]           
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
binary_conv2d_15 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_15[0][0]           
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 16)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_16 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_16[0][0]           
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
binary_conv2d_17 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_17[0][0]           
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 16)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_18 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_18[0][0]           
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
binary_conv2d_19 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_19[0][0]           
__________________________________________________________________________________________________
add_9 (Add)                     (None, 32, 32, 16)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 32, 32, 16)   0           add_9[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_20 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_20[0][0]           
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
binary_conv2d_21 (BinaryConv2D) (None, 32, 32, 16)   2320        activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          binary_conv2d_21[0][0]           
__________________________________________________________________________________________________
add_10 (Add)                    (None, 32, 32, 16)   0           activation_19[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 16)   0           add_10[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_22 (BinaryConv2D) (None, 16, 16, 32)   4640        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_22[0][0]           
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
binary_conv2d_23 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_22[0][0]              
__________________________________________________________________________________________________
binary_conv2d_24 (BinaryConv2D) (None, 16, 16, 32)   544         activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_23[0][0]           
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 32)   0           binary_conv2d_24[0][0]           
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_25 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_25[0][0]           
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
binary_conv2d_26 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_26[0][0]           
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 32)   0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 16, 16, 32)   0           add_12[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_27 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_27[0][0]           
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
binary_conv2d_28 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_28[0][0]           
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 32)   0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_29 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_29[0][0]           
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
binary_conv2d_30 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_30[0][0]           
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 32)   0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_31 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_31[0][0]           
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
binary_conv2d_32 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_32[0][0]           
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 32)   0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_33 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_31[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_33[0][0]           
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
binary_conv2d_34 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_32[0][0]              
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_34[0][0]           
__________________________________________________________________________________________________
add_16 (Add)                    (None, 16, 16, 32)   0           activation_31[0][0]              
                                                                 batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 16, 16, 32)   0           add_16[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_35 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_33[0][0]              
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_35[0][0]           
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
binary_conv2d_36 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_36[0][0]           
__________________________________________________________________________________________________
add_17 (Add)                    (None, 16, 16, 32)   0           activation_33[0][0]              
                                                                 batch_normalization_35[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 16, 16, 32)   0           add_17[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_37 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_37[0][0]           
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
binary_conv2d_38 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_38[0][0]           
__________________________________________________________________________________________________
add_18 (Add)                    (None, 16, 16, 32)   0           activation_35[0][0]              
                                                                 batch_normalization_37[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 16, 16, 32)   0           add_18[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_39 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_39[0][0]           
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 16, 16, 32)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
binary_conv2d_40 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_38[0][0]              
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_40[0][0]           
__________________________________________________________________________________________________
add_19 (Add)                    (None, 16, 16, 32)   0           activation_37[0][0]              
                                                                 batch_normalization_39[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 16, 16, 32)   0           add_19[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_41 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_39[0][0]              
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_41[0][0]           
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 16, 16, 32)   0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
binary_conv2d_42 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_40[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_42[0][0]           
__________________________________________________________________________________________________
add_20 (Add)                    (None, 16, 16, 32)   0           activation_39[0][0]              
                                                                 batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 16, 16, 32)   0           add_20[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_43 (BinaryConv2D) (None, 8, 8, 64)     18496       activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_43[0][0]           
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
binary_conv2d_44 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_42[0][0]              
__________________________________________________________________________________________________
binary_conv2d_45 (BinaryConv2D) (None, 8, 8, 64)     2112        activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_44[0][0]           
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 8, 64)     0           binary_conv2d_45[0][0]           
                                                                 batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 8, 8, 64)     0           add_21[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_46 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_43[0][0]              
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_46[0][0]           
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
binary_conv2d_47 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_47[0][0]           
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 8, 64)     0           activation_43[0][0]              
                                                                 batch_normalization_45[0][0]     
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 8, 8, 64)     0           add_22[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_48 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_48[0][0]           
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
binary_conv2d_49 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_49[0][0]           
__________________________________________________________________________________________________
add_23 (Add)                    (None, 8, 8, 64)     0           activation_45[0][0]              
                                                                 batch_normalization_47[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 8, 8, 64)     0           add_23[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_50 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_50[0][0]           
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
binary_conv2d_51 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_48[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_51[0][0]           
__________________________________________________________________________________________________
add_24 (Add)                    (None, 8, 8, 64)     0           activation_47[0][0]              
                                                                 batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 8, 8, 64)     0           add_24[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_52 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_49[0][0]              
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_52[0][0]           
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
binary_conv2d_53 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_50[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_53[0][0]           
__________________________________________________________________________________________________
add_25 (Add)                    (None, 8, 8, 64)     0           activation_49[0][0]              
                                                                 batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_54 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_51[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_54[0][0]           
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
binary_conv2d_55 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_52[0][0]              
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_55[0][0]           
__________________________________________________________________________________________________
add_26 (Add)                    (None, 8, 8, 64)     0           activation_51[0][0]              
                                                                 batch_normalization_53[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_56 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_53[0][0]              
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_56[0][0]           
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
binary_conv2d_57 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_54[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_57[0][0]           
__________________________________________________________________________________________________
add_27 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              
                                                                 batch_normalization_55[0][0]     
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 8, 8, 64)     0           add_27[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_58 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_55[0][0]              
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_58[0][0]           
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
binary_conv2d_59 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_56[0][0]              
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_59[0][0]           
__________________________________________________________________________________________________
add_28 (Add)                    (None, 8, 8, 64)     0           activation_55[0][0]              
                                                                 batch_normalization_57[0][0]     
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 8, 8, 64)     0           add_28[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_60 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_57[0][0]              
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_60[0][0]           
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 8, 8, 64)     0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
binary_conv2d_61 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_58[0][0]              
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_61[0][0]           
__________________________________________________________________________________________________
add_29 (Add)                    (None, 8, 8, 64)     0           activation_57[0][0]              
                                                                 batch_normalization_59[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 8, 8, 64)     0           add_29[0][0]                     
__________________________________________________________________________________________________
binary_conv2d_62 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_59[0][0]              
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_62[0][0]           
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 8, 8, 64)     0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
binary_conv2d_63 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_60[0][0]              
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_63[0][0]           
__________________________________________________________________________________________________
add_30 (Add)                    (None, 8, 8, 64)     0           activation_59[0][0]              
                                                                 batch_normalization_61[0][0]     
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 8, 8, 64)     0           add_30[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_61[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
binary_dense_2 (BinaryDense)    (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 959,658
Trainable params: 955,146
Non-trainable params: 4,512
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.09940, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 143s - loss: 33.7976 - acc: 0.1001 - val_loss: 33.2910 - val_acc: 0.0994
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.09940 to 0.10180, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 59s - loss: 32.8133 - acc: 0.1001 - val_loss: 32.3529 - val_acc: 0.1018
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc did not improve
 - 58s - loss: 31.8638 - acc: 0.1011 - val_loss: 31.3850 - val_acc: 0.0946
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc did not improve
 - 58s - loss: 30.9250 - acc: 0.1011 - val_loss: 30.4497 - val_acc: 0.1006
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc did not improve
 - 58s - loss: 29.9942 - acc: 0.1020 - val_loss: 29.5519 - val_acc: 0.0960
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc improved from 0.10180 to 0.10400, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 29.0631 - acc: 0.1022 - val_loss: 28.5814 - val_acc: 0.1040
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.10400 to 0.10740, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 28.1126 - acc: 0.1009 - val_loss: 27.6267 - val_acc: 0.1074
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc did not improve
 - 58s - loss: 27.1282 - acc: 0.0986 - val_loss: 26.6145 - val_acc: 0.1042
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 58s - loss: 26.0957 - acc: 0.1001 - val_loss: 25.5607 - val_acc: 0.0980
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 58s - loss: 25.0161 - acc: 0.1000 - val_loss: 24.4434 - val_acc: 0.1026
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 58s - loss: 23.8773 - acc: 0.1002 - val_loss: 23.2681 - val_acc: 0.0952
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc improved from 0.10740 to 0.11000, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 22.6661 - acc: 0.0991 - val_loss: 22.0301 - val_acc: 0.1100
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc did not improve
 - 58s - loss: 21.3969 - acc: 0.1002 - val_loss: 20.7309 - val_acc: 0.1000
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 58s - loss: 20.0871 - acc: 0.1021 - val_loss: 19.4206 - val_acc: 0.0964
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc did not improve
 - 58s - loss: 18.7697 - acc: 0.1021 - val_loss: 18.1039 - val_acc: 0.0992
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 58s - loss: 17.4708 - acc: 0.1008 - val_loss: 16.8165 - val_acc: 0.1016
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 58s - loss: 16.2048 - acc: 0.0993 - val_loss: 15.5787 - val_acc: 0.1042
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 58s - loss: 14.9958 - acc: 0.0998 - val_loss: 14.4049 - val_acc: 0.0986
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 58s - loss: 13.8456 - acc: 0.1008 - val_loss: 13.2799 - val_acc: 0.1050
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 58s - loss: 12.7613 - acc: 0.0984 - val_loss: 12.2487 - val_acc: 0.0916
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 58s - loss: 11.7466 - acc: 0.0988 - val_loss: 11.2806 - val_acc: 0.0990
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 58s - loss: 10.8050 - acc: 0.1011 - val_loss: 10.3589 - val_acc: 0.1034
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 58s - loss: 9.9444 - acc: 0.0986 - val_loss: 9.5397 - val_acc: 0.0934
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 58s - loss: 9.1584 - acc: 0.1000 - val_loss: 8.7923 - val_acc: 0.0974
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 58s - loss: 8.4471 - acc: 0.1010 - val_loss: 8.1215 - val_acc: 0.0976
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 58s - loss: 7.8154 - acc: 0.1033 - val_loss: 7.5335 - val_acc: 0.0984
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 58s - loss: 7.2525 - acc: 0.0996 - val_loss: 6.9940 - val_acc: 0.0936
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 58s - loss: 6.7464 - acc: 0.1008 - val_loss: 6.5174 - val_acc: 0.0958
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 58s - loss: 6.2991 - acc: 0.0997 - val_loss: 6.0824 - val_acc: 0.1048
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 58s - loss: 5.8979 - acc: 0.0992 - val_loss: 5.7041 - val_acc: 0.0940
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 58s - loss: 5.5460 - acc: 0.1007 - val_loss: 5.3767 - val_acc: 0.0988
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 58s - loss: 5.2360 - acc: 0.0998 - val_loss: 5.0870 - val_acc: 0.0952
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 58s - loss: 4.9544 - acc: 0.0997 - val_loss: 4.8117 - val_acc: 0.1024
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 58s - loss: 4.6982 - acc: 0.0985 - val_loss: 4.5780 - val_acc: 0.1002
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 58s - loss: 4.4615 - acc: 0.0965 - val_loss: 4.3492 - val_acc: 0.0984
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 58s - loss: 4.2472 - acc: 0.1022 - val_loss: 4.1441 - val_acc: 0.0974
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 58s - loss: 4.0540 - acc: 0.0989 - val_loss: 3.9678 - val_acc: 0.1056
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 58s - loss: 3.8806 - acc: 0.1010 - val_loss: 3.8000 - val_acc: 0.0926
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 58s - loss: 3.7323 - acc: 0.0975 - val_loss: 3.6590 - val_acc: 0.0978
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 58s - loss: 3.5985 - acc: 0.0989 - val_loss: 3.5375 - val_acc: 0.0872
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc improved from 0.11000 to 0.16500, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 3.4563 - acc: 0.1258 - val_loss: 3.3724 - val_acc: 0.1650
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 58s - loss: 3.3491 - acc: 0.1525 - val_loss: 3.3662 - val_acc: 0.1118
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc improved from 0.16500 to 0.16740, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 3.2774 - acc: 0.1487 - val_loss: 3.2277 - val_acc: 0.1674
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc improved from 0.16740 to 0.17400, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 3.1742 - acc: 0.1738 - val_loss: 3.1322 - val_acc: 0.1740
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 58s - loss: 3.0448 - acc: 0.1984 - val_loss: 3.1985 - val_acc: 0.1312
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 58s - loss: 2.9485 - acc: 0.1976 - val_loss: 3.0471 - val_acc: 0.1720
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 58s - loss: 2.8669 - acc: 0.2062 - val_loss: 3.1354 - val_acc: 0.1422
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 58s - loss: 2.8174 - acc: 0.2009 - val_loss: 3.0881 - val_acc: 0.1530
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 58s - loss: 2.7322 - acc: 0.2139 - val_loss: 2.9202 - val_acc: 0.1504
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc improved from 0.17400 to 0.21940, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 2.6487 - acc: 0.2334 - val_loss: 2.6708 - val_acc: 0.2194
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 58s - loss: 2.5823 - acc: 0.2423 - val_loss: 3.2606 - val_acc: 0.1232
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 58s - loss: 2.5454 - acc: 0.2400 - val_loss: 2.6608 - val_acc: 0.1978
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 58s - loss: 2.5403 - acc: 0.2250 - val_loss: 2.6007 - val_acc: 0.2078
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 58s - loss: 2.4848 - acc: 0.2405 - val_loss: 3.2989 - val_acc: 0.0986
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 58s - loss: 2.4846 - acc: 0.2291 - val_loss: 2.9749 - val_acc: 0.1360
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 58s - loss: 2.4396 - acc: 0.2318 - val_loss: 2.5752 - val_acc: 0.1728
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 58s - loss: 2.4837 - acc: 0.2092 - val_loss: 2.7313 - val_acc: 0.1538
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 58s - loss: 2.4261 - acc: 0.2258 - val_loss: 2.4765 - val_acc: 0.2134
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 58s - loss: 2.4583 - acc: 0.2068 - val_loss: 2.4824 - val_acc: 0.1926
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 58s - loss: 2.4914 - acc: 0.1758 - val_loss: 3.1715 - val_acc: 0.1026
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc improved from 0.21940 to 0.22680, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 2.4249 - acc: 0.1976 - val_loss: 2.4245 - val_acc: 0.2268
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 58s - loss: 2.4072 - acc: 0.2016 - val_loss: 2.6327 - val_acc: 0.1904
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 58s - loss: 2.4420 - acc: 0.1777 - val_loss: 2.5318 - val_acc: 0.1934
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 58s - loss: 2.4428 - acc: 0.1790 - val_loss: 2.5898 - val_acc: 0.1660
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 58s - loss: 2.4732 - acc: 0.1617 - val_loss: 2.4660 - val_acc: 0.1834
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 58s - loss: 2.4792 - acc: 0.1499 - val_loss: 2.5024 - val_acc: 0.1308
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 58s - loss: 2.4216 - acc: 0.1778 - val_loss: 2.6742 - val_acc: 0.1034
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 58s - loss: 2.4202 - acc: 0.1723 - val_loss: 2.4733 - val_acc: 0.2094
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 58s - loss: 2.4102 - acc: 0.1859 - val_loss: 2.5343 - val_acc: 0.1492
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 58s - loss: 2.3704 - acc: 0.1977 - val_loss: 2.3819 - val_acc: 0.2086
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 58s - loss: 2.3230 - acc: 0.2099 - val_loss: 2.4225 - val_acc: 0.1768
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 58s - loss: 2.3609 - acc: 0.1911 - val_loss: 2.4717 - val_acc: 0.1902
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 58s - loss: 2.3310 - acc: 0.2038 - val_loss: 2.6506 - val_acc: 0.1086
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 58s - loss: 2.3736 - acc: 0.1770 - val_loss: 2.4661 - val_acc: 0.1604
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 58s - loss: 2.3997 - acc: 0.1674 - val_loss: 2.6968 - val_acc: 0.1046
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 58s - loss: 2.3378 - acc: 0.1852 - val_loss: 2.5978 - val_acc: 0.1338
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 58s - loss: 2.3384 - acc: 0.1866 - val_loss: 3.0011 - val_acc: 0.1080
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 58s - loss: 2.3575 - acc: 0.1832 - val_loss: 2.3249 - val_acc: 0.1920
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 58s - loss: 2.3263 - acc: 0.1945 - val_loss: 2.3630 - val_acc: 0.1704
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 58s - loss: 2.3684 - acc: 0.1684 - val_loss: 2.4119 - val_acc: 0.1446
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 58s - loss: 2.3459 - acc: 0.1780 - val_loss: 2.5366 - val_acc: 0.1054
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.22680 to 0.23780, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 2.2451 - acc: 0.2168 - val_loss: 2.2066 - val_acc: 0.2378
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.23780 to 0.24360, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 2.1598 - acc: 0.2528 - val_loss: 2.1940 - val_acc: 0.2436
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc improved from 0.24360 to 0.25240, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 2.1499 - acc: 0.2560 - val_loss: 2.2994 - val_acc: 0.2524
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 58s - loss: 2.2178 - acc: 0.2231 - val_loss: 2.6031 - val_acc: 0.1254
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 58s - loss: 2.2059 - acc: 0.2330 - val_loss: 2.3901 - val_acc: 0.1992
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 58s - loss: 2.2117 - acc: 0.2305 - val_loss: 2.3677 - val_acc: 0.1812
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 58s - loss: 2.1621 - acc: 0.2506 - val_loss: 2.1885 - val_acc: 0.2402
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 58s - loss: 2.1662 - acc: 0.2473 - val_loss: 2.4835 - val_acc: 0.1592
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 58s - loss: 2.1763 - acc: 0.2347 - val_loss: 2.3206 - val_acc: 0.1862
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 58s - loss: 2.2041 - acc: 0.2277 - val_loss: 2.3692 - val_acc: 0.1730
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 58s - loss: 2.1685 - acc: 0.2388 - val_loss: 2.5409 - val_acc: 0.1736
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 58s - loss: 2.1869 - acc: 0.2380 - val_loss: 2.2952 - val_acc: 0.1968
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 58s - loss: 2.2078 - acc: 0.2129 - val_loss: 2.3860 - val_acc: 0.1908
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 58s - loss: 2.1880 - acc: 0.2249 - val_loss: 2.2686 - val_acc: 0.2036
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 58s - loss: 2.1447 - acc: 0.2448 - val_loss: 2.2954 - val_acc: 0.2078
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 58s - loss: 2.1271 - acc: 0.2518 - val_loss: 2.0998 - val_acc: 0.2512
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 58s - loss: 2.1386 - acc: 0.2445 - val_loss: 2.2862 - val_acc: 0.1924
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 58s - loss: 2.1927 - acc: 0.2253 - val_loss: 2.2180 - val_acc: 0.2124
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 58s - loss: 2.1516 - acc: 0.2391 - val_loss: 2.2443 - val_acc: 0.2110
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 58s - loss: 2.1408 - acc: 0.2422 - val_loss: 2.4580 - val_acc: 0.1680
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 58s - loss: 2.0963 - acc: 0.2558 - val_loss: 2.5111 - val_acc: 0.1668
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 58s - loss: 2.1075 - acc: 0.2520 - val_loss: 2.3066 - val_acc: 0.1990
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 58s - loss: 2.0846 - acc: 0.2655 - val_loss: 2.6808 - val_acc: 0.1502
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 58s - loss: 2.0781 - acc: 0.2661 - val_loss: 2.1789 - val_acc: 0.2270
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 58s - loss: 2.0457 - acc: 0.2755 - val_loss: 2.4486 - val_acc: 0.1474
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 58s - loss: 2.0122 - acc: 0.2869 - val_loss: 2.2044 - val_acc: 0.2348
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 58s - loss: 2.0144 - acc: 0.2887 - val_loss: 2.3255 - val_acc: 0.2106
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 58s - loss: 2.1028 - acc: 0.2568 - val_loss: 2.7400 - val_acc: 0.1398
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 58s - loss: 2.1130 - acc: 0.2534 - val_loss: 2.3227 - val_acc: 0.2222
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc improved from 0.25240 to 0.26780, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 2.0425 - acc: 0.2751 - val_loss: 2.0445 - val_acc: 0.2678
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 58s - loss: 2.0069 - acc: 0.2936 - val_loss: 2.2005 - val_acc: 0.2518
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc improved from 0.26780 to 0.27340, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 2.0079 - acc: 0.2907 - val_loss: 2.0496 - val_acc: 0.2734
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 58s - loss: 1.9774 - acc: 0.3004 - val_loss: 2.1546 - val_acc: 0.2516
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc improved from 0.27340 to 0.27540, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.9668 - acc: 0.3049 - val_loss: 1.9928 - val_acc: 0.2754
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc improved from 0.27540 to 0.29180, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 2.0080 - acc: 0.2925 - val_loss: 2.0035 - val_acc: 0.2918
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 58s - loss: 1.9959 - acc: 0.2982 - val_loss: 2.0428 - val_acc: 0.2850
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 58s - loss: 2.0643 - acc: 0.2735 - val_loss: 2.1431 - val_acc: 0.2392
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 58s - loss: 2.0831 - acc: 0.2572 - val_loss: 2.5209 - val_acc: 0.1866
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 58s - loss: 2.1166 - acc: 0.2435 - val_loss: 2.2586 - val_acc: 0.2162
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 58s - loss: 2.0240 - acc: 0.2816 - val_loss: 2.0029 - val_acc: 0.2778
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc improved from 0.29180 to 0.31800, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.9206 - acc: 0.3132 - val_loss: 1.9106 - val_acc: 0.3180
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 58s - loss: 1.9261 - acc: 0.3151 - val_loss: 1.9192 - val_acc: 0.3136
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 58s - loss: 1.9124 - acc: 0.3182 - val_loss: 1.9125 - val_acc: 0.3132
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc improved from 0.31800 to 0.31880, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.9048 - acc: 0.3241 - val_loss: 1.9197 - val_acc: 0.3188
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 58s - loss: 1.8960 - acc: 0.3273 - val_loss: 1.9162 - val_acc: 0.3164
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 58s - loss: 1.8972 - acc: 0.3290 - val_loss: 1.9394 - val_acc: 0.3074
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc improved from 0.31880 to 0.32400, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8939 - acc: 0.3290 - val_loss: 1.8829 - val_acc: 0.3240
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 58s - loss: 1.8971 - acc: 0.3280 - val_loss: 1.9363 - val_acc: 0.3228
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 58s - loss: 1.8882 - acc: 0.3308 - val_loss: 1.9683 - val_acc: 0.3068
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc improved from 0.32400 to 0.33480, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8796 - acc: 0.3340 - val_loss: 1.8756 - val_acc: 0.3348
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 58s - loss: 1.8642 - acc: 0.3393 - val_loss: 1.8815 - val_acc: 0.3340
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 58s - loss: 1.8632 - acc: 0.3378 - val_loss: 1.8605 - val_acc: 0.3304
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc improved from 0.33480 to 0.33720, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8550 - acc: 0.3456 - val_loss: 1.8902 - val_acc: 0.3372
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 58s - loss: 1.8595 - acc: 0.3414 - val_loss: 1.8807 - val_acc: 0.3338
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 58s - loss: 1.8583 - acc: 0.3442 - val_loss: 1.9799 - val_acc: 0.3082
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc improved from 0.33720 to 0.33820, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8568 - acc: 0.3449 - val_loss: 1.8579 - val_acc: 0.3382
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 58s - loss: 1.8545 - acc: 0.3474 - val_loss: 1.9389 - val_acc: 0.3192
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 58s - loss: 1.8557 - acc: 0.3497 - val_loss: 1.8535 - val_acc: 0.3382
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 58s - loss: 1.8527 - acc: 0.3470 - val_loss: 1.8480 - val_acc: 0.3378
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc improved from 0.33820 to 0.34380, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8501 - acc: 0.3514 - val_loss: 1.8555 - val_acc: 0.3438
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc improved from 0.34380 to 0.34660, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8476 - acc: 0.3502 - val_loss: 1.8545 - val_acc: 0.3466
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 58s - loss: 1.8578 - acc: 0.3443 - val_loss: 1.9718 - val_acc: 0.3054
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 58s - loss: 1.8521 - acc: 0.3474 - val_loss: 1.8577 - val_acc: 0.3276
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 58s - loss: 1.8311 - acc: 0.3568 - val_loss: 1.8909 - val_acc: 0.3314
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc improved from 0.34660 to 0.35360, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8220 - acc: 0.3605 - val_loss: 1.8201 - val_acc: 0.3536
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc improved from 0.35360 to 0.35880, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8235 - acc: 0.3631 - val_loss: 1.7892 - val_acc: 0.3588
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc improved from 0.35880 to 0.36000, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8337 - acc: 0.3551 - val_loss: 1.8383 - val_acc: 0.3600
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 58s - loss: 1.8487 - acc: 0.3518 - val_loss: 1.8874 - val_acc: 0.3452
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 58s - loss: 1.8299 - acc: 0.3598 - val_loss: 1.8645 - val_acc: 0.3338
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 58s - loss: 1.8190 - acc: 0.3625 - val_loss: 1.9031 - val_acc: 0.3298
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc improved from 0.36000 to 0.36360, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8313 - acc: 0.3574 - val_loss: 1.8176 - val_acc: 0.3636
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 58s - loss: 1.8127 - acc: 0.3678 - val_loss: 1.8287 - val_acc: 0.3536
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 58s - loss: 1.8131 - acc: 0.3658 - val_loss: 1.9305 - val_acc: 0.3272
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 58s - loss: 1.8168 - acc: 0.3632 - val_loss: 1.9047 - val_acc: 0.3238
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 58s - loss: 1.8185 - acc: 0.3636 - val_loss: 1.8285 - val_acc: 0.3558
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 58s - loss: 1.8078 - acc: 0.3681 - val_loss: 1.8499 - val_acc: 0.3552
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 58s - loss: 1.8160 - acc: 0.3659 - val_loss: 2.1200 - val_acc: 0.2852
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 58s - loss: 1.8121 - acc: 0.3679 - val_loss: 1.8176 - val_acc: 0.3494
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 58s - loss: 1.8451 - acc: 0.3520 - val_loss: 2.0085 - val_acc: 0.2986
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc improved from 0.36360 to 0.36580, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.8345 - acc: 0.3596 - val_loss: 1.7931 - val_acc: 0.3658
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 58s - loss: 1.7894 - acc: 0.3729 - val_loss: 1.7949 - val_acc: 0.3634
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 58s - loss: 1.7908 - acc: 0.3737 - val_loss: 1.7976 - val_acc: 0.3584
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 58s - loss: 1.7931 - acc: 0.3728 - val_loss: 1.7805 - val_acc: 0.3600
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc improved from 0.36580 to 0.37240, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.7971 - acc: 0.3686 - val_loss: 1.7903 - val_acc: 0.3724
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc improved from 0.37240 to 0.38020, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.7855 - acc: 0.3748 - val_loss: 1.7546 - val_acc: 0.3802
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 58s - loss: 1.7906 - acc: 0.3746 - val_loss: 1.7945 - val_acc: 0.3708
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 58s - loss: 1.7870 - acc: 0.3733 - val_loss: 1.7820 - val_acc: 0.3716
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 58s - loss: 1.7873 - acc: 0.3783 - val_loss: 1.7896 - val_acc: 0.3756
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 58s - loss: 1.7916 - acc: 0.3715 - val_loss: 1.7931 - val_acc: 0.3672
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 58s - loss: 1.7887 - acc: 0.3713 - val_loss: 1.8651 - val_acc: 0.3548
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 58s - loss: 1.7855 - acc: 0.3746 - val_loss: 1.7679 - val_acc: 0.3708
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 58s - loss: 1.7822 - acc: 0.3789 - val_loss: 1.8040 - val_acc: 0.3562
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 58s - loss: 1.7692 - acc: 0.3790 - val_loss: 1.7472 - val_acc: 0.3760
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 58s - loss: 1.7690 - acc: 0.3797 - val_loss: 1.7928 - val_acc: 0.3724
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 58s - loss: 1.7744 - acc: 0.3777 - val_loss: 1.7859 - val_acc: 0.3650
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 58s - loss: 1.7779 - acc: 0.3794 - val_loss: 1.8011 - val_acc: 0.3718
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 58s - loss: 1.7806 - acc: 0.3778 - val_loss: 1.8070 - val_acc: 0.3700
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 58s - loss: 1.7825 - acc: 0.3742 - val_loss: 1.7696 - val_acc: 0.3742
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 58s - loss: 1.7794 - acc: 0.3791 - val_loss: 1.7621 - val_acc: 0.3734
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc improved from 0.38020 to 0.38200, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.7775 - acc: 0.3790 - val_loss: 1.7580 - val_acc: 0.3820
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 58s - loss: 1.7689 - acc: 0.3778 - val_loss: 1.7611 - val_acc: 0.3764
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 58s - loss: 1.7698 - acc: 0.3817 - val_loss: 1.7609 - val_acc: 0.3682
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 58s - loss: 1.7601 - acc: 0.3849 - val_loss: 1.7643 - val_acc: 0.3664
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 58s - loss: 1.7576 - acc: 0.3862 - val_loss: 1.7850 - val_acc: 0.3602
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc improved from 0.38200 to 0.38520, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.7622 - acc: 0.3828 - val_loss: 1.7554 - val_acc: 0.3852
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 58s - loss: 1.7659 - acc: 0.3802 - val_loss: 1.7801 - val_acc: 0.3688
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 58s - loss: 1.7572 - acc: 0.3883 - val_loss: 1.7614 - val_acc: 0.3796
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 58s - loss: 1.7626 - acc: 0.3827 - val_loss: 1.7556 - val_acc: 0.3840
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc improved from 0.38520 to 0.38660, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.7552 - acc: 0.3871 - val_loss: 1.7375 - val_acc: 0.3866
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 58s - loss: 1.7570 - acc: 0.3877 - val_loss: 1.7557 - val_acc: 0.3792
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 58s - loss: 1.7593 - acc: 0.3860 - val_loss: 1.7536 - val_acc: 0.3832
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc improved from 0.38660 to 0.38860, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.7545 - acc: 0.3869 - val_loss: 1.7366 - val_acc: 0.3886
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 58s - loss: 1.7565 - acc: 0.3863 - val_loss: 1.7557 - val_acc: 0.3812
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 58s - loss: 1.7545 - acc: 0.3857 - val_loss: 1.7550 - val_acc: 0.3832
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 58s - loss: 1.7606 - acc: 0.3854 - val_loss: 1.7752 - val_acc: 0.3828
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 58s - loss: 1.7497 - acc: 0.3906 - val_loss: 1.7374 - val_acc: 0.3834
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 58s - loss: 1.7491 - acc: 0.3898 - val_loss: 1.7660 - val_acc: 0.3752
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc improved from 0.38860 to 0.39080, saving model to ./weights/CIFAR-10_full-bnn_4b_4b_1_64_1_128_1_256.hdf5
 - 60s - loss: 1.7517 - acc: 0.3901 - val_loss: 1.7366 - val_acc: 0.3908
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 58s - loss: 1.7507 - acc: 0.3893 - val_loss: 1.7588 - val_acc: 0.3664
Done

