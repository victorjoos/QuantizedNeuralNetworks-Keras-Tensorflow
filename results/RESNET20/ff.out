Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_1[0][0]              
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_3[0][0]              
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        leaky_re_lu_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           leaky_re_lu_5[0][0]              
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        leaky_re_lu_7[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        leaky_re_lu_8[0][0]              
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         leaky_re_lu_7[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_9 (LeakyReLU)       (None, 16, 16, 32)   0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_9[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_10 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_10[0][0]             
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           leaky_re_lu_9[0][0]              
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 32)   0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_11[0][0]             
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_12 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        leaky_re_lu_12[0][0]             
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           leaky_re_lu_11[0][0]             
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_13 (LeakyReLU)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       leaky_re_lu_13[0][0]             
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_14 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_14[0][0]             
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        leaky_re_lu_13[0][0]             
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_15 (LeakyReLU)      (None, 8, 8, 64)     0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_15[0][0]             
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_16 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_16[0][0]             
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           leaky_re_lu_15[0][0]             
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_17 (LeakyReLU)      (None, 8, 8, 64)     0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_17[0][0]             
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_18 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       leaky_re_lu_18[0][0]             
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           leaky_re_lu_17[0][0]             
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
leaky_re_lu_19 (LeakyReLU)      (None, 8, 8, 64)     0           add_9[0][0]                      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           leaky_re_lu_19[0][0]             
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 274,442
Trainable params: 273,066
Non-trainable params: 1,376
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.51820, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 20s - loss: 1.5658 - acc: 0.4773 - val_loss: 1.5161 - val_acc: 0.5182
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.51820 to 0.57160, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 16s - loss: 1.1773 - acc: 0.6254 - val_loss: 1.3471 - val_acc: 0.5716
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc improved from 0.57160 to 0.65780, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 1.0279 - acc: 0.6770 - val_loss: 1.1012 - val_acc: 0.6578
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.65780 to 0.67100, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 16s - loss: 0.9175 - acc: 0.7170 - val_loss: 1.1091 - val_acc: 0.6710
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc improved from 0.67100 to 0.72120, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 16s - loss: 0.8335 - acc: 0.7494 - val_loss: 0.9489 - val_acc: 0.7212
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc did not improve
 - 16s - loss: 0.7717 - acc: 0.7715 - val_loss: 0.9712 - val_acc: 0.7040
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc did not improve
 - 16s - loss: 0.7224 - acc: 0.7915 - val_loss: 1.0834 - val_acc: 0.6822
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc improved from 0.72120 to 0.72940, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 16s - loss: 0.6778 - acc: 0.8051 - val_loss: 0.9055 - val_acc: 0.7294
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 16s - loss: 0.6423 - acc: 0.8175 - val_loss: 1.0548 - val_acc: 0.7174
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 16s - loss: 0.6074 - acc: 0.8308 - val_loss: 0.9634 - val_acc: 0.7288
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc improved from 0.72940 to 0.75900, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.5769 - acc: 0.8413 - val_loss: 0.8835 - val_acc: 0.7590
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 16s - loss: 0.5472 - acc: 0.8541 - val_loss: 0.9287 - val_acc: 0.7400
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc did not improve
 - 16s - loss: 0.5239 - acc: 0.8631 - val_loss: 1.1396 - val_acc: 0.7022
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 16s - loss: 0.4964 - acc: 0.8731 - val_loss: 1.0580 - val_acc: 0.7288
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc did not improve
 - 16s - loss: 0.4689 - acc: 0.8835 - val_loss: 1.0240 - val_acc: 0.7362
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc improved from 0.75900 to 0.75920, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 16s - loss: 0.4532 - acc: 0.8893 - val_loss: 0.9129 - val_acc: 0.7592
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc improved from 0.75920 to 0.76620, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 16s - loss: 0.4285 - acc: 0.8983 - val_loss: 0.9232 - val_acc: 0.7662
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 16s - loss: 0.4110 - acc: 0.9026 - val_loss: 0.9989 - val_acc: 0.7428
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 16s - loss: 0.3920 - acc: 0.9117 - val_loss: 1.0499 - val_acc: 0.7460
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 16s - loss: 0.3757 - acc: 0.9188 - val_loss: 1.0136 - val_acc: 0.7602
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 16s - loss: 0.3728 - acc: 0.9202 - val_loss: 1.1647 - val_acc: 0.7498
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 16s - loss: 0.3548 - acc: 0.9273 - val_loss: 1.3283 - val_acc: 0.7084
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc improved from 0.76620 to 0.77660, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.3385 - acc: 0.9333 - val_loss: 1.0126 - val_acc: 0.7766
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 16s - loss: 0.3297 - acc: 0.9380 - val_loss: 1.0105 - val_acc: 0.7738
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 16s - loss: 0.3256 - acc: 0.9387 - val_loss: 1.1828 - val_acc: 0.7426
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 16s - loss: 0.3242 - acc: 0.9388 - val_loss: 1.0932 - val_acc: 0.7632
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 16s - loss: 0.3042 - acc: 0.9488 - val_loss: 1.3881 - val_acc: 0.7276
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 16s - loss: 0.2998 - acc: 0.9496 - val_loss: 1.0313 - val_acc: 0.7736
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 16s - loss: 0.3067 - acc: 0.9467 - val_loss: 1.2619 - val_acc: 0.7508
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 16s - loss: 0.2992 - acc: 0.9521 - val_loss: 1.1641 - val_acc: 0.7710
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc improved from 0.77660 to 0.77740, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.2812 - acc: 0.9592 - val_loss: 1.1850 - val_acc: 0.7774
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 16s - loss: 0.2864 - acc: 0.9561 - val_loss: 1.3191 - val_acc: 0.7564
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 16s - loss: 0.2950 - acc: 0.9540 - val_loss: 1.1693 - val_acc: 0.7738
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 16s - loss: 0.2880 - acc: 0.9580 - val_loss: 1.2766 - val_acc: 0.7570
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 16s - loss: 0.2786 - acc: 0.9618 - val_loss: 1.3037 - val_acc: 0.7652
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 16s - loss: 0.2790 - acc: 0.9601 - val_loss: 1.6110 - val_acc: 0.7140
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 16s - loss: 0.2792 - acc: 0.9615 - val_loss: 1.2400 - val_acc: 0.7618
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc improved from 0.77740 to 0.78460, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.2749 - acc: 0.9628 - val_loss: 1.0887 - val_acc: 0.7846
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 16s - loss: 0.2798 - acc: 0.9610 - val_loss: 1.5172 - val_acc: 0.7430
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 16s - loss: 0.2744 - acc: 0.9628 - val_loss: 1.3309 - val_acc: 0.7616
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 16s - loss: 0.2780 - acc: 0.9627 - val_loss: 1.3392 - val_acc: 0.7592
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc improved from 0.78460 to 0.78560, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.2624 - acc: 0.9686 - val_loss: 1.1939 - val_acc: 0.7856
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 16s - loss: 0.2775 - acc: 0.9623 - val_loss: 1.2807 - val_acc: 0.7602
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 16s - loss: 0.2720 - acc: 0.9656 - val_loss: 1.3170 - val_acc: 0.7670
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 16s - loss: 0.2666 - acc: 0.9673 - val_loss: 1.4666 - val_acc: 0.7556
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 16s - loss: 0.2704 - acc: 0.9658 - val_loss: 1.2693 - val_acc: 0.7712
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 16s - loss: 0.2632 - acc: 0.9687 - val_loss: 1.6432 - val_acc: 0.7328
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 16s - loss: 0.2775 - acc: 0.9642 - val_loss: 1.4476 - val_acc: 0.7450
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 16s - loss: 0.2614 - acc: 0.9695 - val_loss: 1.3261 - val_acc: 0.7726
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 16s - loss: 0.2701 - acc: 0.9666 - val_loss: 1.3992 - val_acc: 0.7576
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 16s - loss: 0.2613 - acc: 0.9701 - val_loss: 1.8121 - val_acc: 0.7150
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 16s - loss: 0.2658 - acc: 0.9694 - val_loss: 1.5355 - val_acc: 0.7440
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 16s - loss: 0.2609 - acc: 0.9705 - val_loss: 1.3996 - val_acc: 0.7638
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 16s - loss: 0.2713 - acc: 0.9668 - val_loss: 1.2993 - val_acc: 0.7790
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 16s - loss: 0.2533 - acc: 0.9739 - val_loss: 1.3632 - val_acc: 0.7648
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 16s - loss: 0.2606 - acc: 0.9709 - val_loss: 1.4975 - val_acc: 0.7558
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 16s - loss: 0.2623 - acc: 0.9707 - val_loss: 1.5392 - val_acc: 0.7480
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 16s - loss: 0.2601 - acc: 0.9710 - val_loss: 1.5413 - val_acc: 0.7612
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 16s - loss: 0.2694 - acc: 0.9686 - val_loss: 1.4193 - val_acc: 0.7536
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 16s - loss: 0.2645 - acc: 0.9696 - val_loss: 1.3621 - val_acc: 0.7596
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 16s - loss: 0.2569 - acc: 0.9730 - val_loss: 1.4778 - val_acc: 0.7608
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 16s - loss: 0.2662 - acc: 0.9690 - val_loss: 1.4066 - val_acc: 0.7688
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 16s - loss: 0.2560 - acc: 0.9728 - val_loss: 1.3019 - val_acc: 0.7710
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 16s - loss: 0.2539 - acc: 0.9740 - val_loss: 1.5291 - val_acc: 0.7538
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 16s - loss: 0.2624 - acc: 0.9710 - val_loss: 1.3649 - val_acc: 0.7730
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 16s - loss: 0.2634 - acc: 0.9706 - val_loss: 1.3230 - val_acc: 0.7660
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 16s - loss: 0.2589 - acc: 0.9724 - val_loss: 1.5815 - val_acc: 0.7544
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 16s - loss: 0.2497 - acc: 0.9756 - val_loss: 1.3133 - val_acc: 0.7706
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 16s - loss: 0.2577 - acc: 0.9724 - val_loss: 1.6629 - val_acc: 0.7420
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 16s - loss: 0.2547 - acc: 0.9741 - val_loss: 1.5518 - val_acc: 0.7500
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 16s - loss: 0.2625 - acc: 0.9716 - val_loss: 1.7804 - val_acc: 0.7320
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 16s - loss: 0.2533 - acc: 0.9746 - val_loss: 1.4489 - val_acc: 0.7662
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 16s - loss: 0.2608 - acc: 0.9724 - val_loss: 1.8714 - val_acc: 0.7318
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 16s - loss: 0.2639 - acc: 0.9710 - val_loss: 1.6025 - val_acc: 0.7478
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 16s - loss: 0.2480 - acc: 0.9768 - val_loss: 1.3790 - val_acc: 0.7738
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 16s - loss: 0.2482 - acc: 0.9761 - val_loss: 1.6564 - val_acc: 0.7522
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 16s - loss: 0.2582 - acc: 0.9722 - val_loss: 1.2870 - val_acc: 0.7734
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 16s - loss: 0.2492 - acc: 0.9754 - val_loss: 1.3256 - val_acc: 0.7788
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 16s - loss: 0.2563 - acc: 0.9728 - val_loss: 1.5723 - val_acc: 0.7532
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 16s - loss: 0.2637 - acc: 0.9701 - val_loss: 1.5384 - val_acc: 0.7530
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 16s - loss: 0.2509 - acc: 0.9754 - val_loss: 1.4230 - val_acc: 0.7606
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.78560 to 0.80640, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.2037 - acc: 0.9934 - val_loss: 1.1194 - val_acc: 0.8064
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.80640 to 0.80880, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.1869 - acc: 0.9994 - val_loss: 1.1226 - val_acc: 0.8088
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc improved from 0.80880 to 0.80900, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.1834 - acc: 0.9998 - val_loss: 1.1331 - val_acc: 0.8090
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc improved from 0.80900 to 0.81080, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.1810 - acc: 0.9999 - val_loss: 1.1360 - val_acc: 0.8108
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 16s - loss: 0.1790 - acc: 0.9999 - val_loss: 1.1368 - val_acc: 0.8098
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc improved from 0.81080 to 0.81240, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.1769 - acc: 0.9999 - val_loss: 1.1434 - val_acc: 0.8124
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 16s - loss: 0.1745 - acc: 1.0000 - val_loss: 1.1493 - val_acc: 0.8116
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 16s - loss: 0.1719 - acc: 1.0000 - val_loss: 1.1498 - val_acc: 0.8110
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc improved from 0.81240 to 0.81420, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.1690 - acc: 1.0000 - val_loss: 1.1526 - val_acc: 0.8142
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 16s - loss: 0.1659 - acc: 1.0000 - val_loss: 1.1602 - val_acc: 0.8116
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 16s - loss: 0.1622 - acc: 1.0000 - val_loss: 1.1567 - val_acc: 0.8138
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 16s - loss: 0.1583 - acc: 1.0000 - val_loss: 1.1592 - val_acc: 0.8118
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc improved from 0.81420 to 0.81640, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.1536 - acc: 1.0000 - val_loss: 1.1708 - val_acc: 0.8164
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 16s - loss: 0.1486 - acc: 1.0000 - val_loss: 1.1701 - val_acc: 0.8132
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 16s - loss: 0.1431 - acc: 1.0000 - val_loss: 1.1636 - val_acc: 0.8140
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 16s - loss: 0.1371 - acc: 1.0000 - val_loss: 1.1676 - val_acc: 0.8138
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 16s - loss: 0.1306 - acc: 1.0000 - val_loss: 1.1555 - val_acc: 0.8140
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 16s - loss: 0.1275 - acc: 0.9990 - val_loss: 1.2909 - val_acc: 0.8012
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 16s - loss: 0.1242 - acc: 0.9994 - val_loss: 1.2103 - val_acc: 0.8092
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 16s - loss: 0.1200 - acc: 1.0000 - val_loss: 1.2081 - val_acc: 0.8116
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 16s - loss: 0.1174 - acc: 1.0000 - val_loss: 1.2138 - val_acc: 0.8118
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 16s - loss: 0.1147 - acc: 1.0000 - val_loss: 1.2164 - val_acc: 0.8112
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 16s - loss: 0.1119 - acc: 1.0000 - val_loss: 1.2176 - val_acc: 0.8136
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 16s - loss: 0.1085 - acc: 1.0000 - val_loss: 1.2078 - val_acc: 0.8124
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 16s - loss: 0.1094 - acc: 0.9990 - val_loss: 1.3707 - val_acc: 0.7922
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 16s - loss: 0.1065 - acc: 0.9992 - val_loss: 1.2458 - val_acc: 0.8094
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 16s - loss: 0.1030 - acc: 1.0000 - val_loss: 1.2246 - val_acc: 0.8160
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 16s - loss: 0.1009 - acc: 1.0000 - val_loss: 1.2206 - val_acc: 0.8144
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 16s - loss: 0.0990 - acc: 1.0000 - val_loss: 1.2272 - val_acc: 0.8138
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 16s - loss: 0.0972 - acc: 0.9999 - val_loss: 1.2470 - val_acc: 0.8152
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 16s - loss: 0.0948 - acc: 1.0000 - val_loss: 1.2244 - val_acc: 0.8146
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 16s - loss: 0.0922 - acc: 1.0000 - val_loss: 1.2249 - val_acc: 0.8124
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 16s - loss: 0.0894 - acc: 1.0000 - val_loss: 1.2201 - val_acc: 0.8122
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 16s - loss: 0.0925 - acc: 0.9980 - val_loss: 1.4621 - val_acc: 0.7948
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 16s - loss: 0.0918 - acc: 0.9982 - val_loss: 1.2841 - val_acc: 0.8052
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 16s - loss: 0.0860 - acc: 0.9999 - val_loss: 1.2430 - val_acc: 0.8118
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 16s - loss: 0.0847 - acc: 1.0000 - val_loss: 1.2420 - val_acc: 0.8146
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc improved from 0.81640 to 0.81660, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.0836 - acc: 1.0000 - val_loss: 1.2311 - val_acc: 0.8166
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 16s - loss: 0.0824 - acc: 1.0000 - val_loss: 1.2370 - val_acc: 0.8144
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 16s - loss: 0.0811 - acc: 1.0000 - val_loss: 1.2319 - val_acc: 0.8150
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc did not improve
 - 16s - loss: 0.0803 - acc: 1.0000 - val_loss: 1.2487 - val_acc: 0.8150
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 16s - loss: 0.0801 - acc: 1.0000 - val_loss: 1.2510 - val_acc: 0.8142
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 16s - loss: 0.0799 - acc: 1.0000 - val_loss: 1.2488 - val_acc: 0.8158
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc improved from 0.81660 to 0.81740, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.0797 - acc: 1.0000 - val_loss: 1.2479 - val_acc: 0.8174
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc improved from 0.81740 to 0.81760, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.0794 - acc: 1.0000 - val_loss: 1.2447 - val_acc: 0.8176
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 16s - loss: 0.0790 - acc: 1.0000 - val_loss: 1.2455 - val_acc: 0.8164
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 16s - loss: 0.0787 - acc: 1.0000 - val_loss: 1.2470 - val_acc: 0.8174
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 16s - loss: 0.0783 - acc: 1.0000 - val_loss: 1.2487 - val_acc: 0.8156
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 16s - loss: 0.0778 - acc: 1.0000 - val_loss: 1.2490 - val_acc: 0.8160
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 16s - loss: 0.0772 - acc: 1.0000 - val_loss: 1.2487 - val_acc: 0.8160
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 16s - loss: 0.0766 - acc: 1.0000 - val_loss: 1.2473 - val_acc: 0.8170
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 16s - loss: 0.0759 - acc: 1.0000 - val_loss: 1.2464 - val_acc: 0.8172
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 16s - loss: 0.0752 - acc: 1.0000 - val_loss: 1.2548 - val_acc: 0.8158
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 16s - loss: 0.0744 - acc: 1.0000 - val_loss: 1.2476 - val_acc: 0.8168
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 16s - loss: 0.0736 - acc: 1.0000 - val_loss: 1.2473 - val_acc: 0.8148
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 16s - loss: 0.0728 - acc: 1.0000 - val_loss: 1.2523 - val_acc: 0.8142
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 16s - loss: 0.0720 - acc: 1.0000 - val_loss: 1.2520 - val_acc: 0.8166
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 16s - loss: 0.0711 - acc: 1.0000 - val_loss: 1.2517 - val_acc: 0.8154
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 16s - loss: 0.0702 - acc: 1.0000 - val_loss: 1.2482 - val_acc: 0.8166
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 16s - loss: 0.0692 - acc: 1.0000 - val_loss: 1.2453 - val_acc: 0.8148
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 16s - loss: 0.0682 - acc: 1.0000 - val_loss: 1.2562 - val_acc: 0.8148
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 16s - loss: 0.0673 - acc: 1.0000 - val_loss: 1.2547 - val_acc: 0.8162
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 16s - loss: 0.0664 - acc: 1.0000 - val_loss: 1.2574 - val_acc: 0.8150
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 16s - loss: 0.0655 - acc: 1.0000 - val_loss: 1.2591 - val_acc: 0.8162
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 16s - loss: 0.0646 - acc: 1.0000 - val_loss: 1.2629 - val_acc: 0.8152
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 16s - loss: 0.0637 - acc: 1.0000 - val_loss: 1.2610 - val_acc: 0.8142
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 16s - loss: 0.0628 - acc: 1.0000 - val_loss: 1.2667 - val_acc: 0.8162
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 16s - loss: 0.0620 - acc: 1.0000 - val_loss: 1.2621 - val_acc: 0.8168
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 16s - loss: 0.0611 - acc: 1.0000 - val_loss: 1.2688 - val_acc: 0.8176
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 16s - loss: 0.0602 - acc: 1.0000 - val_loss: 1.2677 - val_acc: 0.8150
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 16s - loss: 0.0594 - acc: 1.0000 - val_loss: 1.2687 - val_acc: 0.8166
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 16s - loss: 0.0585 - acc: 1.0000 - val_loss: 1.2701 - val_acc: 0.8176
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 16s - loss: 0.0577 - acc: 1.0000 - val_loss: 1.2714 - val_acc: 0.8158
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 16s - loss: 0.0570 - acc: 1.0000 - val_loss: 1.2690 - val_acc: 0.8134
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 16s - loss: 0.0563 - acc: 1.0000 - val_loss: 1.2791 - val_acc: 0.8146
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 16s - loss: 0.0557 - acc: 1.0000 - val_loss: 1.2839 - val_acc: 0.8150
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 16s - loss: 0.0552 - acc: 1.0000 - val_loss: 1.2769 - val_acc: 0.8158
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 16s - loss: 0.0546 - acc: 1.0000 - val_loss: 1.2811 - val_acc: 0.8142
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 16s - loss: 0.0541 - acc: 1.0000 - val_loss: 1.2841 - val_acc: 0.8156
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 16s - loss: 0.0535 - acc: 1.0000 - val_loss: 1.2771 - val_acc: 0.8156
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 16s - loss: 0.0532 - acc: 1.0000 - val_loss: 1.2850 - val_acc: 0.8150
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 16s - loss: 0.0531 - acc: 1.0000 - val_loss: 1.2844 - val_acc: 0.8152
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 16s - loss: 0.0530 - acc: 1.0000 - val_loss: 1.2864 - val_acc: 0.8154
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 16s - loss: 0.0530 - acc: 1.0000 - val_loss: 1.2868 - val_acc: 0.8154
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 16s - loss: 0.0529 - acc: 1.0000 - val_loss: 1.2884 - val_acc: 0.8162
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 16s - loss: 0.0528 - acc: 1.0000 - val_loss: 1.2884 - val_acc: 0.8158
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 16s - loss: 0.0528 - acc: 1.0000 - val_loss: 1.2880 - val_acc: 0.8156
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 16s - loss: 0.0527 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.8156
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 16s - loss: 0.0526 - acc: 1.0000 - val_loss: 1.2900 - val_acc: 0.8158
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 16s - loss: 0.0525 - acc: 1.0000 - val_loss: 1.2896 - val_acc: 0.8154
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 16s - loss: 0.0524 - acc: 1.0000 - val_loss: 1.2894 - val_acc: 0.8152
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 16s - loss: 0.0523 - acc: 1.0000 - val_loss: 1.2904 - val_acc: 0.8162
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 16s - loss: 0.0522 - acc: 1.0000 - val_loss: 1.2908 - val_acc: 0.8160
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 16s - loss: 0.0521 - acc: 1.0000 - val_loss: 1.2896 - val_acc: 0.8162
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 16s - loss: 0.0521 - acc: 1.0000 - val_loss: 1.2885 - val_acc: 0.8160
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 16s - loss: 0.0520 - acc: 1.0000 - val_loss: 1.2885 - val_acc: 0.8162
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 16s - loss: 0.0519 - acc: 1.0000 - val_loss: 1.2895 - val_acc: 0.8170
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 16s - loss: 0.0518 - acc: 1.0000 - val_loss: 1.2897 - val_acc: 0.8162
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 16s - loss: 0.0517 - acc: 1.0000 - val_loss: 1.2895 - val_acc: 0.8166
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc improved from 0.81760 to 0.81820, saving model to ./weights/RESNET_CIFAR-10_float_4b_4b_3.hdf5
 - 17s - loss: 0.0516 - acc: 1.0000 - val_loss: 1.2882 - val_acc: 0.8182
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 16s - loss: 0.0515 - acc: 1.0000 - val_loss: 1.2880 - val_acc: 0.8170
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 16s - loss: 0.0515 - acc: 1.0000 - val_loss: 1.2889 - val_acc: 0.8176
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 16s - loss: 0.0514 - acc: 1.0000 - val_loss: 1.2875 - val_acc: 0.8176
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 16s - loss: 0.0514 - acc: 1.0000 - val_loss: 1.2895 - val_acc: 0.8168
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 16s - loss: 0.0514 - acc: 1.0000 - val_loss: 1.2886 - val_acc: 0.8178
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 16s - loss: 0.0513 - acc: 1.0000 - val_loss: 1.2896 - val_acc: 0.8178
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 16s - loss: 0.0513 - acc: 1.0000 - val_loss: 1.2891 - val_acc: 0.8170
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 16s - loss: 0.0512 - acc: 1.0000 - val_loss: 1.2897 - val_acc: 0.8174
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 16s - loss: 0.0512 - acc: 1.0000 - val_loss: 1.2890 - val_acc: 0.8160
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 16s - loss: 0.0511 - acc: 1.0000 - val_loss: 1.2886 - val_acc: 0.8162
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 16s - loss: 0.0511 - acc: 1.0000 - val_loss: 1.2912 - val_acc: 0.8178
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 16s - loss: 0.0511 - acc: 1.0000 - val_loss: 1.2908 - val_acc: 0.8168
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 16s - loss: 0.0510 - acc: 1.0000 - val_loss: 1.2901 - val_acc: 0.8158
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 16s - loss: 0.0510 - acc: 1.0000 - val_loss: 1.2908 - val_acc: 0.8170
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 16s - loss: 0.0509 - acc: 1.0000 - val_loss: 1.2914 - val_acc: 0.8166
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 16s - loss: 0.0509 - acc: 1.0000 - val_loss: 1.2916 - val_acc: 0.8162
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 16s - loss: 0.0508 - acc: 1.0000 - val_loss: 1.2924 - val_acc: 0.8162
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 16s - loss: 0.0508 - acc: 1.0000 - val_loss: 1.2908 - val_acc: 0.8166
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 16s - loss: 0.0508 - acc: 1.0000 - val_loss: 1.2920 - val_acc: 0.8164
Done

