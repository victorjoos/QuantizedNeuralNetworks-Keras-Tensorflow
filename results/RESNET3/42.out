Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
quantized_conv2d_1 (QuantizedCo (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_1[0][0]         
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_2 (QuantizedCo (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_2[0][0]         
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_3 (QuantizedCo (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_3[0][0]         
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_4 (QuantizedCo (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_4[0][0]         
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_5 (QuantizedCo (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_5[0][0]         
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_6 (QuantizedCo (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_6[0][0]         
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_7 (QuantizedCo (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          quantized_conv2d_7[0][0]         
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_8 (QuantizedCo (None, 16, 16, 32)   4640        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         quantized_conv2d_8[0][0]         
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
quantized_conv2d_9 (QuantizedCo (None, 16, 16, 32)   9248        activation_8[0][0]               
__________________________________________________________________________________________________
quantized_conv2d_10 (QuantizedC (None, 16, 16, 32)   544         activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         quantized_conv2d_9[0][0]         
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           quantized_conv2d_10[0][0]        
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_11 (QuantizedC (None, 16, 16, 32)   9248        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_11[0][0]        
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_12 (QuantizedC (None, 16, 16, 32)   9248        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_12[0][0]        
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_13 (QuantizedC (None, 16, 16, 32)   9248        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_13[0][0]        
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_14 (QuantizedC (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         quantized_conv2d_14[0][0]        
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_15 (QuantizedC (None, 8, 8, 64)     18496       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_15[0][0]        
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_16 (QuantizedC (None, 8, 8, 64)     36928       activation_14[0][0]              
__________________________________________________________________________________________________
quantized_conv2d_17 (QuantizedC (None, 8, 8, 64)     2112        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_16[0][0]        
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           quantized_conv2d_17[0][0]        
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_18 (QuantizedC (None, 8, 8, 64)     36928       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_18[0][0]        
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_19 (QuantizedC (None, 8, 8, 64)     36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_19[0][0]        
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      
__________________________________________________________________________________________________
quantized_conv2d_20 (QuantizedC (None, 8, 8, 64)     36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_20[0][0]        
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
quantized_conv2d_21 (QuantizedC (None, 8, 8, 64)     36928       activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         quantized_conv2d_21[0][0]        
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
quantized_dense_2 (QuantizedDen (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 274,442
Trainable params: 273,066
Non-trainable params: 1,376
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.13020, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 29s - loss: 11.3081 - acc: 0.1102 - val_loss: 11.2072 - val_acc: 0.1302
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.13020 to 0.19800, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 11.0504 - acc: 0.1838 - val_loss: 10.9697 - val_acc: 0.1980
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc improved from 0.19800 to 0.23940, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 10.8978 - acc: 0.2282 - val_loss: 10.8664 - val_acc: 0.2394
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.23940 to 0.26080, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 10.8037 - acc: 0.2494 - val_loss: 10.7621 - val_acc: 0.2608
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc did not improve
 - 24s - loss: 10.7239 - acc: 0.2707 - val_loss: 10.8138 - val_acc: 0.2418
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc improved from 0.26080 to 0.31120, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 10.6331 - acc: 0.3005 - val_loss: 10.5862 - val_acc: 0.3112
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.31120 to 0.32520, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 10.5495 - acc: 0.3159 - val_loss: 10.5104 - val_acc: 0.3252
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc did not improve
 - 24s - loss: 10.4579 - acc: 0.3341 - val_loss: 10.4850 - val_acc: 0.3156
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc improved from 0.32520 to 0.35220, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 10.3637 - acc: 0.3562 - val_loss: 10.3251 - val_acc: 0.3522
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc improved from 0.35220 to 0.37180, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 10.2812 - acc: 0.3724 - val_loss: 10.2415 - val_acc: 0.3718
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc improved from 0.37180 to 0.38100, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 10.2135 - acc: 0.3819 - val_loss: 10.1971 - val_acc: 0.3810
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 24s - loss: 10.1487 - acc: 0.3934 - val_loss: 10.1958 - val_acc: 0.3722
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc improved from 0.38100 to 0.40680, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 10.0842 - acc: 0.4069 - val_loss: 10.0525 - val_acc: 0.4068
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc improved from 0.40680 to 0.41660, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 10.0230 - acc: 0.4154 - val_loss: 10.0128 - val_acc: 0.4166
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc improved from 0.41660 to 0.42140, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 9.9686 - acc: 0.4261 - val_loss: 9.9611 - val_acc: 0.4214
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc improved from 0.42140 to 0.42560, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 9.9184 - acc: 0.4331 - val_loss: 9.8926 - val_acc: 0.4256
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc improved from 0.42560 to 0.43900, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 9.8609 - acc: 0.4437 - val_loss: 9.8421 - val_acc: 0.4390
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc improved from 0.43900 to 0.45660, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 9.8037 - acc: 0.4544 - val_loss: 9.7763 - val_acc: 0.4566
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc improved from 0.45660 to 0.46640, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 9.7546 - acc: 0.4624 - val_loss: 9.7284 - val_acc: 0.4664
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 24s - loss: 9.7078 - acc: 0.4686 - val_loss: 9.7639 - val_acc: 0.4484
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc improved from 0.46640 to 0.47900, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 9.6573 - acc: 0.4780 - val_loss: 9.6374 - val_acc: 0.4790
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 24s - loss: 9.6162 - acc: 0.4799 - val_loss: 9.6003 - val_acc: 0.4788
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 24s - loss: 9.5621 - acc: 0.4912 - val_loss: 9.5586 - val_acc: 0.4750
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc improved from 0.47900 to 0.49700, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 9.5210 - acc: 0.5005 - val_loss: 9.4926 - val_acc: 0.4970
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 24s - loss: 9.4819 - acc: 0.5024 - val_loss: 9.5013 - val_acc: 0.4870
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc improved from 0.49700 to 0.50720, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 9.4424 - acc: 0.5078 - val_loss: 9.4326 - val_acc: 0.5072
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 24s - loss: 9.4024 - acc: 0.5141 - val_loss: 9.4074 - val_acc: 0.5054
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 24s - loss: 9.3629 - acc: 0.5168 - val_loss: 9.4519 - val_acc: 0.4830
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc improved from 0.50720 to 0.50860, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 9.3271 - acc: 0.5246 - val_loss: 9.3357 - val_acc: 0.5086
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 24s - loss: 9.2920 - acc: 0.5290 - val_loss: 9.3269 - val_acc: 0.5078
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc improved from 0.50860 to 0.51720, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 9.2519 - acc: 0.5365 - val_loss: 9.2827 - val_acc: 0.5172
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc improved from 0.51720 to 0.53400, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 9.2165 - acc: 0.5402 - val_loss: 9.2106 - val_acc: 0.5340
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 24s - loss: 9.1804 - acc: 0.5450 - val_loss: 9.2109 - val_acc: 0.5238
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 24s - loss: 9.1447 - acc: 0.5514 - val_loss: 9.2271 - val_acc: 0.5052
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc improved from 0.53400 to 0.53840, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 9.1076 - acc: 0.5581 - val_loss: 9.1323 - val_acc: 0.5384
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc improved from 0.53840 to 0.55760, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 9.0748 - acc: 0.5629 - val_loss: 9.0617 - val_acc: 0.5576
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 24s - loss: 9.0406 - acc: 0.5667 - val_loss: 9.0961 - val_acc: 0.5354
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc improved from 0.55760 to 0.56760, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 9.0100 - acc: 0.5717 - val_loss: 9.0210 - val_acc: 0.5676
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 24s - loss: 8.9798 - acc: 0.5748 - val_loss: 9.0131 - val_acc: 0.5574
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 24s - loss: 8.9489 - acc: 0.5811 - val_loss: 8.9934 - val_acc: 0.5590
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 24s - loss: 8.9185 - acc: 0.5850 - val_loss: 8.9534 - val_acc: 0.5664
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 24s - loss: 8.8888 - acc: 0.5864 - val_loss: 8.9375 - val_acc: 0.5626
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 24s - loss: 8.8615 - acc: 0.5915 - val_loss: 8.9026 - val_acc: 0.5670
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc improved from 0.56760 to 0.57960, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 8.8283 - acc: 0.5957 - val_loss: 8.8859 - val_acc: 0.5796
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc improved from 0.57960 to 0.59260, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 8.8067 - acc: 0.5984 - val_loss: 8.8260 - val_acc: 0.5926
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 24s - loss: 8.7786 - acc: 0.6022 - val_loss: 8.8172 - val_acc: 0.5810
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 24s - loss: 8.7498 - acc: 0.6062 - val_loss: 8.7921 - val_acc: 0.5856
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 24s - loss: 8.7300 - acc: 0.6031 - val_loss: 8.7841 - val_acc: 0.5882
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 24s - loss: 8.6958 - acc: 0.6118 - val_loss: 8.8182 - val_acc: 0.5666
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 24s - loss: 8.6731 - acc: 0.6122 - val_loss: 8.8030 - val_acc: 0.5652
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 24s - loss: 8.6514 - acc: 0.6153 - val_loss: 8.7774 - val_acc: 0.5690
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc improved from 0.59260 to 0.61180, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 8.6229 - acc: 0.6224 - val_loss: 8.6568 - val_acc: 0.6118
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 24s - loss: 8.5998 - acc: 0.6220 - val_loss: 8.6382 - val_acc: 0.6064
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 24s - loss: 8.5779 - acc: 0.6261 - val_loss: 8.6735 - val_acc: 0.5872
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc improved from 0.61180 to 0.61300, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 8.5603 - acc: 0.6286 - val_loss: 8.5945 - val_acc: 0.6130
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 24s - loss: 8.5303 - acc: 0.6314 - val_loss: 8.5764 - val_acc: 0.6054
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc improved from 0.61300 to 0.61720, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 8.5136 - acc: 0.6314 - val_loss: 8.5437 - val_acc: 0.6172
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 24s - loss: 8.4922 - acc: 0.6367 - val_loss: 8.6385 - val_acc: 0.5906
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 24s - loss: 8.4655 - acc: 0.6402 - val_loss: 8.5659 - val_acc: 0.6048
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 24s - loss: 8.4487 - acc: 0.6408 - val_loss: 8.5073 - val_acc: 0.6108
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 24s - loss: 8.4294 - acc: 0.6416 - val_loss: 8.5007 - val_acc: 0.6088
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc improved from 0.61720 to 0.63260, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 8.4034 - acc: 0.6465 - val_loss: 8.4475 - val_acc: 0.6326
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 24s - loss: 8.3823 - acc: 0.6470 - val_loss: 8.5109 - val_acc: 0.6052
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 24s - loss: 8.3642 - acc: 0.6488 - val_loss: 8.4748 - val_acc: 0.6158
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 24s - loss: 8.3392 - acc: 0.6533 - val_loss: 8.5256 - val_acc: 0.6026
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 24s - loss: 8.3224 - acc: 0.6540 - val_loss: 8.4120 - val_acc: 0.6236
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 24s - loss: 8.2985 - acc: 0.6579 - val_loss: 8.4196 - val_acc: 0.6188
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 24s - loss: 8.2825 - acc: 0.6609 - val_loss: 8.3726 - val_acc: 0.6270
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 24s - loss: 8.2710 - acc: 0.6596 - val_loss: 8.3332 - val_acc: 0.6322
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc improved from 0.63260 to 0.64100, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 8.2510 - acc: 0.6623 - val_loss: 8.3210 - val_acc: 0.6410
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 24s - loss: 8.2328 - acc: 0.6634 - val_loss: 8.5779 - val_acc: 0.5446
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 24s - loss: 8.2145 - acc: 0.6649 - val_loss: 8.3361 - val_acc: 0.6278
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 24s - loss: 8.1969 - acc: 0.6682 - val_loss: 8.3184 - val_acc: 0.6270
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc improved from 0.64100 to 0.64220, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 8.1768 - acc: 0.6704 - val_loss: 8.2743 - val_acc: 0.6422
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 24s - loss: 8.1624 - acc: 0.6706 - val_loss: 8.2818 - val_acc: 0.6234
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc improved from 0.64220 to 0.64440, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 8.1460 - acc: 0.6739 - val_loss: 8.2342 - val_acc: 0.6444
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc improved from 0.64440 to 0.64740, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 24s - loss: 8.1307 - acc: 0.6757 - val_loss: 8.1843 - val_acc: 0.6474
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 24s - loss: 8.1117 - acc: 0.6755 - val_loss: 8.2110 - val_acc: 0.6386
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 24s - loss: 8.0985 - acc: 0.6760 - val_loss: 8.2265 - val_acc: 0.6342
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc improved from 0.64740 to 0.65880, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 8.0810 - acc: 0.6791 - val_loss: 8.1289 - val_acc: 0.6588
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 24s - loss: 8.0647 - acc: 0.6821 - val_loss: 8.2290 - val_acc: 0.6320
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.65880 to 0.67060, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 8.0284 - acc: 0.6897 - val_loss: 8.0913 - val_acc: 0.6706
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc did not improve
 - 24s - loss: 8.0224 - acc: 0.6940 - val_loss: 8.1188 - val_acc: 0.6686
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc improved from 0.67060 to 0.67420, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 8.0215 - acc: 0.6923 - val_loss: 8.0844 - val_acc: 0.6742
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 24s - loss: 8.0134 - acc: 0.6951 - val_loss: 8.0774 - val_acc: 0.6662
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 24s - loss: 8.0110 - acc: 0.6942 - val_loss: 8.1223 - val_acc: 0.6508
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 24s - loss: 8.0125 - acc: 0.6944 - val_loss: 8.0753 - val_acc: 0.6704
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 24s - loss: 8.0082 - acc: 0.6952 - val_loss: 8.1714 - val_acc: 0.6354
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 24s - loss: 8.0024 - acc: 0.6927 - val_loss: 8.0962 - val_acc: 0.6662
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 24s - loss: 8.0058 - acc: 0.6928 - val_loss: 8.0971 - val_acc: 0.6654
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 24s - loss: 7.9982 - acc: 0.6956 - val_loss: 8.0814 - val_acc: 0.6662
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 24s - loss: 7.9980 - acc: 0.6954 - val_loss: 8.0835 - val_acc: 0.6628
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc improved from 0.67420 to 0.67540, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 7.9927 - acc: 0.6955 - val_loss: 8.0545 - val_acc: 0.6754
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 24s - loss: 7.9895 - acc: 0.6956 - val_loss: 8.0899 - val_acc: 0.6594
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 24s - loss: 7.9875 - acc: 0.6956 - val_loss: 8.0660 - val_acc: 0.6722
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 24s - loss: 7.9866 - acc: 0.6944 - val_loss: 8.0639 - val_acc: 0.6660
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 24s - loss: 7.9829 - acc: 0.6956 - val_loss: 8.0634 - val_acc: 0.6666
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 24s - loss: 7.9810 - acc: 0.6959 - val_loss: 8.1397 - val_acc: 0.6430
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 24s - loss: 7.9777 - acc: 0.6968 - val_loss: 8.1548 - val_acc: 0.6438
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 24s - loss: 7.9744 - acc: 0.6965 - val_loss: 8.1398 - val_acc: 0.6518
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 24s - loss: 7.9740 - acc: 0.6940 - val_loss: 8.0959 - val_acc: 0.6586
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc improved from 0.67540 to 0.67940, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 7.9698 - acc: 0.6958 - val_loss: 8.0235 - val_acc: 0.6794
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 24s - loss: 7.9655 - acc: 0.6985 - val_loss: 8.0559 - val_acc: 0.6642
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 24s - loss: 7.9616 - acc: 0.6964 - val_loss: 8.0448 - val_acc: 0.6712
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 24s - loss: 7.9617 - acc: 0.6974 - val_loss: 8.0139 - val_acc: 0.6788
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 24s - loss: 7.9584 - acc: 0.6949 - val_loss: 8.0446 - val_acc: 0.6704
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 24s - loss: 7.9558 - acc: 0.6986 - val_loss: 8.1074 - val_acc: 0.6488
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 24s - loss: 7.9556 - acc: 0.6974 - val_loss: 8.0234 - val_acc: 0.6766
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc improved from 0.67940 to 0.68260, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 7.9526 - acc: 0.6976 - val_loss: 8.0123 - val_acc: 0.6826
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 24s - loss: 7.9483 - acc: 0.6996 - val_loss: 8.0613 - val_acc: 0.6608
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 24s - loss: 7.9469 - acc: 0.6989 - val_loss: 8.0427 - val_acc: 0.6642
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 24s - loss: 7.9427 - acc: 0.6986 - val_loss: 8.0156 - val_acc: 0.6752
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 24s - loss: 7.9404 - acc: 0.6992 - val_loss: 8.0260 - val_acc: 0.6744
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 24s - loss: 7.9420 - acc: 0.6981 - val_loss: 8.0227 - val_acc: 0.6750
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 24s - loss: 7.9356 - acc: 0.6986 - val_loss: 8.0825 - val_acc: 0.6474
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 24s - loss: 7.9330 - acc: 0.7019 - val_loss: 8.0085 - val_acc: 0.6746
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 24s - loss: 7.9330 - acc: 0.7001 - val_loss: 8.0647 - val_acc: 0.6546
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 24s - loss: 7.9364 - acc: 0.7002 - val_loss: 8.0255 - val_acc: 0.6626
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 24s - loss: 7.9295 - acc: 0.6993 - val_loss: 8.0022 - val_acc: 0.6696
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 24s - loss: 7.9268 - acc: 0.7000 - val_loss: 8.0227 - val_acc: 0.6708
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 24s - loss: 7.9219 - acc: 0.7001 - val_loss: 7.9991 - val_acc: 0.6738
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc did not improve
 - 24s - loss: 7.9192 - acc: 0.7014 - val_loss: 7.9904 - val_acc: 0.6794
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc did not improve
 - 24s - loss: 7.9198 - acc: 0.7009 - val_loss: 7.9999 - val_acc: 0.6742
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 24s - loss: 7.9169 - acc: 0.7054 - val_loss: 8.0509 - val_acc: 0.6656
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc improved from 0.68260 to 0.68320, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 7.9170 - acc: 0.7020 - val_loss: 7.9849 - val_acc: 0.6832
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc improved from 0.68320 to 0.68620, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 7.9173 - acc: 0.7021 - val_loss: 7.9922 - val_acc: 0.6862
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 24s - loss: 7.9142 - acc: 0.7024 - val_loss: 8.0063 - val_acc: 0.6682
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc improved from 0.68620 to 0.68740, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 7.9158 - acc: 0.7011 - val_loss: 7.9825 - val_acc: 0.6874
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 24s - loss: 7.9127 - acc: 0.7016 - val_loss: 7.9784 - val_acc: 0.6766
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 24s - loss: 7.9170 - acc: 0.7012 - val_loss: 7.9966 - val_acc: 0.6812
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 24s - loss: 7.9139 - acc: 0.7014 - val_loss: 7.9966 - val_acc: 0.6752
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 24s - loss: 7.9116 - acc: 0.7043 - val_loss: 7.9874 - val_acc: 0.6788
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 24s - loss: 7.9141 - acc: 0.7036 - val_loss: 7.9886 - val_acc: 0.6782
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 24s - loss: 7.9107 - acc: 0.7008 - val_loss: 7.9837 - val_acc: 0.6782
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 24s - loss: 7.9097 - acc: 0.7041 - val_loss: 8.0181 - val_acc: 0.6718
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 24s - loss: 7.9106 - acc: 0.7022 - val_loss: 7.9728 - val_acc: 0.6850
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 24s - loss: 7.9113 - acc: 0.7027 - val_loss: 7.9983 - val_acc: 0.6774
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 24s - loss: 7.9142 - acc: 0.7021 - val_loss: 7.9836 - val_acc: 0.6832
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 24s - loss: 7.9136 - acc: 0.7045 - val_loss: 7.9953 - val_acc: 0.6742
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 24s - loss: 7.9112 - acc: 0.7038 - val_loss: 7.9944 - val_acc: 0.6702
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 24s - loss: 7.9118 - acc: 0.7040 - val_loss: 7.9816 - val_acc: 0.6788
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 24s - loss: 7.9114 - acc: 0.7019 - val_loss: 7.9757 - val_acc: 0.6838
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 24s - loss: 7.9110 - acc: 0.7015 - val_loss: 7.9848 - val_acc: 0.6784
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 24s - loss: 7.9122 - acc: 0.7016 - val_loss: 7.9815 - val_acc: 0.6812
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 24s - loss: 7.9104 - acc: 0.7047 - val_loss: 7.9849 - val_acc: 0.6842
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 24s - loss: 7.9047 - acc: 0.7042 - val_loss: 7.9798 - val_acc: 0.6820
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 24s - loss: 7.9104 - acc: 0.7035 - val_loss: 8.0042 - val_acc: 0.6702
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 24s - loss: 7.9120 - acc: 0.7018 - val_loss: 7.9835 - val_acc: 0.6830
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 24s - loss: 7.9067 - acc: 0.7048 - val_loss: 7.9819 - val_acc: 0.6808
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 24s - loss: 7.9068 - acc: 0.7044 - val_loss: 7.9848 - val_acc: 0.6814
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 24s - loss: 7.9074 - acc: 0.7032 - val_loss: 7.9920 - val_acc: 0.6778
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 24s - loss: 7.9074 - acc: 0.7026 - val_loss: 8.0246 - val_acc: 0.6662
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 24s - loss: 7.9087 - acc: 0.7032 - val_loss: 7.9701 - val_acc: 0.6732
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 24s - loss: 7.9096 - acc: 0.7020 - val_loss: 7.9736 - val_acc: 0.6842
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 24s - loss: 7.9070 - acc: 0.7059 - val_loss: 8.0240 - val_acc: 0.6656
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 24s - loss: 7.9093 - acc: 0.7017 - val_loss: 8.0451 - val_acc: 0.6592
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 24s - loss: 7.9082 - acc: 0.7008 - val_loss: 8.0190 - val_acc: 0.6684
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 24s - loss: 7.9056 - acc: 0.7040 - val_loss: 7.9697 - val_acc: 0.6830
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 24s - loss: 7.9090 - acc: 0.7016 - val_loss: 7.9919 - val_acc: 0.6722
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc improved from 0.68740 to 0.69180, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 7.9064 - acc: 0.7042 - val_loss: 7.9768 - val_acc: 0.6918
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 24s - loss: 7.9080 - acc: 0.7028 - val_loss: 8.0022 - val_acc: 0.6712
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 24s - loss: 7.9061 - acc: 0.7035 - val_loss: 7.9651 - val_acc: 0.6886
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 24s - loss: 7.9003 - acc: 0.7043 - val_loss: 7.9853 - val_acc: 0.6732
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 24s - loss: 7.9061 - acc: 0.7035 - val_loss: 7.9705 - val_acc: 0.6880
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 24s - loss: 7.9026 - acc: 0.7045 - val_loss: 8.0045 - val_acc: 0.6760
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 24s - loss: 7.9039 - acc: 0.7034 - val_loss: 7.9749 - val_acc: 0.6796
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 24s - loss: 7.9037 - acc: 0.7052 - val_loss: 7.9825 - val_acc: 0.6716
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 24s - loss: 7.9078 - acc: 0.7032 - val_loss: 7.9692 - val_acc: 0.6888
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 24s - loss: 7.9023 - acc: 0.7055 - val_loss: 8.0129 - val_acc: 0.6750
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 24s - loss: 7.9042 - acc: 0.7028 - val_loss: 7.9747 - val_acc: 0.6762
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 24s - loss: 7.9067 - acc: 0.7040 - val_loss: 8.0135 - val_acc: 0.6726
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 24s - loss: 7.9059 - acc: 0.7025 - val_loss: 8.0104 - val_acc: 0.6652
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 24s - loss: 7.9054 - acc: 0.7044 - val_loss: 7.9925 - val_acc: 0.6794
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 24s - loss: 7.9028 - acc: 0.7034 - val_loss: 7.9952 - val_acc: 0.6752
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 24s - loss: 7.9037 - acc: 0.7044 - val_loss: 7.9847 - val_acc: 0.6724
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 24s - loss: 7.9088 - acc: 0.7014 - val_loss: 8.0293 - val_acc: 0.6672
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 24s - loss: 7.9094 - acc: 0.7004 - val_loss: 7.9984 - val_acc: 0.6668
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 24s - loss: 7.9066 - acc: 0.7023 - val_loss: 7.9694 - val_acc: 0.6882
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 24s - loss: 7.9048 - acc: 0.7056 - val_loss: 7.9740 - val_acc: 0.6832
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 24s - loss: 7.9042 - acc: 0.7017 - val_loss: 7.9665 - val_acc: 0.6810
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 24s - loss: 7.9039 - acc: 0.7027 - val_loss: 7.9909 - val_acc: 0.6782
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 24s - loss: 7.9031 - acc: 0.7037 - val_loss: 7.9757 - val_acc: 0.6836
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 24s - loss: 7.9028 - acc: 0.7031 - val_loss: 7.9743 - val_acc: 0.6802
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 24s - loss: 7.9029 - acc: 0.7043 - val_loss: 8.0050 - val_acc: 0.6686
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 24s - loss: 7.9077 - acc: 0.7025 - val_loss: 7.9880 - val_acc: 0.6824
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 24s - loss: 7.9069 - acc: 0.7014 - val_loss: 8.0037 - val_acc: 0.6724
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 24s - loss: 7.9016 - acc: 0.7026 - val_loss: 7.9777 - val_acc: 0.6848
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 24s - loss: 7.9101 - acc: 0.7026 - val_loss: 7.9852 - val_acc: 0.6822
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc improved from 0.69180 to 0.69200, saving model to ./weights/RESNET_CIFAR-10_full-qnn_2b_4b_3.hdf5
 - 25s - loss: 7.9018 - acc: 0.7047 - val_loss: 7.9668 - val_acc: 0.6920
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 24s - loss: 7.9031 - acc: 0.7032 - val_loss: 7.9765 - val_acc: 0.6798
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 24s - loss: 7.9070 - acc: 0.7021 - val_loss: 8.0154 - val_acc: 0.6742
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 24s - loss: 7.9031 - acc: 0.7056 - val_loss: 8.0074 - val_acc: 0.6716
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 24s - loss: 7.9049 - acc: 0.7035 - val_loss: 8.0021 - val_acc: 0.6678
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 24s - loss: 7.9066 - acc: 0.7028 - val_loss: 8.0530 - val_acc: 0.6530
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 24s - loss: 7.9058 - acc: 0.7042 - val_loss: 7.9940 - val_acc: 0.6782
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 24s - loss: 7.9066 - acc: 0.7042 - val_loss: 7.9608 - val_acc: 0.6920
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 24s - loss: 7.9018 - acc: 0.7055 - val_loss: 7.9741 - val_acc: 0.6774
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 24s - loss: 7.9067 - acc: 0.7041 - val_loss: 7.9747 - val_acc: 0.6810
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 24s - loss: 7.9072 - acc: 0.7027 - val_loss: 8.0248 - val_acc: 0.6590
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 24s - loss: 7.9039 - acc: 0.7035 - val_loss: 7.9977 - val_acc: 0.6674
Done

