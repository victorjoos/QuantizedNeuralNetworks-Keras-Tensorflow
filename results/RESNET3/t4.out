Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
ternary_conv2d_1 (TernaryConv2D (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_2 (TernaryConv2D (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_2[0][0]           
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_3 (TernaryConv2D (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_3[0][0]           
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_4 (TernaryConv2D (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_4[0][0]           
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_5 (TernaryConv2D (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_5[0][0]           
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_6 (TernaryConv2D (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_6[0][0]           
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_7 (TernaryConv2D (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_7[0][0]           
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_8 (TernaryConv2D (None, 16, 16, 32)   4640        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         ternary_conv2d_8[0][0]           
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_9 (TernaryConv2D (None, 16, 16, 32)   9248        activation_8[0][0]               
__________________________________________________________________________________________________
ternary_conv2d_10 (TernaryConv2 (None, 16, 16, 32)   544         activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         ternary_conv2d_9[0][0]           
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           ternary_conv2d_10[0][0]          
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_11 (TernaryConv2 (None, 16, 16, 32)   9248        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_11[0][0]          
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_12 (TernaryConv2 (None, 16, 16, 32)   9248        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_12[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_13 (TernaryConv2 (None, 16, 16, 32)   9248        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_13[0][0]          
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_14 (TernaryConv2 (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_14[0][0]          
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_15 (TernaryConv2 (None, 8, 8, 64)     18496       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_15[0][0]          
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_16 (TernaryConv2 (None, 8, 8, 64)     36928       activation_14[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_17 (TernaryConv2 (None, 8, 8, 64)     2112        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_16[0][0]          
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           ternary_conv2d_17[0][0]          
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_18 (TernaryConv2 (None, 8, 8, 64)     36928       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_18[0][0]          
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_19 (TernaryConv2 (None, 8, 8, 64)     36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_19[0][0]          
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_20 (TernaryConv2 (None, 8, 8, 64)     36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_20[0][0]          
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_21 (TernaryConv2 (None, 8, 8, 64)     36928       activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_21[0][0]          
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
ternary_dense_1 (TernaryDense)  (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 274,442
Trainable params: 273,066
Non-trainable params: 1,376
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.14440, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 26s - loss: 10.9663 - acc: 0.1273 - val_loss: 9.8111 - val_acc: 0.1444
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.14440 to 0.20880, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 9.0652 - acc: 0.1892 - val_loss: 8.4139 - val_acc: 0.2088
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc improved from 0.20880 to 0.23540, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 7.8743 - acc: 0.2367 - val_loss: 7.4062 - val_acc: 0.2354
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.23540 to 0.24300, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 6.9673 - acc: 0.2738 - val_loss: 6.6788 - val_acc: 0.2430
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc improved from 0.24300 to 0.25000, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 6.2978 - acc: 0.2912 - val_loss: 6.1795 - val_acc: 0.2500
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc improved from 0.25000 to 0.28540, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 5.7353 - acc: 0.3148 - val_loss: 5.5752 - val_acc: 0.2854
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.28540 to 0.29620, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 5.2933 - acc: 0.3315 - val_loss: 5.2651 - val_acc: 0.2962
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc improved from 0.29620 to 0.33420, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 4.9261 - acc: 0.3531 - val_loss: 4.8297 - val_acc: 0.3342
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 22s - loss: 4.6150 - acc: 0.3718 - val_loss: 4.6196 - val_acc: 0.3074
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc improved from 0.33420 to 0.35440, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 4.3602 - acc: 0.3859 - val_loss: 4.3741 - val_acc: 0.3544
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 22s - loss: 4.1460 - acc: 0.3986 - val_loss: 4.2776 - val_acc: 0.3228
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 22s - loss: 3.9635 - acc: 0.4118 - val_loss: 4.0569 - val_acc: 0.3494
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc did not improve
 - 22s - loss: 3.8071 - acc: 0.4246 - val_loss: 3.9735 - val_acc: 0.3466
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 22s - loss: 3.6678 - acc: 0.4349 - val_loss: 4.6921 - val_acc: 0.1628
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc did not improve
 - 22s - loss: 3.5433 - acc: 0.4424 - val_loss: 3.9827 - val_acc: 0.3034
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 22s - loss: 3.4395 - acc: 0.4502 - val_loss: 3.8081 - val_acc: 0.3268
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc improved from 0.35440 to 0.39300, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 3.3444 - acc: 0.4580 - val_loss: 3.5893 - val_acc: 0.3930
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 22s - loss: 3.2556 - acc: 0.4605 - val_loss: 3.6610 - val_acc: 0.3142
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 22s - loss: 3.1781 - acc: 0.4694 - val_loss: 3.5395 - val_acc: 0.3560
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc did not improve
 - 22s - loss: 3.1137 - acc: 0.4710 - val_loss: 3.5550 - val_acc: 0.3388
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 22s - loss: 3.0330 - acc: 0.4769 - val_loss: 3.3116 - val_acc: 0.3620
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 22s - loss: 2.9604 - acc: 0.4838 - val_loss: 3.4232 - val_acc: 0.3352
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc improved from 0.39300 to 0.42380, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 2.8877 - acc: 0.4912 - val_loss: 3.0404 - val_acc: 0.4238
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 22s - loss: 2.8195 - acc: 0.4971 - val_loss: 3.1143 - val_acc: 0.3848
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 22s - loss: 2.7568 - acc: 0.5024 - val_loss: 3.4097 - val_acc: 0.3324
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc improved from 0.42380 to 0.42600, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 2.6884 - acc: 0.5107 - val_loss: 2.9418 - val_acc: 0.4260
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 22s - loss: 2.6343 - acc: 0.5156 - val_loss: 2.9593 - val_acc: 0.4192
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 22s - loss: 2.5777 - acc: 0.5177 - val_loss: 3.2275 - val_acc: 0.3466
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 22s - loss: 2.5142 - acc: 0.5313 - val_loss: 3.4218 - val_acc: 0.3184
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc improved from 0.42600 to 0.43200, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 2.4644 - acc: 0.5317 - val_loss: 2.7364 - val_acc: 0.4320
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc improved from 0.43200 to 0.47540, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 2.4080 - acc: 0.5399 - val_loss: 2.5717 - val_acc: 0.4754
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 22s - loss: 2.3694 - acc: 0.5416 - val_loss: 2.9249 - val_acc: 0.3560
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 22s - loss: 2.3153 - acc: 0.5470 - val_loss: 2.5575 - val_acc: 0.4648
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 22s - loss: 2.2723 - acc: 0.5527 - val_loss: 3.1872 - val_acc: 0.3152
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 22s - loss: 2.2226 - acc: 0.5568 - val_loss: 2.7985 - val_acc: 0.4036
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 22s - loss: 2.1770 - acc: 0.5653 - val_loss: 3.5185 - val_acc: 0.2380
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 22s - loss: 2.1251 - acc: 0.5748 - val_loss: 3.1901 - val_acc: 0.3436
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 22s - loss: 2.0859 - acc: 0.5797 - val_loss: 2.9419 - val_acc: 0.3314
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 22s - loss: 2.0399 - acc: 0.5865 - val_loss: 2.7581 - val_acc: 0.4024
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 22s - loss: 1.9940 - acc: 0.5927 - val_loss: 2.4942 - val_acc: 0.4368
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc improved from 0.47540 to 0.50380, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 1.9492 - acc: 0.6013 - val_loss: 2.1905 - val_acc: 0.5038
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc improved from 0.50380 to 0.52100, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 1.9097 - acc: 0.6082 - val_loss: 2.1334 - val_acc: 0.5210
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 22s - loss: 1.8685 - acc: 0.6143 - val_loss: 3.5382 - val_acc: 0.3030
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 22s - loss: 1.8360 - acc: 0.6156 - val_loss: 2.4232 - val_acc: 0.4446
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 22s - loss: 1.8003 - acc: 0.6262 - val_loss: 2.0741 - val_acc: 0.5160
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 22s - loss: 1.7695 - acc: 0.6312 - val_loss: 3.4082 - val_acc: 0.3022
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc improved from 0.52100 to 0.54340, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 1.7487 - acc: 0.6315 - val_loss: 1.9966 - val_acc: 0.5434
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 22s - loss: 1.6988 - acc: 0.6433 - val_loss: 2.0757 - val_acc: 0.5162
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 22s - loss: 1.6617 - acc: 0.6491 - val_loss: 2.2387 - val_acc: 0.4496
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 22s - loss: 1.6294 - acc: 0.6570 - val_loss: 2.3229 - val_acc: 0.4432
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 22s - loss: 1.6094 - acc: 0.6589 - val_loss: 2.0684 - val_acc: 0.5204
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc improved from 0.54340 to 0.54700, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 1.5727 - acc: 0.6666 - val_loss: 1.9452 - val_acc: 0.5470
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc improved from 0.54700 to 0.55760, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 1.5440 - acc: 0.6700 - val_loss: 1.9807 - val_acc: 0.5576
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 22s - loss: 1.5246 - acc: 0.6732 - val_loss: 1.9646 - val_acc: 0.5256
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 22s - loss: 1.5021 - acc: 0.6792 - val_loss: 2.7047 - val_acc: 0.4316
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 22s - loss: 1.4696 - acc: 0.6845 - val_loss: 1.9949 - val_acc: 0.5098
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 22s - loss: 1.4409 - acc: 0.6907 - val_loss: 2.6912 - val_acc: 0.3820
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 22s - loss: 1.4292 - acc: 0.6905 - val_loss: 2.7790 - val_acc: 0.3332
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 22s - loss: 1.4052 - acc: 0.6949 - val_loss: 2.2871 - val_acc: 0.4514
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 22s - loss: 1.3772 - acc: 0.7034 - val_loss: 3.3787 - val_acc: 0.3476
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 22s - loss: 1.3566 - acc: 0.7072 - val_loss: 2.7159 - val_acc: 0.3912
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 22s - loss: 1.3403 - acc: 0.7093 - val_loss: 2.4566 - val_acc: 0.4110
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 22s - loss: 1.3146 - acc: 0.7144 - val_loss: 2.1481 - val_acc: 0.4848
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 22s - loss: 1.2974 - acc: 0.7203 - val_loss: 2.1620 - val_acc: 0.5110
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 22s - loss: 1.2809 - acc: 0.7214 - val_loss: 2.1223 - val_acc: 0.4744
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc improved from 0.55760 to 0.56840, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 1.2678 - acc: 0.7223 - val_loss: 1.7181 - val_acc: 0.5684
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 21s - loss: 1.2562 - acc: 0.7246 - val_loss: 2.2595 - val_acc: 0.4566
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 22s - loss: 1.2408 - acc: 0.7256 - val_loss: 1.7274 - val_acc: 0.5666
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 22s - loss: 1.2145 - acc: 0.7352 - val_loss: 1.8164 - val_acc: 0.5570
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc improved from 0.56840 to 0.61660, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 1.1973 - acc: 0.7375 - val_loss: 1.5514 - val_acc: 0.6166
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc improved from 0.61660 to 0.61820, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 1.1865 - acc: 0.7366 - val_loss: 1.5315 - val_acc: 0.6182
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 22s - loss: 1.1697 - acc: 0.7431 - val_loss: 1.9171 - val_acc: 0.5244
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 22s - loss: 1.1533 - acc: 0.7462 - val_loss: 1.8587 - val_acc: 0.5438
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 22s - loss: 1.1426 - acc: 0.7475 - val_loss: 1.6977 - val_acc: 0.5772
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 22s - loss: 1.1273 - acc: 0.7498 - val_loss: 1.9469 - val_acc: 0.5520
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 22s - loss: 1.1216 - acc: 0.7519 - val_loss: 1.7198 - val_acc: 0.5690
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 22s - loss: 1.1043 - acc: 0.7551 - val_loss: 1.8174 - val_acc: 0.5600
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 22s - loss: 1.0914 - acc: 0.7587 - val_loss: 1.5888 - val_acc: 0.5864
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 22s - loss: 1.0739 - acc: 0.7586 - val_loss: 2.1436 - val_acc: 0.5068
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc improved from 0.61820 to 0.64000, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 1.0647 - acc: 0.7630 - val_loss: 1.4654 - val_acc: 0.6400
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 22s - loss: 1.0569 - acc: 0.7622 - val_loss: 1.7312 - val_acc: 0.5690
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.64000 to 0.76500, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 23s - loss: 0.9112 - acc: 0.8153 - val_loss: 1.0642 - val_acc: 0.7650
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc did not improve
 - 22s - loss: 0.8605 - acc: 0.8324 - val_loss: 1.0682 - val_acc: 0.7616
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc improved from 0.76500 to 0.77400, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 0.8359 - acc: 0.8397 - val_loss: 1.0314 - val_acc: 0.7740
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 22s - loss: 0.8164 - acc: 0.8473 - val_loss: 1.0483 - val_acc: 0.7716
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 22s - loss: 0.8087 - acc: 0.8473 - val_loss: 1.0731 - val_acc: 0.7612
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 22s - loss: 0.7978 - acc: 0.8518 - val_loss: 1.4257 - val_acc: 0.6784
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 22s - loss: 0.7871 - acc: 0.8549 - val_loss: 1.2373 - val_acc: 0.7118
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 22s - loss: 0.7776 - acc: 0.8582 - val_loss: 1.1420 - val_acc: 0.7402
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 22s - loss: 0.7677 - acc: 0.8602 - val_loss: 1.2096 - val_acc: 0.7272
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 22s - loss: 0.7624 - acc: 0.8611 - val_loss: 1.2545 - val_acc: 0.7126
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 22s - loss: 0.7547 - acc: 0.8627 - val_loss: 1.1323 - val_acc: 0.7442
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 22s - loss: 0.7478 - acc: 0.8670 - val_loss: 1.1198 - val_acc: 0.7424
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 22s - loss: 0.7468 - acc: 0.8676 - val_loss: 1.1920 - val_acc: 0.7256
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 22s - loss: 0.7410 - acc: 0.8682 - val_loss: 1.1454 - val_acc: 0.7326
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 22s - loss: 0.7371 - acc: 0.8679 - val_loss: 1.2914 - val_acc: 0.7044
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 22s - loss: 0.7273 - acc: 0.8707 - val_loss: 1.2850 - val_acc: 0.7088
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 22s - loss: 0.7192 - acc: 0.8760 - val_loss: 1.2810 - val_acc: 0.7052
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 22s - loss: 0.7115 - acc: 0.8766 - val_loss: 1.0826 - val_acc: 0.7540
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 22s - loss: 0.7111 - acc: 0.8768 - val_loss: 1.1008 - val_acc: 0.7534
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 22s - loss: 0.7127 - acc: 0.8749 - val_loss: 1.1971 - val_acc: 0.7276
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 22s - loss: 0.7140 - acc: 0.8744 - val_loss: 1.2788 - val_acc: 0.7110
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 22s - loss: 0.7033 - acc: 0.8768 - val_loss: 1.3046 - val_acc: 0.7058
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 22s - loss: 0.7072 - acc: 0.8747 - val_loss: 1.2924 - val_acc: 0.7064
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 22s - loss: 0.7005 - acc: 0.8788 - val_loss: 1.1400 - val_acc: 0.7532
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 22s - loss: 0.6966 - acc: 0.8796 - val_loss: 1.1523 - val_acc: 0.7428
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 22s - loss: 0.6957 - acc: 0.8799 - val_loss: 1.3697 - val_acc: 0.6854
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 22s - loss: 0.6877 - acc: 0.8816 - val_loss: 1.2603 - val_acc: 0.7026
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 22s - loss: 0.6867 - acc: 0.8821 - val_loss: 1.2740 - val_acc: 0.7196
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 22s - loss: 0.6870 - acc: 0.8820 - val_loss: 1.3272 - val_acc: 0.6996
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 22s - loss: 0.6795 - acc: 0.8837 - val_loss: 1.3668 - val_acc: 0.6948
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 22s - loss: 0.6813 - acc: 0.8845 - val_loss: 1.1050 - val_acc: 0.7536
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 22s - loss: 0.6765 - acc: 0.8840 - val_loss: 1.3983 - val_acc: 0.6768
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 21s - loss: 0.6743 - acc: 0.8833 - val_loss: 1.2816 - val_acc: 0.7222
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 22s - loss: 0.6772 - acc: 0.8846 - val_loss: 1.1809 - val_acc: 0.7408
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 22s - loss: 0.6663 - acc: 0.8871 - val_loss: 1.1493 - val_acc: 0.7420
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 22s - loss: 0.6653 - acc: 0.8872 - val_loss: 1.2904 - val_acc: 0.7110
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 22s - loss: 0.6676 - acc: 0.8864 - val_loss: 1.1914 - val_acc: 0.7374
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 22s - loss: 0.6594 - acc: 0.8892 - val_loss: 1.2389 - val_acc: 0.7186
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 22s - loss: 0.6563 - acc: 0.8906 - val_loss: 1.2032 - val_acc: 0.7250
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 22s - loss: 0.6596 - acc: 0.8887 - val_loss: 1.4186 - val_acc: 0.6922
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc did not improve
 - 22s - loss: 0.5939 - acc: 0.9142 - val_loss: 1.1189 - val_acc: 0.7562
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc improved from 0.77400 to 0.77620, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 0.5754 - acc: 0.9208 - val_loss: 1.0293 - val_acc: 0.7762
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc improved from 0.77620 to 0.78680, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 0.5673 - acc: 0.9238 - val_loss: 1.0241 - val_acc: 0.7868
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 22s - loss: 0.5673 - acc: 0.9237 - val_loss: 1.0587 - val_acc: 0.7706
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 22s - loss: 0.5647 - acc: 0.9250 - val_loss: 1.0957 - val_acc: 0.7582
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 22s - loss: 0.5655 - acc: 0.9254 - val_loss: 1.0349 - val_acc: 0.7804
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 22s - loss: 0.5580 - acc: 0.9264 - val_loss: 1.1021 - val_acc: 0.7650
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 22s - loss: 0.5596 - acc: 0.9268 - val_loss: 1.0730 - val_acc: 0.7692
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 22s - loss: 0.5619 - acc: 0.9251 - val_loss: 1.1742 - val_acc: 0.7468
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 22s - loss: 0.5589 - acc: 0.9266 - val_loss: 1.0068 - val_acc: 0.7866
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 22s - loss: 0.5593 - acc: 0.9260 - val_loss: 1.0958 - val_acc: 0.7576
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 22s - loss: 0.5659 - acc: 0.9226 - val_loss: 1.1751 - val_acc: 0.7446
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 22s - loss: 0.5533 - acc: 0.9290 - val_loss: 1.0719 - val_acc: 0.7678
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 22s - loss: 0.5579 - acc: 0.9262 - val_loss: 1.0731 - val_acc: 0.7790
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 22s - loss: 0.5568 - acc: 0.9277 - val_loss: 1.0513 - val_acc: 0.7752
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 22s - loss: 0.5603 - acc: 0.9262 - val_loss: 1.0864 - val_acc: 0.7684
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 22s - loss: 0.5566 - acc: 0.9257 - val_loss: 1.0574 - val_acc: 0.7722
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 22s - loss: 0.5584 - acc: 0.9270 - val_loss: 1.1368 - val_acc: 0.7546
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 22s - loss: 0.5575 - acc: 0.9263 - val_loss: 1.2486 - val_acc: 0.7342
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 22s - loss: 0.5561 - acc: 0.9265 - val_loss: 1.2626 - val_acc: 0.7312
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 22s - loss: 0.5578 - acc: 0.9275 - val_loss: 1.2071 - val_acc: 0.7406
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 22s - loss: 0.5513 - acc: 0.9291 - val_loss: 1.0987 - val_acc: 0.7706
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 22s - loss: 0.5583 - acc: 0.9262 - val_loss: 1.0863 - val_acc: 0.7650
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 22s - loss: 0.5555 - acc: 0.9267 - val_loss: 1.1100 - val_acc: 0.7558
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 22s - loss: 0.5570 - acc: 0.9262 - val_loss: 1.0699 - val_acc: 0.7742
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 22s - loss: 0.5569 - acc: 0.9261 - val_loss: 1.0716 - val_acc: 0.7762
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 22s - loss: 0.5572 - acc: 0.9254 - val_loss: 1.1303 - val_acc: 0.7642
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 22s - loss: 0.5519 - acc: 0.9284 - val_loss: 1.0634 - val_acc: 0.7700
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 22s - loss: 0.5563 - acc: 0.9268 - val_loss: 1.1422 - val_acc: 0.7508
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 22s - loss: 0.5545 - acc: 0.9279 - val_loss: 1.2723 - val_acc: 0.7216
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 22s - loss: 0.5496 - acc: 0.9277 - val_loss: 1.1364 - val_acc: 0.7638
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 22s - loss: 0.5547 - acc: 0.9273 - val_loss: 1.1760 - val_acc: 0.7506
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 22s - loss: 0.5524 - acc: 0.9280 - val_loss: 1.1429 - val_acc: 0.7576
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 22s - loss: 0.5503 - acc: 0.9285 - val_loss: 1.1418 - val_acc: 0.7542
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 22s - loss: 0.5531 - acc: 0.9273 - val_loss: 1.1655 - val_acc: 0.7476
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 22s - loss: 0.5492 - acc: 0.9296 - val_loss: 1.1002 - val_acc: 0.7672
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 22s - loss: 0.5482 - acc: 0.9291 - val_loss: 1.2385 - val_acc: 0.7340
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 22s - loss: 0.5558 - acc: 0.9258 - val_loss: 1.0810 - val_acc: 0.7746
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 22s - loss: 0.5545 - acc: 0.9252 - val_loss: 1.1488 - val_acc: 0.7482
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 22s - loss: 0.5521 - acc: 0.9271 - val_loss: 1.1079 - val_acc: 0.7574
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 22s - loss: 0.5176 - acc: 0.9409 - val_loss: 1.0672 - val_acc: 0.7750
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 22s - loss: 0.5125 - acc: 0.9440 - val_loss: 1.0844 - val_acc: 0.7708
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 22s - loss: 0.5120 - acc: 0.9436 - val_loss: 1.0964 - val_acc: 0.7714
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 22s - loss: 0.5184 - acc: 0.9422 - val_loss: 1.0325 - val_acc: 0.7798
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 22s - loss: 0.5187 - acc: 0.9412 - val_loss: 1.1963 - val_acc: 0.7480
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 22s - loss: 0.5179 - acc: 0.9403 - val_loss: 1.1155 - val_acc: 0.7698
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 22s - loss: 0.5169 - acc: 0.9417 - val_loss: 1.1134 - val_acc: 0.7694
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 22s - loss: 0.5185 - acc: 0.9414 - val_loss: 1.1012 - val_acc: 0.7692
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 22s - loss: 0.5180 - acc: 0.9407 - val_loss: 1.0351 - val_acc: 0.7812
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 22s - loss: 0.5175 - acc: 0.9422 - val_loss: 1.0772 - val_acc: 0.7760
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 22s - loss: 0.5135 - acc: 0.9443 - val_loss: 1.1696 - val_acc: 0.7436
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 22s - loss: 0.5206 - acc: 0.9406 - val_loss: 1.0846 - val_acc: 0.7788
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 22s - loss: 0.5204 - acc: 0.9403 - val_loss: 1.1576 - val_acc: 0.7544
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 22s - loss: 0.5171 - acc: 0.9418 - val_loss: 1.0588 - val_acc: 0.7798
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 22s - loss: 0.5201 - acc: 0.9396 - val_loss: 1.0518 - val_acc: 0.7788
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 22s - loss: 0.5197 - acc: 0.9406 - val_loss: 1.1414 - val_acc: 0.7560
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 22s - loss: 0.5205 - acc: 0.9400 - val_loss: 1.1958 - val_acc: 0.7540
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 22s - loss: 0.5220 - acc: 0.9400 - val_loss: 1.0496 - val_acc: 0.7822
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 22s - loss: 0.5182 - acc: 0.9407 - val_loss: 1.0828 - val_acc: 0.7664
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 22s - loss: 0.5208 - acc: 0.9409 - val_loss: 1.1095 - val_acc: 0.7682
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 22s - loss: 0.5120 - acc: 0.9436 - val_loss: 1.1343 - val_acc: 0.7572
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 22s - loss: 0.5125 - acc: 0.9442 - val_loss: 1.0945 - val_acc: 0.7656
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 22s - loss: 0.5144 - acc: 0.9433 - val_loss: 1.1614 - val_acc: 0.7576
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 22s - loss: 0.5169 - acc: 0.9411 - val_loss: 1.2160 - val_acc: 0.7422
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 22s - loss: 0.5167 - acc: 0.9419 - val_loss: 1.0653 - val_acc: 0.7772
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 22s - loss: 0.5183 - acc: 0.9394 - val_loss: 1.0515 - val_acc: 0.7776
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 22s - loss: 0.5158 - acc: 0.9423 - val_loss: 1.1752 - val_acc: 0.7472
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 22s - loss: 0.5160 - acc: 0.9415 - val_loss: 1.1441 - val_acc: 0.7594
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 22s - loss: 0.5191 - acc: 0.9406 - val_loss: 1.1324 - val_acc: 0.7654
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 22s - loss: 0.5179 - acc: 0.9407 - val_loss: 1.0856 - val_acc: 0.7676
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 22s - loss: 0.5175 - acc: 0.9415 - val_loss: 1.0751 - val_acc: 0.7668
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 22s - loss: 0.5170 - acc: 0.9411 - val_loss: 1.1696 - val_acc: 0.7410
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 22s - loss: 0.5157 - acc: 0.9424 - val_loss: 1.2900 - val_acc: 0.7172
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 22s - loss: 0.5223 - acc: 0.9392 - val_loss: 1.0342 - val_acc: 0.7796
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 22s - loss: 0.5157 - acc: 0.9413 - val_loss: 1.0972 - val_acc: 0.7692
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 22s - loss: 0.5166 - acc: 0.9404 - val_loss: 1.0869 - val_acc: 0.7750
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc improved from 0.78680 to 0.78760, saving model to ./weights/RESNET_CIFAR-10_qtnn_4b_4b_3.hdf5
 - 22s - loss: 0.5201 - acc: 0.9386 - val_loss: 1.0377 - val_acc: 0.7876
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 21s - loss: 0.5229 - acc: 0.9384 - val_loss: 1.0270 - val_acc: 0.7782
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 22s - loss: 0.5164 - acc: 0.9413 - val_loss: 1.1800 - val_acc: 0.7560
Done

