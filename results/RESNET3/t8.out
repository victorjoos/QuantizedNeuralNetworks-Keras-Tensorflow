Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
ternary_conv2d_1 (TernaryConv2D (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_2 (TernaryConv2D (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_2[0][0]           
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_3 (TernaryConv2D (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_3[0][0]           
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_4 (TernaryConv2D (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_4[0][0]           
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_5 (TernaryConv2D (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_5[0][0]           
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_6 (TernaryConv2D (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_6[0][0]           
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_7 (TernaryConv2D (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          ternary_conv2d_7[0][0]           
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_8 (TernaryConv2D (None, 16, 16, 32)   4640        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         ternary_conv2d_8[0][0]           
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
ternary_conv2d_9 (TernaryConv2D (None, 16, 16, 32)   9248        activation_8[0][0]               
__________________________________________________________________________________________________
ternary_conv2d_10 (TernaryConv2 (None, 16, 16, 32)   544         activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         ternary_conv2d_9[0][0]           
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           ternary_conv2d_10[0][0]          
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_11 (TernaryConv2 (None, 16, 16, 32)   9248        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_11[0][0]          
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_12 (TernaryConv2 (None, 16, 16, 32)   9248        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_12[0][0]          
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_13 (TernaryConv2 (None, 16, 16, 32)   9248        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_13[0][0]          
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_14 (TernaryConv2 (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         ternary_conv2d_14[0][0]          
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_15 (TernaryConv2 (None, 8, 8, 64)     18496       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_15[0][0]          
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_16 (TernaryConv2 (None, 8, 8, 64)     36928       activation_14[0][0]              
__________________________________________________________________________________________________
ternary_conv2d_17 (TernaryConv2 (None, 8, 8, 64)     2112        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_16[0][0]          
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           ternary_conv2d_17[0][0]          
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_18 (TernaryConv2 (None, 8, 8, 64)     36928       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_18[0][0]          
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_19 (TernaryConv2 (None, 8, 8, 64)     36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_19[0][0]          
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      
__________________________________________________________________________________________________
ternary_conv2d_20 (TernaryConv2 (None, 8, 8, 64)     36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_20[0][0]          
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
ternary_conv2d_21 (TernaryConv2 (None, 8, 8, 64)     36928       activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         ternary_conv2d_21[0][0]          
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
ternary_dense_1 (TernaryDense)  (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 274,442
Trainable params: 273,066
Non-trainable params: 1,376
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.11640, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 26s - loss: 10.6398 - acc: 0.1247 - val_loss: 9.7239 - val_acc: 0.1164
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.11640 to 0.15700, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 8.8402 - acc: 0.1733 - val_loss: 8.2539 - val_acc: 0.1570
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc improved from 0.15700 to 0.21120, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 7.6216 - acc: 0.2097 - val_loss: 7.1892 - val_acc: 0.2112
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.21120 to 0.21840, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 6.7284 - acc: 0.2310 - val_loss: 6.4422 - val_acc: 0.2184
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc improved from 0.21840 to 0.22160, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 6.0088 - acc: 0.2705 - val_loss: 5.9110 - val_acc: 0.2216
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc improved from 0.22160 to 0.26860, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 5.4663 - acc: 0.2918 - val_loss: 5.2775 - val_acc: 0.2686
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.26860 to 0.29360, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 5.0230 - acc: 0.3114 - val_loss: 4.8860 - val_acc: 0.2936
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc improved from 0.29360 to 0.34060, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 4.6286 - acc: 0.3443 - val_loss: 4.5049 - val_acc: 0.3406
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc did not improve
 - 22s - loss: 4.3244 - acc: 0.3631 - val_loss: 4.2700 - val_acc: 0.3394
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc improved from 0.34060 to 0.34600, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 4.0726 - acc: 0.3792 - val_loss: 4.1161 - val_acc: 0.3460
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc improved from 0.34600 to 0.35220, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 3.8468 - acc: 0.3981 - val_loss: 3.8554 - val_acc: 0.3522
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 22s - loss: 3.6636 - acc: 0.4112 - val_loss: 3.8384 - val_acc: 0.3470
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc improved from 0.35220 to 0.37840, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 3.5028 - acc: 0.4205 - val_loss: 3.5873 - val_acc: 0.3784
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 22s - loss: 3.3632 - acc: 0.4336 - val_loss: 3.5307 - val_acc: 0.3646
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc did not improve
 - 22s - loss: 3.2547 - acc: 0.4340 - val_loss: 3.4169 - val_acc: 0.3646
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc did not improve
 - 22s - loss: 3.1336 - acc: 0.4431 - val_loss: 3.6141 - val_acc: 0.3120
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 22s - loss: 3.0211 - acc: 0.4546 - val_loss: 3.1921 - val_acc: 0.3732
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 22s - loss: 2.9262 - acc: 0.4627 - val_loss: 3.5374 - val_acc: 0.2938
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc did not improve
 - 22s - loss: 2.8360 - acc: 0.4670 - val_loss: 3.1429 - val_acc: 0.3358
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc improved from 0.37840 to 0.42520, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 2.7498 - acc: 0.4711 - val_loss: 2.8435 - val_acc: 0.4252
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 22s - loss: 2.6732 - acc: 0.4732 - val_loss: 2.7897 - val_acc: 0.4152
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 22s - loss: 2.6015 - acc: 0.4767 - val_loss: 2.8655 - val_acc: 0.3670
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 22s - loss: 2.5248 - acc: 0.4835 - val_loss: 2.8759 - val_acc: 0.3428
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc did not improve
 - 22s - loss: 2.4406 - acc: 0.4915 - val_loss: 2.8708 - val_acc: 0.3496
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc did not improve
 - 22s - loss: 2.3809 - acc: 0.4940 - val_loss: 2.9936 - val_acc: 0.3230
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 22s - loss: 2.3200 - acc: 0.5012 - val_loss: 2.5840 - val_acc: 0.3858
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc did not improve
 - 22s - loss: 2.2594 - acc: 0.5035 - val_loss: 2.5931 - val_acc: 0.3980
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 22s - loss: 2.2014 - acc: 0.5068 - val_loss: 2.6845 - val_acc: 0.3320
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc did not improve
 - 22s - loss: 2.1433 - acc: 0.5137 - val_loss: 2.5465 - val_acc: 0.3906
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 22s - loss: 2.0910 - acc: 0.5171 - val_loss: 3.2357 - val_acc: 0.2774
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 22s - loss: 2.0324 - acc: 0.5262 - val_loss: 2.8830 - val_acc: 0.3616
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc improved from 0.42520 to 0.44800, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 1.9837 - acc: 0.5321 - val_loss: 2.1988 - val_acc: 0.4480
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc did not improve
 - 22s - loss: 1.9506 - acc: 0.5321 - val_loss: 2.4276 - val_acc: 0.3706
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 22s - loss: 1.9261 - acc: 0.5336 - val_loss: 2.4292 - val_acc: 0.3926
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 22s - loss: 1.8869 - acc: 0.5363 - val_loss: 2.3543 - val_acc: 0.3640
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 22s - loss: 1.8383 - acc: 0.5455 - val_loss: 2.3348 - val_acc: 0.3760
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 22s - loss: 1.7873 - acc: 0.5561 - val_loss: 3.5787 - val_acc: 0.2202
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 22s - loss: 1.7472 - acc: 0.5615 - val_loss: 2.2685 - val_acc: 0.4380
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc did not improve
 - 22s - loss: 1.7194 - acc: 0.5654 - val_loss: 2.3221 - val_acc: 0.3594
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 22s - loss: 1.6783 - acc: 0.5736 - val_loss: 2.4838 - val_acc: 0.3502
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc improved from 0.44800 to 0.49160, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 1.6612 - acc: 0.5719 - val_loss: 1.9204 - val_acc: 0.4916
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc did not improve
 - 22s - loss: 1.6233 - acc: 0.5862 - val_loss: 2.6101 - val_acc: 0.3056
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 22s - loss: 1.5925 - acc: 0.5916 - val_loss: 2.1127 - val_acc: 0.4106
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 22s - loss: 1.5652 - acc: 0.5950 - val_loss: 3.8350 - val_acc: 0.1978
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc improved from 0.49160 to 0.49560, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 1.5472 - acc: 0.5943 - val_loss: 1.8254 - val_acc: 0.4956
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 22s - loss: 1.5109 - acc: 0.6046 - val_loss: 2.0466 - val_acc: 0.4196
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc improved from 0.49560 to 0.52500, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 1.4864 - acc: 0.6101 - val_loss: 1.6851 - val_acc: 0.5250
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 22s - loss: 1.4507 - acc: 0.6222 - val_loss: 2.0156 - val_acc: 0.4350
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 22s - loss: 1.4326 - acc: 0.6209 - val_loss: 1.9611 - val_acc: 0.4628
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 22s - loss: 1.4117 - acc: 0.6254 - val_loss: 2.7023 - val_acc: 0.3494
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc did not improve
 - 22s - loss: 1.3919 - acc: 0.6292 - val_loss: 2.2465 - val_acc: 0.3958
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc did not improve
 - 22s - loss: 1.3586 - acc: 0.6374 - val_loss: 1.8164 - val_acc: 0.4902
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 22s - loss: 1.3341 - acc: 0.6447 - val_loss: 1.7775 - val_acc: 0.4998
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 22s - loss: 1.3146 - acc: 0.6494 - val_loss: 1.7902 - val_acc: 0.4956
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc did not improve
 - 22s - loss: 1.2881 - acc: 0.6547 - val_loss: 1.9614 - val_acc: 0.4510
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 22s - loss: 1.2675 - acc: 0.6567 - val_loss: 1.8883 - val_acc: 0.4966
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc improved from 0.52500 to 0.55560, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 1.2388 - acc: 0.6672 - val_loss: 1.6103 - val_acc: 0.5556
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc improved from 0.55560 to 0.58080, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 1.2146 - acc: 0.6745 - val_loss: 1.4969 - val_acc: 0.5808
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 22s - loss: 1.2006 - acc: 0.6767 - val_loss: 1.6489 - val_acc: 0.5412
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 22s - loss: 1.1832 - acc: 0.6796 - val_loss: 1.5571 - val_acc: 0.5468
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 22s - loss: 1.1672 - acc: 0.6832 - val_loss: 3.0077 - val_acc: 0.3510
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 22s - loss: 1.1525 - acc: 0.6850 - val_loss: 1.8423 - val_acc: 0.4722
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc improved from 0.58080 to 0.60220, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 1.1396 - acc: 0.6884 - val_loss: 1.4284 - val_acc: 0.6022
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 22s - loss: 1.1223 - acc: 0.6940 - val_loss: 1.7527 - val_acc: 0.4944
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 22s - loss: 1.1026 - acc: 0.6987 - val_loss: 1.8902 - val_acc: 0.4724
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 22s - loss: 1.0901 - acc: 0.6997 - val_loss: 2.1470 - val_acc: 0.4314
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 22s - loss: 1.0820 - acc: 0.6992 - val_loss: 2.1677 - val_acc: 0.3890
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 22s - loss: 1.0533 - acc: 0.7105 - val_loss: 1.4863 - val_acc: 0.5818
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 22s - loss: 1.0445 - acc: 0.7122 - val_loss: 1.7959 - val_acc: 0.4832
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc did not improve
 - 22s - loss: 1.0255 - acc: 0.7152 - val_loss: 1.7842 - val_acc: 0.5094
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 22s - loss: 1.0146 - acc: 0.7132 - val_loss: 2.0154 - val_acc: 0.4058
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 22s - loss: 1.0143 - acc: 0.7162 - val_loss: 2.0566 - val_acc: 0.4358
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 22s - loss: 0.9994 - acc: 0.7197 - val_loss: 1.6052 - val_acc: 0.5192
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 22s - loss: 0.9854 - acc: 0.7234 - val_loss: 1.8012 - val_acc: 0.5080
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc did not improve
 - 22s - loss: 0.9707 - acc: 0.7238 - val_loss: 2.0004 - val_acc: 0.4798
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 22s - loss: 0.9583 - acc: 0.7274 - val_loss: 1.5816 - val_acc: 0.5200
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc improved from 0.60220 to 0.62060, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 0.9457 - acc: 0.7296 - val_loss: 1.2712 - val_acc: 0.6206
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 22s - loss: 0.9347 - acc: 0.7299 - val_loss: 1.5532 - val_acc: 0.5278
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 22s - loss: 0.9306 - acc: 0.7312 - val_loss: 1.8380 - val_acc: 0.5124
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 22s - loss: 0.9138 - acc: 0.7340 - val_loss: 1.7561 - val_acc: 0.5144
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 22s - loss: 0.9096 - acc: 0.7356 - val_loss: 1.5253 - val_acc: 0.5360
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.62060 to 0.71700, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 0.7623 - acc: 0.7898 - val_loss: 0.9619 - val_acc: 0.7170
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc improved from 0.71700 to 0.75520, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 0.7023 - acc: 0.8101 - val_loss: 0.8414 - val_acc: 0.7552
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc did not improve
 - 22s - loss: 0.6757 - acc: 0.8187 - val_loss: 0.9762 - val_acc: 0.7108
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 22s - loss: 0.6549 - acc: 0.8250 - val_loss: 0.9016 - val_acc: 0.7434
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 22s - loss: 0.6355 - acc: 0.8312 - val_loss: 0.8945 - val_acc: 0.7476
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 22s - loss: 0.6228 - acc: 0.8367 - val_loss: 0.8544 - val_acc: 0.7518
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc did not improve
 - 22s - loss: 0.6116 - acc: 0.8399 - val_loss: 0.9332 - val_acc: 0.7340
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc did not improve
 - 22s - loss: 0.5955 - acc: 0.8453 - val_loss: 0.8773 - val_acc: 0.7470
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 22s - loss: 0.5868 - acc: 0.8484 - val_loss: 0.9546 - val_acc: 0.7288
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 22s - loss: 0.5801 - acc: 0.8502 - val_loss: 0.9537 - val_acc: 0.7306
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 22s - loss: 0.5708 - acc: 0.8542 - val_loss: 0.8840 - val_acc: 0.7458
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 22s - loss: 0.5704 - acc: 0.8506 - val_loss: 0.9179 - val_acc: 0.7392
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 22s - loss: 0.5676 - acc: 0.8526 - val_loss: 0.9844 - val_acc: 0.7248
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 22s - loss: 0.5616 - acc: 0.8550 - val_loss: 0.9541 - val_acc: 0.7330
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc improved from 0.75520 to 0.75720, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 0.5493 - acc: 0.8573 - val_loss: 0.8679 - val_acc: 0.7572
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 22s - loss: 0.5471 - acc: 0.8596 - val_loss: 0.9496 - val_acc: 0.7338
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 22s - loss: 0.5455 - acc: 0.8594 - val_loss: 0.9223 - val_acc: 0.7380
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 22s - loss: 0.5377 - acc: 0.8612 - val_loss: 1.0930 - val_acc: 0.6906
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 22s - loss: 0.5321 - acc: 0.8652 - val_loss: 1.2603 - val_acc: 0.6500
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 22s - loss: 0.5282 - acc: 0.8650 - val_loss: 0.9537 - val_acc: 0.7318
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 22s - loss: 0.5308 - acc: 0.8636 - val_loss: 0.9177 - val_acc: 0.7420
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 22s - loss: 0.5181 - acc: 0.8704 - val_loss: 0.9953 - val_acc: 0.7144
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 22s - loss: 0.5206 - acc: 0.8664 - val_loss: 1.0756 - val_acc: 0.6886
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 22s - loss: 0.5244 - acc: 0.8655 - val_loss: 0.9649 - val_acc: 0.7254
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 22s - loss: 0.5175 - acc: 0.8684 - val_loss: 0.9810 - val_acc: 0.7252
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 22s - loss: 0.5164 - acc: 0.8685 - val_loss: 0.9853 - val_acc: 0.7164
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 22s - loss: 0.5200 - acc: 0.8655 - val_loss: 0.9594 - val_acc: 0.7376
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 22s - loss: 0.5123 - acc: 0.8660 - val_loss: 1.0056 - val_acc: 0.7178
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 22s - loss: 0.5056 - acc: 0.8722 - val_loss: 1.0004 - val_acc: 0.7244
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 22s - loss: 0.5063 - acc: 0.8698 - val_loss: 1.1012 - val_acc: 0.6864
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 22s - loss: 0.5089 - acc: 0.8687 - val_loss: 0.9557 - val_acc: 0.7310
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 22s - loss: 0.5087 - acc: 0.8676 - val_loss: 1.1298 - val_acc: 0.6940
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 22s - loss: 0.4994 - acc: 0.8723 - val_loss: 1.3590 - val_acc: 0.6512
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 22s - loss: 0.4975 - acc: 0.8712 - val_loss: 0.9890 - val_acc: 0.7282
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 22s - loss: 0.4946 - acc: 0.8734 - val_loss: 0.9331 - val_acc: 0.7332
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 22s - loss: 0.4983 - acc: 0.8712 - val_loss: 1.9596 - val_acc: 0.5250
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 22s - loss: 0.4897 - acc: 0.8759 - val_loss: 1.2484 - val_acc: 0.6498
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 22s - loss: 0.4951 - acc: 0.8711 - val_loss: 1.2813 - val_acc: 0.6392
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 22s - loss: 0.4886 - acc: 0.8737 - val_loss: 1.2335 - val_acc: 0.6710
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 22s - loss: 0.4828 - acc: 0.8763 - val_loss: 1.1716 - val_acc: 0.6858
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc improved from 0.75720 to 0.78260, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 0.4135 - acc: 0.9053 - val_loss: 0.7777 - val_acc: 0.7826
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc improved from 0.78260 to 0.78720, saving model to ./weights/RESNET_CIFAR-10_qtnn_8b_4b_3.hdf5
 - 22s - loss: 0.3874 - acc: 0.9148 - val_loss: 0.7882 - val_acc: 0.7872
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 22s - loss: 0.3819 - acc: 0.9165 - val_loss: 0.8518 - val_acc: 0.7610
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 22s - loss: 0.3722 - acc: 0.9206 - val_loss: 0.9173 - val_acc: 0.7464
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 22s - loss: 0.3713 - acc: 0.9203 - val_loss: 1.0106 - val_acc: 0.7358
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 22s - loss: 0.3683 - acc: 0.9226 - val_loss: 0.9120 - val_acc: 0.7536
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 22s - loss: 0.3688 - acc: 0.9193 - val_loss: 0.8861 - val_acc: 0.7644
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 22s - loss: 0.3678 - acc: 0.9209 - val_loss: 0.8161 - val_acc: 0.7802
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 22s - loss: 0.3693 - acc: 0.9214 - val_loss: 0.9508 - val_acc: 0.7550
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 22s - loss: 0.3665 - acc: 0.9222 - val_loss: 0.9162 - val_acc: 0.7536
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 22s - loss: 0.3630 - acc: 0.9222 - val_loss: 0.9610 - val_acc: 0.7428
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc did not improve
 - 22s - loss: 0.3676 - acc: 0.9213 - val_loss: 0.9801 - val_acc: 0.7462
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 22s - loss: 0.3652 - acc: 0.9217 - val_loss: 0.9352 - val_acc: 0.7490
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 22s - loss: 0.3610 - acc: 0.9242 - val_loss: 0.8883 - val_acc: 0.7634
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 22s - loss: 0.3646 - acc: 0.9213 - val_loss: 0.9880 - val_acc: 0.7356
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 22s - loss: 0.3599 - acc: 0.9238 - val_loss: 1.0525 - val_acc: 0.7088
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 22s - loss: 0.3643 - acc: 0.9209 - val_loss: 1.0490 - val_acc: 0.7190
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 22s - loss: 0.3610 - acc: 0.9232 - val_loss: 1.0065 - val_acc: 0.7354
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 22s - loss: 0.3620 - acc: 0.9228 - val_loss: 0.9988 - val_acc: 0.7258
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 22s - loss: 0.3634 - acc: 0.9222 - val_loss: 1.1566 - val_acc: 0.6990
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 22s - loss: 0.3639 - acc: 0.9208 - val_loss: 1.0911 - val_acc: 0.7120
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 22s - loss: 0.3641 - acc: 0.9216 - val_loss: 0.8928 - val_acc: 0.7606
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 22s - loss: 0.3604 - acc: 0.9222 - val_loss: 0.9546 - val_acc: 0.7482
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 22s - loss: 0.3622 - acc: 0.9236 - val_loss: 0.9310 - val_acc: 0.7412
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 22s - loss: 0.3683 - acc: 0.9199 - val_loss: 1.0852 - val_acc: 0.7252
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 22s - loss: 0.3654 - acc: 0.9210 - val_loss: 0.9293 - val_acc: 0.7510
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 22s - loss: 0.3662 - acc: 0.9204 - val_loss: 1.1040 - val_acc: 0.6982
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 22s - loss: 0.3589 - acc: 0.9244 - val_loss: 1.1600 - val_acc: 0.7018
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 22s - loss: 0.3575 - acc: 0.9239 - val_loss: 1.0004 - val_acc: 0.7380
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 22s - loss: 0.3583 - acc: 0.9233 - val_loss: 0.9342 - val_acc: 0.7474
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 22s - loss: 0.3645 - acc: 0.9207 - val_loss: 0.9815 - val_acc: 0.7354
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 22s - loss: 0.3633 - acc: 0.9217 - val_loss: 0.9556 - val_acc: 0.7454
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 22s - loss: 0.3609 - acc: 0.9226 - val_loss: 1.1201 - val_acc: 0.7076
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 22s - loss: 0.3662 - acc: 0.9207 - val_loss: 0.9000 - val_acc: 0.7566
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 22s - loss: 0.3598 - acc: 0.9233 - val_loss: 0.9411 - val_acc: 0.7524
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 22s - loss: 0.3619 - acc: 0.9221 - val_loss: 1.0132 - val_acc: 0.7274
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 22s - loss: 0.3595 - acc: 0.9230 - val_loss: 1.0939 - val_acc: 0.7180
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 22s - loss: 0.3593 - acc: 0.9225 - val_loss: 1.2279 - val_acc: 0.6884
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 22s - loss: 0.3569 - acc: 0.9233 - val_loss: 0.9145 - val_acc: 0.7464
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 22s - loss: 0.3533 - acc: 0.9246 - val_loss: 1.0565 - val_acc: 0.7190
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 22s - loss: 0.3186 - acc: 0.9391 - val_loss: 0.8250 - val_acc: 0.7812
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc did not improve
 - 22s - loss: 0.3113 - acc: 0.9421 - val_loss: 0.9060 - val_acc: 0.7586
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 22s - loss: 0.3068 - acc: 0.9448 - val_loss: 0.9323 - val_acc: 0.7580
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 22s - loss: 0.3178 - acc: 0.9403 - val_loss: 0.9154 - val_acc: 0.7522
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 22s - loss: 0.3153 - acc: 0.9406 - val_loss: 0.9031 - val_acc: 0.7644
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 22s - loss: 0.3127 - acc: 0.9418 - val_loss: 0.8728 - val_acc: 0.7700
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 22s - loss: 0.3113 - acc: 0.9415 - val_loss: 0.8839 - val_acc: 0.7630
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 22s - loss: 0.3186 - acc: 0.9392 - val_loss: 0.9496 - val_acc: 0.7578
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 22s - loss: 0.3121 - acc: 0.9425 - val_loss: 0.9246 - val_acc: 0.7550
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 22s - loss: 0.3143 - acc: 0.9407 - val_loss: 0.9287 - val_acc: 0.7492
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 22s - loss: 0.3119 - acc: 0.9422 - val_loss: 0.8661 - val_acc: 0.7670
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 22s - loss: 0.3121 - acc: 0.9414 - val_loss: 1.0052 - val_acc: 0.7328
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 22s - loss: 0.3206 - acc: 0.9374 - val_loss: 0.8556 - val_acc: 0.7796
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 22s - loss: 0.3146 - acc: 0.9413 - val_loss: 1.0386 - val_acc: 0.7178
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 22s - loss: 0.3145 - acc: 0.9409 - val_loss: 0.9456 - val_acc: 0.7602
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 22s - loss: 0.3227 - acc: 0.9365 - val_loss: 1.0024 - val_acc: 0.7418
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 22s - loss: 0.3192 - acc: 0.9394 - val_loss: 0.8918 - val_acc: 0.7604
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 22s - loss: 0.3226 - acc: 0.9373 - val_loss: 0.9918 - val_acc: 0.7368
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 21s - loss: 0.3185 - acc: 0.9388 - val_loss: 0.9723 - val_acc: 0.7500
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 22s - loss: 0.3221 - acc: 0.9368 - val_loss: 0.9083 - val_acc: 0.7512
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 22s - loss: 0.3116 - acc: 0.9425 - val_loss: 1.1227 - val_acc: 0.7052
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 22s - loss: 0.3101 - acc: 0.9418 - val_loss: 0.9203 - val_acc: 0.7640
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 22s - loss: 0.3136 - acc: 0.9403 - val_loss: 1.1533 - val_acc: 0.7076
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 22s - loss: 0.3136 - acc: 0.9405 - val_loss: 0.9090 - val_acc: 0.7534
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 22s - loss: 0.3168 - acc: 0.9396 - val_loss: 0.8918 - val_acc: 0.7568
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 22s - loss: 0.3165 - acc: 0.9403 - val_loss: 0.9457 - val_acc: 0.7412
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 22s - loss: 0.3134 - acc: 0.9414 - val_loss: 0.9422 - val_acc: 0.7584
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 22s - loss: 0.3217 - acc: 0.9376 - val_loss: 0.8724 - val_acc: 0.7724
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 22s - loss: 0.3128 - acc: 0.9408 - val_loss: 1.0383 - val_acc: 0.7288
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 22s - loss: 0.3219 - acc: 0.9367 - val_loss: 0.9092 - val_acc: 0.7586
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 22s - loss: 0.3178 - acc: 0.9389 - val_loss: 0.9837 - val_acc: 0.7426
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 22s - loss: 0.3199 - acc: 0.9390 - val_loss: 0.9220 - val_acc: 0.7524
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 22s - loss: 0.3176 - acc: 0.9391 - val_loss: 0.9794 - val_acc: 0.7452
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 22s - loss: 0.3210 - acc: 0.9365 - val_loss: 0.8655 - val_acc: 0.7606
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 22s - loss: 0.3202 - acc: 0.9376 - val_loss: 1.1428 - val_acc: 0.6920
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 22s - loss: 0.3138 - acc: 0.9414 - val_loss: 1.0240 - val_acc: 0.7268
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 22s - loss: 0.3202 - acc: 0.9380 - val_loss: 0.8695 - val_acc: 0.7614
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 22s - loss: 0.3282 - acc: 0.9347 - val_loss: 0.9897 - val_acc: 0.7338
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 22s - loss: 0.3203 - acc: 0.9386 - val_loss: 0.8999 - val_acc: 0.7626
Done

