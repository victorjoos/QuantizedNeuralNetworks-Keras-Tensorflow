Construct the Network

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
binary_conv2d_1 (BinaryConv2D)  (None, 32, 32, 16)   448         input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_1[0][0]            
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
binary_conv2d_2 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_2[0][0]            
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
binary_conv2d_3 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_3[0][0]            
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_4 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_4[0][0]            
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
binary_conv2d_5 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_5[0][0]            
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_6 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_6[0][0]            
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
binary_conv2d_7 (BinaryConv2D)  (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          binary_conv2d_7[0][0]            
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_8 (BinaryConv2D)  (None, 16, 16, 32)   4640        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         binary_conv2d_8[0][0]            
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
binary_conv2d_9 (BinaryConv2D)  (None, 16, 16, 32)   9248        activation_8[0][0]               
__________________________________________________________________________________________________
binary_conv2d_10 (BinaryConv2D) (None, 16, 16, 32)   544         activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         binary_conv2d_9[0][0]            
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           binary_conv2d_10[0][0]           
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_11 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_11[0][0]           
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
binary_conv2d_12 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_12[0][0]           
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_13 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_13[0][0]           
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
binary_conv2d_14 (BinaryConv2D) (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         binary_conv2d_14[0][0]           
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_15 (BinaryConv2D) (None, 8, 8, 64)     18496       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_15[0][0]           
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
binary_conv2d_16 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_14[0][0]              
__________________________________________________________________________________________________
binary_conv2d_17 (BinaryConv2D) (None, 8, 8, 64)     2112        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_16[0][0]           
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           binary_conv2d_17[0][0]           
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_18 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_18[0][0]           
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
binary_conv2d_19 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_19[0][0]           
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      
__________________________________________________________________________________________________
binary_conv2d_20 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_20[0][0]           
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
binary_conv2d_21 (BinaryConv2D) (None, 8, 8, 64)     36928       activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         binary_conv2d_21[0][0]           
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
binary_dense_2 (BinaryDense)    (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 274,442
Trainable params: 273,066
Non-trainable params: 1,376
__________________________________________________________________________________________________
loading data

Loading CIFAR-10 dataset...
(45000, 32, 32, 3)
setting up the network and creating callbacks

Learning rate:  0.001
compiling the network

No weights preloaded, training from scratch

(re)training the network

Train on 45000 samples, validate on 5000 samples
Learning rate:  0.001
Epoch 1/200

Epoch 00001: val_acc improved from -inf to 0.11560, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 30s - loss: 12.0772 - acc: 0.1228 - val_loss: 11.3448 - val_acc: 0.1156
Learning rate:  0.001
Epoch 2/200

Epoch 00002: val_acc improved from 0.11560 to 0.13580, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 11.1432 - acc: 0.1623 - val_loss: 11.2654 - val_acc: 0.1358
Learning rate:  0.001
Epoch 3/200

Epoch 00003: val_acc improved from 0.13580 to 0.22180, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 10.9149 - acc: 0.2107 - val_loss: 10.8537 - val_acc: 0.2218
Learning rate:  0.001
Epoch 4/200

Epoch 00004: val_acc improved from 0.22180 to 0.24000, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 10.7560 - acc: 0.2341 - val_loss: 10.6785 - val_acc: 0.2400
Learning rate:  0.001
Epoch 5/200

Epoch 00005: val_acc did not improve
 - 24s - loss: 10.6344 - acc: 0.2429 - val_loss: 10.7077 - val_acc: 0.2060
Learning rate:  0.001
Epoch 6/200

Epoch 00006: val_acc did not improve
 - 24s - loss: 10.4993 - acc: 0.2607 - val_loss: 10.6380 - val_acc: 0.2162
Learning rate:  0.001
Epoch 7/200

Epoch 00007: val_acc improved from 0.24000 to 0.24240, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 10.3393 - acc: 0.2829 - val_loss: 10.3721 - val_acc: 0.2424
Learning rate:  0.001
Epoch 8/200

Epoch 00008: val_acc improved from 0.24240 to 0.25760, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 10.2145 - acc: 0.2947 - val_loss: 10.2930 - val_acc: 0.2576
Learning rate:  0.001
Epoch 9/200

Epoch 00009: val_acc improved from 0.25760 to 0.29300, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 10.0818 - acc: 0.3112 - val_loss: 10.1250 - val_acc: 0.2930
Learning rate:  0.001
Epoch 10/200

Epoch 00010: val_acc did not improve
 - 24s - loss: 9.9581 - acc: 0.3188 - val_loss: 10.1892 - val_acc: 0.2628
Learning rate:  0.001
Epoch 11/200

Epoch 00011: val_acc did not improve
 - 24s - loss: 9.8220 - acc: 0.3334 - val_loss: 9.9390 - val_acc: 0.2738
Learning rate:  0.001
Epoch 12/200

Epoch 00012: val_acc did not improve
 - 24s - loss: 9.7089 - acc: 0.3352 - val_loss: 9.9424 - val_acc: 0.2504
Learning rate:  0.001
Epoch 13/200

Epoch 00013: val_acc improved from 0.29300 to 0.31480, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 9.5917 - acc: 0.3426 - val_loss: 9.6071 - val_acc: 0.3148
Learning rate:  0.001
Epoch 14/200

Epoch 00014: val_acc did not improve
 - 24s - loss: 9.4685 - acc: 0.3474 - val_loss: 9.8034 - val_acc: 0.2542
Learning rate:  0.001
Epoch 15/200

Epoch 00015: val_acc improved from 0.31480 to 0.35020, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 9.3170 - acc: 0.3659 - val_loss: 9.3434 - val_acc: 0.3502
Learning rate:  0.001
Epoch 16/200

Epoch 00016: val_acc improved from 0.35020 to 0.35760, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 9.2192 - acc: 0.3619 - val_loss: 9.1851 - val_acc: 0.3576
Learning rate:  0.001
Epoch 17/200

Epoch 00017: val_acc did not improve
 - 24s - loss: 9.0802 - acc: 0.3774 - val_loss: 9.1107 - val_acc: 0.3498
Learning rate:  0.001
Epoch 18/200

Epoch 00018: val_acc did not improve
 - 24s - loss: 8.9656 - acc: 0.3811 - val_loss: 8.9670 - val_acc: 0.3462
Learning rate:  0.001
Epoch 19/200

Epoch 00019: val_acc improved from 0.35760 to 0.36740, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 8.8339 - acc: 0.3926 - val_loss: 8.8296 - val_acc: 0.3674
Learning rate:  0.001
Epoch 20/200

Epoch 00020: val_acc improved from 0.36740 to 0.40380, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 8.7046 - acc: 0.4022 - val_loss: 8.6291 - val_acc: 0.4038
Learning rate:  0.001
Epoch 21/200

Epoch 00021: val_acc did not improve
 - 24s - loss: 8.5698 - acc: 0.4100 - val_loss: 8.6382 - val_acc: 0.3712
Learning rate:  0.001
Epoch 22/200

Epoch 00022: val_acc did not improve
 - 24s - loss: 8.4483 - acc: 0.4149 - val_loss: 8.6751 - val_acc: 0.3364
Learning rate:  0.001
Epoch 23/200

Epoch 00023: val_acc did not improve
 - 24s - loss: 8.3336 - acc: 0.4200 - val_loss: 8.3789 - val_acc: 0.3874
Learning rate:  0.001
Epoch 24/200

Epoch 00024: val_acc improved from 0.40380 to 0.40840, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 8.2104 - acc: 0.4301 - val_loss: 8.2038 - val_acc: 0.4084
Learning rate:  0.001
Epoch 25/200

Epoch 00025: val_acc improved from 0.40840 to 0.42320, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 8.0844 - acc: 0.4428 - val_loss: 8.0784 - val_acc: 0.4232
Learning rate:  0.001
Epoch 26/200

Epoch 00026: val_acc did not improve
 - 24s - loss: 7.9818 - acc: 0.4437 - val_loss: 8.3985 - val_acc: 0.3054
Learning rate:  0.001
Epoch 27/200

Epoch 00027: val_acc improved from 0.42320 to 0.43120, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 7.8739 - acc: 0.4497 - val_loss: 7.8785 - val_acc: 0.4312
Learning rate:  0.001
Epoch 28/200

Epoch 00028: val_acc did not improve
 - 24s - loss: 7.7703 - acc: 0.4512 - val_loss: 7.8080 - val_acc: 0.4222
Learning rate:  0.001
Epoch 29/200

Epoch 00029: val_acc improved from 0.43120 to 0.44680, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 7.6724 - acc: 0.4528 - val_loss: 7.6238 - val_acc: 0.4468
Learning rate:  0.001
Epoch 30/200

Epoch 00030: val_acc did not improve
 - 24s - loss: 7.5697 - acc: 0.4612 - val_loss: 7.6886 - val_acc: 0.3930
Learning rate:  0.001
Epoch 31/200

Epoch 00031: val_acc did not improve
 - 24s - loss: 7.5148 - acc: 0.4508 - val_loss: 7.7969 - val_acc: 0.3584
Learning rate:  0.001
Epoch 32/200

Epoch 00032: val_acc did not improve
 - 24s - loss: 7.4070 - acc: 0.4561 - val_loss: 7.4243 - val_acc: 0.4328
Learning rate:  0.001
Epoch 33/200

Epoch 00033: val_acc improved from 0.44680 to 0.45180, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 7.3039 - acc: 0.4685 - val_loss: 7.3057 - val_acc: 0.4518
Learning rate:  0.001
Epoch 34/200

Epoch 00034: val_acc did not improve
 - 24s - loss: 7.2090 - acc: 0.4731 - val_loss: 7.2470 - val_acc: 0.4424
Learning rate:  0.001
Epoch 35/200

Epoch 00035: val_acc did not improve
 - 24s - loss: 7.1234 - acc: 0.4770 - val_loss: 7.2052 - val_acc: 0.4364
Learning rate:  0.001
Epoch 36/200

Epoch 00036: val_acc did not improve
 - 24s - loss: 7.0197 - acc: 0.4861 - val_loss: 7.1180 - val_acc: 0.4494
Learning rate:  0.001
Epoch 37/200

Epoch 00037: val_acc did not improve
 - 24s - loss: 6.9427 - acc: 0.4892 - val_loss: 7.1947 - val_acc: 0.4026
Learning rate:  0.001
Epoch 38/200

Epoch 00038: val_acc did not improve
 - 24s - loss: 6.8533 - acc: 0.4965 - val_loss: 7.0398 - val_acc: 0.4232
Learning rate:  0.001
Epoch 39/200

Epoch 00039: val_acc improved from 0.45180 to 0.46620, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 6.7811 - acc: 0.4951 - val_loss: 6.8163 - val_acc: 0.4662
Learning rate:  0.001
Epoch 40/200

Epoch 00040: val_acc did not improve
 - 24s - loss: 6.7058 - acc: 0.4988 - val_loss: 6.9327 - val_acc: 0.4038
Learning rate:  0.001
Epoch 41/200

Epoch 00041: val_acc did not improve
 - 24s - loss: 6.6267 - acc: 0.5020 - val_loss: 7.0213 - val_acc: 0.4014
Learning rate:  0.001
Epoch 42/200

Epoch 00042: val_acc improved from 0.46620 to 0.47820, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 6.5547 - acc: 0.5064 - val_loss: 6.5857 - val_acc: 0.4782
Learning rate:  0.001
Epoch 43/200

Epoch 00043: val_acc did not improve
 - 24s - loss: 6.4779 - acc: 0.5092 - val_loss: 7.0103 - val_acc: 0.3486
Learning rate:  0.001
Epoch 44/200

Epoch 00044: val_acc did not improve
 - 24s - loss: 6.4252 - acc: 0.5071 - val_loss: 6.6391 - val_acc: 0.4270
Learning rate:  0.001
Epoch 45/200

Epoch 00045: val_acc did not improve
 - 24s - loss: 6.3436 - acc: 0.5155 - val_loss: 6.5581 - val_acc: 0.4436
Learning rate:  0.001
Epoch 46/200

Epoch 00046: val_acc did not improve
 - 24s - loss: 6.2749 - acc: 0.5204 - val_loss: 6.5489 - val_acc: 0.4192
Learning rate:  0.001
Epoch 47/200

Epoch 00047: val_acc did not improve
 - 24s - loss: 6.2012 - acc: 0.5267 - val_loss: 6.3169 - val_acc: 0.4704
Learning rate:  0.001
Epoch 48/200

Epoch 00048: val_acc did not improve
 - 24s - loss: 6.1395 - acc: 0.5262 - val_loss: 6.3692 - val_acc: 0.4228
Learning rate:  0.001
Epoch 49/200

Epoch 00049: val_acc did not improve
 - 24s - loss: 6.0795 - acc: 0.5302 - val_loss: 6.2168 - val_acc: 0.4712
Learning rate:  0.001
Epoch 50/200

Epoch 00050: val_acc did not improve
 - 24s - loss: 6.0063 - acc: 0.5342 - val_loss: 6.8424 - val_acc: 0.3368
Learning rate:  0.001
Epoch 51/200

Epoch 00051: val_acc improved from 0.47820 to 0.49400, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 5.9514 - acc: 0.5381 - val_loss: 6.0264 - val_acc: 0.4940
Learning rate:  0.001
Epoch 52/200

Epoch 00052: val_acc improved from 0.49400 to 0.49460, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 5.9042 - acc: 0.5370 - val_loss: 5.9853 - val_acc: 0.4946
Learning rate:  0.001
Epoch 53/200

Epoch 00053: val_acc did not improve
 - 24s - loss: 5.8418 - acc: 0.5395 - val_loss: 6.1286 - val_acc: 0.4236
Learning rate:  0.001
Epoch 54/200

Epoch 00054: val_acc did not improve
 - 24s - loss: 5.7951 - acc: 0.5419 - val_loss: 6.1645 - val_acc: 0.4184
Learning rate:  0.001
Epoch 55/200

Epoch 00055: val_acc improved from 0.49460 to 0.50740, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 5.7232 - acc: 0.5486 - val_loss: 5.8147 - val_acc: 0.5074
Learning rate:  0.001
Epoch 56/200

Epoch 00056: val_acc did not improve
 - 24s - loss: 5.6663 - acc: 0.5548 - val_loss: 6.2779 - val_acc: 0.3684
Learning rate:  0.001
Epoch 57/200

Epoch 00057: val_acc did not improve
 - 24s - loss: 5.6228 - acc: 0.5544 - val_loss: 5.8120 - val_acc: 0.4842
Learning rate:  0.001
Epoch 58/200

Epoch 00058: val_acc did not improve
 - 24s - loss: 5.5650 - acc: 0.5572 - val_loss: 6.2845 - val_acc: 0.3764
Learning rate:  0.001
Epoch 59/200

Epoch 00059: val_acc did not improve
 - 24s - loss: 5.5129 - acc: 0.5605 - val_loss: 5.7092 - val_acc: 0.4822
Learning rate:  0.001
Epoch 60/200

Epoch 00060: val_acc did not improve
 - 24s - loss: 5.4622 - acc: 0.5640 - val_loss: 6.6071 - val_acc: 0.2816
Learning rate:  0.001
Epoch 61/200

Epoch 00061: val_acc did not improve
 - 24s - loss: 5.4167 - acc: 0.5669 - val_loss: 5.6235 - val_acc: 0.4822
Learning rate:  0.001
Epoch 62/200

Epoch 00062: val_acc did not improve
 - 24s - loss: 5.3756 - acc: 0.5694 - val_loss: 5.9617 - val_acc: 0.3946
Learning rate:  0.001
Epoch 63/200

Epoch 00063: val_acc did not improve
 - 24s - loss: 5.3257 - acc: 0.5693 - val_loss: 5.5616 - val_acc: 0.4864
Learning rate:  0.001
Epoch 64/200

Epoch 00064: val_acc did not improve
 - 24s - loss: 5.2729 - acc: 0.5755 - val_loss: 5.6098 - val_acc: 0.4634
Learning rate:  0.001
Epoch 65/200

Epoch 00065: val_acc did not improve
 - 24s - loss: 5.2272 - acc: 0.5792 - val_loss: 5.3895 - val_acc: 0.5010
Learning rate:  0.001
Epoch 66/200

Epoch 00066: val_acc did not improve
 - 24s - loss: 5.1897 - acc: 0.5807 - val_loss: 5.4702 - val_acc: 0.4788
Learning rate:  0.001
Epoch 67/200

Epoch 00067: val_acc did not improve
 - 24s - loss: 5.1510 - acc: 0.5826 - val_loss: 5.5663 - val_acc: 0.4450
Learning rate:  0.001
Epoch 68/200

Epoch 00068: val_acc did not improve
 - 24s - loss: 5.1130 - acc: 0.5836 - val_loss: 6.1583 - val_acc: 0.3212
Learning rate:  0.001
Epoch 69/200

Epoch 00069: val_acc did not improve
 - 24s - loss: 5.0629 - acc: 0.5900 - val_loss: 6.1380 - val_acc: 0.3534
Learning rate:  0.001
Epoch 70/200

Epoch 00070: val_acc improved from 0.50740 to 0.53480, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 5.0136 - acc: 0.5960 - val_loss: 5.1541 - val_acc: 0.5348
Learning rate:  0.001
Epoch 71/200

Epoch 00071: val_acc did not improve
 - 24s - loss: 4.9780 - acc: 0.5976 - val_loss: 5.3634 - val_acc: 0.4594
Learning rate:  0.001
Epoch 72/200

Epoch 00072: val_acc did not improve
 - 24s - loss: 4.9463 - acc: 0.5958 - val_loss: 5.3516 - val_acc: 0.4546
Learning rate:  0.001
Epoch 73/200

Epoch 00073: val_acc did not improve
 - 24s - loss: 4.9045 - acc: 0.6003 - val_loss: 5.8139 - val_acc: 0.3160
Learning rate:  0.001
Epoch 74/200

Epoch 00074: val_acc did not improve
 - 24s - loss: 4.8645 - acc: 0.6030 - val_loss: 5.4462 - val_acc: 0.4248
Learning rate:  0.001
Epoch 75/200

Epoch 00075: val_acc improved from 0.53480 to 0.53720, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 4.8350 - acc: 0.6050 - val_loss: 5.0336 - val_acc: 0.5372
Learning rate:  0.001
Epoch 76/200

Epoch 00076: val_acc did not improve
 - 24s - loss: 4.7861 - acc: 0.6118 - val_loss: 5.1916 - val_acc: 0.4774
Learning rate:  0.001
Epoch 77/200

Epoch 00077: val_acc did not improve
 - 24s - loss: 4.7533 - acc: 0.6136 - val_loss: 5.2675 - val_acc: 0.4242
Learning rate:  0.001
Epoch 78/200

Epoch 00078: val_acc did not improve
 - 24s - loss: 4.7362 - acc: 0.6079 - val_loss: 5.1108 - val_acc: 0.4890
Learning rate:  0.001
Epoch 79/200

Epoch 00079: val_acc did not improve
 - 24s - loss: 4.6959 - acc: 0.6116 - val_loss: 5.6067 - val_acc: 0.3648
Learning rate:  0.001
Epoch 80/200

Epoch 00080: val_acc did not improve
 - 24s - loss: 4.6606 - acc: 0.6171 - val_loss: 5.0623 - val_acc: 0.4800
Learning rate:  0.001
Epoch 81/200

Epoch 00081: val_acc did not improve
 - 24s - loss: 4.6191 - acc: 0.6197 - val_loss: 4.9520 - val_acc: 0.4972
Learning rate:  0.0001
Epoch 82/200

Epoch 00082: val_acc improved from 0.53720 to 0.58840, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 4.5505 - acc: 0.6413 - val_loss: 4.7120 - val_acc: 0.5884
Learning rate:  0.0001
Epoch 83/200

Epoch 00083: val_acc did not improve
 - 24s - loss: 4.5300 - acc: 0.6481 - val_loss: 4.8355 - val_acc: 0.5410
Learning rate:  0.0001
Epoch 84/200

Epoch 00084: val_acc did not improve
 - 24s - loss: 4.5252 - acc: 0.6486 - val_loss: 4.7138 - val_acc: 0.5752
Learning rate:  0.0001
Epoch 85/200

Epoch 00085: val_acc did not improve
 - 24s - loss: 4.5081 - acc: 0.6550 - val_loss: 4.8069 - val_acc: 0.5528
Learning rate:  0.0001
Epoch 86/200

Epoch 00086: val_acc did not improve
 - 24s - loss: 4.5077 - acc: 0.6513 - val_loss: 4.7347 - val_acc: 0.5626
Learning rate:  0.0001
Epoch 87/200

Epoch 00087: val_acc did not improve
 - 24s - loss: 4.5129 - acc: 0.6497 - val_loss: 4.6592 - val_acc: 0.5814
Learning rate:  0.0001
Epoch 88/200

Epoch 00088: val_acc improved from 0.58840 to 0.59340, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 4.4974 - acc: 0.6534 - val_loss: 4.6458 - val_acc: 0.5934
Learning rate:  0.0001
Epoch 89/200

Epoch 00089: val_acc improved from 0.59340 to 0.60200, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 4.4925 - acc: 0.6534 - val_loss: 4.6144 - val_acc: 0.6020
Learning rate:  0.0001
Epoch 90/200

Epoch 00090: val_acc did not improve
 - 24s - loss: 4.4841 - acc: 0.6553 - val_loss: 4.6709 - val_acc: 0.5834
Learning rate:  0.0001
Epoch 91/200

Epoch 00091: val_acc did not improve
 - 24s - loss: 4.4838 - acc: 0.6543 - val_loss: 4.6343 - val_acc: 0.5976
Learning rate:  0.0001
Epoch 92/200

Epoch 00092: val_acc did not improve
 - 24s - loss: 4.4821 - acc: 0.6541 - val_loss: 4.7452 - val_acc: 0.5556
Learning rate:  0.0001
Epoch 93/200

Epoch 00093: val_acc did not improve
 - 24s - loss: 4.4803 - acc: 0.6520 - val_loss: 4.8055 - val_acc: 0.5408
Learning rate:  0.0001
Epoch 94/200

Epoch 00094: val_acc did not improve
 - 24s - loss: 4.4881 - acc: 0.6477 - val_loss: 5.0582 - val_acc: 0.4880
Learning rate:  0.0001
Epoch 95/200

Epoch 00095: val_acc did not improve
 - 24s - loss: 4.4758 - acc: 0.6502 - val_loss: 4.6795 - val_acc: 0.5720
Learning rate:  0.0001
Epoch 96/200

Epoch 00096: val_acc did not improve
 - 24s - loss: 4.4746 - acc: 0.6512 - val_loss: 4.6236 - val_acc: 0.5860
Learning rate:  0.0001
Epoch 97/200

Epoch 00097: val_acc did not improve
 - 24s - loss: 4.4720 - acc: 0.6499 - val_loss: 4.6491 - val_acc: 0.5808
Learning rate:  0.0001
Epoch 98/200

Epoch 00098: val_acc did not improve
 - 24s - loss: 4.4597 - acc: 0.6529 - val_loss: 4.6858 - val_acc: 0.5712
Learning rate:  0.0001
Epoch 99/200

Epoch 00099: val_acc did not improve
 - 24s - loss: 4.4584 - acc: 0.6531 - val_loss: 4.7759 - val_acc: 0.5432
Learning rate:  0.0001
Epoch 100/200

Epoch 00100: val_acc did not improve
 - 24s - loss: 4.4500 - acc: 0.6550 - val_loss: 4.6220 - val_acc: 0.5860
Learning rate:  0.0001
Epoch 101/200

Epoch 00101: val_acc did not improve
 - 24s - loss: 4.4428 - acc: 0.6554 - val_loss: 4.6090 - val_acc: 0.5856
Learning rate:  0.0001
Epoch 102/200

Epoch 00102: val_acc did not improve
 - 24s - loss: 4.4404 - acc: 0.6564 - val_loss: 4.6714 - val_acc: 0.5648
Learning rate:  0.0001
Epoch 103/200

Epoch 00103: val_acc did not improve
 - 24s - loss: 4.4329 - acc: 0.6557 - val_loss: 4.6526 - val_acc: 0.5784
Learning rate:  0.0001
Epoch 104/200

Epoch 00104: val_acc did not improve
 - 24s - loss: 4.4278 - acc: 0.6583 - val_loss: 4.7455 - val_acc: 0.5546
Learning rate:  0.0001
Epoch 105/200

Epoch 00105: val_acc did not improve
 - 24s - loss: 4.4311 - acc: 0.6539 - val_loss: 4.5890 - val_acc: 0.5932
Learning rate:  0.0001
Epoch 106/200

Epoch 00106: val_acc did not improve
 - 24s - loss: 4.4211 - acc: 0.6577 - val_loss: 4.6884 - val_acc: 0.5648
Learning rate:  0.0001
Epoch 107/200

Epoch 00107: val_acc did not improve
 - 24s - loss: 4.4221 - acc: 0.6568 - val_loss: 4.6577 - val_acc: 0.5672
Learning rate:  0.0001
Epoch 108/200

Epoch 00108: val_acc did not improve
 - 24s - loss: 4.4106 - acc: 0.6594 - val_loss: 4.6487 - val_acc: 0.5734
Learning rate:  0.0001
Epoch 109/200

Epoch 00109: val_acc did not improve
 - 24s - loss: 4.4017 - acc: 0.6620 - val_loss: 4.6786 - val_acc: 0.5692
Learning rate:  0.0001
Epoch 110/200

Epoch 00110: val_acc did not improve
 - 24s - loss: 4.3939 - acc: 0.6625 - val_loss: 4.6550 - val_acc: 0.5714
Learning rate:  0.0001
Epoch 111/200

Epoch 00111: val_acc did not improve
 - 24s - loss: 4.3932 - acc: 0.6644 - val_loss: 4.6018 - val_acc: 0.5836
Learning rate:  0.0001
Epoch 112/200

Epoch 00112: val_acc did not improve
 - 24s - loss: 4.3972 - acc: 0.6572 - val_loss: 4.5336 - val_acc: 0.6014
Learning rate:  0.0001
Epoch 113/200

Epoch 00113: val_acc did not improve
 - 24s - loss: 4.3943 - acc: 0.6576 - val_loss: 4.8011 - val_acc: 0.5272
Learning rate:  0.0001
Epoch 114/200

Epoch 00114: val_acc did not improve
 - 24s - loss: 4.3829 - acc: 0.6634 - val_loss: 4.6043 - val_acc: 0.5884
Learning rate:  0.0001
Epoch 115/200

Epoch 00115: val_acc did not improve
 - 24s - loss: 4.3812 - acc: 0.6623 - val_loss: 4.6504 - val_acc: 0.5696
Learning rate:  0.0001
Epoch 116/200

Epoch 00116: val_acc did not improve
 - 24s - loss: 4.3877 - acc: 0.6591 - val_loss: 4.6861 - val_acc: 0.5620
Learning rate:  0.0001
Epoch 117/200

Epoch 00117: val_acc did not improve
 - 24s - loss: 4.3782 - acc: 0.6601 - val_loss: 4.5757 - val_acc: 0.5800
Learning rate:  0.0001
Epoch 118/200

Epoch 00118: val_acc did not improve
 - 24s - loss: 4.3733 - acc: 0.6616 - val_loss: 4.6270 - val_acc: 0.5720
Learning rate:  0.0001
Epoch 119/200

Epoch 00119: val_acc did not improve
 - 24s - loss: 4.3694 - acc: 0.6617 - val_loss: 4.6534 - val_acc: 0.5542
Learning rate:  0.0001
Epoch 120/200

Epoch 00120: val_acc did not improve
 - 24s - loss: 4.3664 - acc: 0.6597 - val_loss: 4.6515 - val_acc: 0.5592
Learning rate:  0.0001
Epoch 121/200

Epoch 00121: val_acc did not improve
 - 24s - loss: 4.3588 - acc: 0.6627 - val_loss: 4.5533 - val_acc: 0.5926
Learning rate:  1e-05
Epoch 122/200

Epoch 00122: val_acc did not improve
 - 24s - loss: 4.3288 - acc: 0.6741 - val_loss: 4.5322 - val_acc: 0.5960
Learning rate:  1e-05
Epoch 123/200

Epoch 00123: val_acc improved from 0.60200 to 0.62040, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 4.3234 - acc: 0.6781 - val_loss: 4.4538 - val_acc: 0.6204
Learning rate:  1e-05
Epoch 124/200

Epoch 00124: val_acc did not improve
 - 24s - loss: 4.3222 - acc: 0.6782 - val_loss: 4.6647 - val_acc: 0.5512
Learning rate:  1e-05
Epoch 125/200

Epoch 00125: val_acc did not improve
 - 24s - loss: 4.3261 - acc: 0.6752 - val_loss: 4.5187 - val_acc: 0.5994
Learning rate:  1e-05
Epoch 126/200

Epoch 00126: val_acc did not improve
 - 24s - loss: 4.3241 - acc: 0.6735 - val_loss: 5.1872 - val_acc: 0.4482
Learning rate:  1e-05
Epoch 127/200

Epoch 00127: val_acc did not improve
 - 24s - loss: 4.3192 - acc: 0.6766 - val_loss: 4.5353 - val_acc: 0.5978
Learning rate:  1e-05
Epoch 128/200

Epoch 00128: val_acc did not improve
 - 24s - loss: 4.3202 - acc: 0.6760 - val_loss: 4.6148 - val_acc: 0.5678
Learning rate:  1e-05
Epoch 129/200

Epoch 00129: val_acc did not improve
 - 24s - loss: 4.3256 - acc: 0.6730 - val_loss: 4.5658 - val_acc: 0.5794
Learning rate:  1e-05
Epoch 130/200

Epoch 00130: val_acc did not improve
 - 24s - loss: 4.3245 - acc: 0.6743 - val_loss: 4.5648 - val_acc: 0.5872
Learning rate:  1e-05
Epoch 131/200

Epoch 00131: val_acc did not improve
 - 24s - loss: 4.3236 - acc: 0.6748 - val_loss: 4.9617 - val_acc: 0.4952
Learning rate:  1e-05
Epoch 132/200

Epoch 00132: val_acc did not improve
 - 24s - loss: 4.3242 - acc: 0.6744 - val_loss: 4.6129 - val_acc: 0.5700
Learning rate:  1e-05
Epoch 133/200

Epoch 00133: val_acc improved from 0.62040 to 0.62380, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 4.3204 - acc: 0.6774 - val_loss: 4.4607 - val_acc: 0.6238
Learning rate:  1e-05
Epoch 134/200

Epoch 00134: val_acc did not improve
 - 24s - loss: 4.3277 - acc: 0.6721 - val_loss: 4.5893 - val_acc: 0.5758
Learning rate:  1e-05
Epoch 135/200

Epoch 00135: val_acc did not improve
 - 24s - loss: 4.3225 - acc: 0.6736 - val_loss: 4.5760 - val_acc: 0.5730
Learning rate:  1e-05
Epoch 136/200

Epoch 00136: val_acc did not improve
 - 24s - loss: 4.3235 - acc: 0.6757 - val_loss: 4.7456 - val_acc: 0.5448
Learning rate:  1e-05
Epoch 137/200

Epoch 00137: val_acc did not improve
 - 24s - loss: 4.3228 - acc: 0.6735 - val_loss: 4.6012 - val_acc: 0.5806
Learning rate:  1e-05
Epoch 138/200

Epoch 00138: val_acc did not improve
 - 24s - loss: 4.3235 - acc: 0.6730 - val_loss: 4.9262 - val_acc: 0.4994
Learning rate:  1e-05
Epoch 139/200

Epoch 00139: val_acc did not improve
 - 24s - loss: 4.3258 - acc: 0.6745 - val_loss: 4.6093 - val_acc: 0.5686
Learning rate:  1e-05
Epoch 140/200

Epoch 00140: val_acc did not improve
 - 24s - loss: 4.3196 - acc: 0.6760 - val_loss: 4.5808 - val_acc: 0.5844
Learning rate:  1e-05
Epoch 141/200

Epoch 00141: val_acc did not improve
 - 24s - loss: 4.3194 - acc: 0.6751 - val_loss: 4.5987 - val_acc: 0.5802
Learning rate:  1e-05
Epoch 142/200

Epoch 00142: val_acc did not improve
 - 24s - loss: 4.3144 - acc: 0.6784 - val_loss: 4.6748 - val_acc: 0.5528
Learning rate:  1e-05
Epoch 143/200

Epoch 00143: val_acc did not improve
 - 24s - loss: 4.3199 - acc: 0.6734 - val_loss: 4.5132 - val_acc: 0.5990
Learning rate:  1e-05
Epoch 144/200

Epoch 00144: val_acc did not improve
 - 24s - loss: 4.3171 - acc: 0.6782 - val_loss: 4.5952 - val_acc: 0.5762
Learning rate:  1e-05
Epoch 145/200

Epoch 00145: val_acc did not improve
 - 24s - loss: 4.3186 - acc: 0.6718 - val_loss: 4.6267 - val_acc: 0.5662
Learning rate:  1e-05
Epoch 146/200

Epoch 00146: val_acc did not improve
 - 24s - loss: 4.3186 - acc: 0.6740 - val_loss: 4.5330 - val_acc: 0.5966
Learning rate:  1e-05
Epoch 147/200

Epoch 00147: val_acc did not improve
 - 24s - loss: 4.3219 - acc: 0.6732 - val_loss: 4.6956 - val_acc: 0.5408
Learning rate:  1e-05
Epoch 148/200

Epoch 00148: val_acc did not improve
 - 24s - loss: 4.3240 - acc: 0.6723 - val_loss: 4.6169 - val_acc: 0.5812
Learning rate:  1e-05
Epoch 149/200

Epoch 00149: val_acc did not improve
 - 24s - loss: 4.3129 - acc: 0.6767 - val_loss: 4.5603 - val_acc: 0.5940
Learning rate:  1e-05
Epoch 150/200

Epoch 00150: val_acc did not improve
 - 24s - loss: 4.3105 - acc: 0.6768 - val_loss: 4.5619 - val_acc: 0.5846
Learning rate:  1e-05
Epoch 151/200

Epoch 00151: val_acc did not improve
 - 24s - loss: 4.3209 - acc: 0.6744 - val_loss: 4.7247 - val_acc: 0.5498
Learning rate:  1e-05
Epoch 152/200

Epoch 00152: val_acc did not improve
 - 24s - loss: 4.3257 - acc: 0.6712 - val_loss: 4.5604 - val_acc: 0.5924
Learning rate:  1e-05
Epoch 153/200

Epoch 00153: val_acc did not improve
 - 24s - loss: 4.3187 - acc: 0.6716 - val_loss: 4.6620 - val_acc: 0.5570
Learning rate:  1e-05
Epoch 154/200

Epoch 00154: val_acc did not improve
 - 24s - loss: 4.3185 - acc: 0.6747 - val_loss: 4.5110 - val_acc: 0.6012
Learning rate:  1e-05
Epoch 155/200

Epoch 00155: val_acc did not improve
 - 24s - loss: 4.3143 - acc: 0.6752 - val_loss: 5.0677 - val_acc: 0.4660
Learning rate:  1e-05
Epoch 156/200

Epoch 00156: val_acc did not improve
 - 24s - loss: 4.3108 - acc: 0.6752 - val_loss: 4.8010 - val_acc: 0.5258
Learning rate:  1e-05
Epoch 157/200

Epoch 00157: val_acc did not improve
 - 24s - loss: 4.3140 - acc: 0.6750 - val_loss: 4.6160 - val_acc: 0.5700
Learning rate:  1e-05
Epoch 158/200

Epoch 00158: val_acc did not improve
 - 24s - loss: 4.3153 - acc: 0.6726 - val_loss: 4.5634 - val_acc: 0.5956
Learning rate:  1e-05
Epoch 159/200

Epoch 00159: val_acc did not improve
 - 24s - loss: 4.3160 - acc: 0.6738 - val_loss: 4.6548 - val_acc: 0.5574
Learning rate:  1e-05
Epoch 160/200

Epoch 00160: val_acc did not improve
 - 24s - loss: 4.3171 - acc: 0.6723 - val_loss: 4.9532 - val_acc: 0.4918
Learning rate:  1e-05
Epoch 161/200

Epoch 00161: val_acc did not improve
 - 24s - loss: 4.3183 - acc: 0.6742 - val_loss: 4.5713 - val_acc: 0.5886
Learning rate:  1e-06
Epoch 162/200

Epoch 00162: val_acc did not improve
 - 24s - loss: 4.2945 - acc: 0.6818 - val_loss: 4.4753 - val_acc: 0.6070
Learning rate:  1e-06
Epoch 163/200

Epoch 00163: val_acc improved from 0.62380 to 0.63620, saving model to ./weights/RESNET_CIFAR-10_qbnn_8b_4b_3.hdf5
 - 25s - loss: 4.2879 - acc: 0.6836 - val_loss: 4.4247 - val_acc: 0.6362
Learning rate:  1e-06
Epoch 164/200

Epoch 00164: val_acc did not improve
 - 24s - loss: 4.2891 - acc: 0.6840 - val_loss: 4.4972 - val_acc: 0.6032
Learning rate:  1e-06
Epoch 165/200

Epoch 00165: val_acc did not improve
 - 24s - loss: 4.2977 - acc: 0.6784 - val_loss: 4.7376 - val_acc: 0.5362
Learning rate:  1e-06
Epoch 166/200

Epoch 00166: val_acc did not improve
 - 24s - loss: 4.2979 - acc: 0.6799 - val_loss: 4.5033 - val_acc: 0.6020
Learning rate:  1e-06
Epoch 167/200

Epoch 00167: val_acc did not improve
 - 24s - loss: 4.3022 - acc: 0.6782 - val_loss: 4.4685 - val_acc: 0.6194
Learning rate:  1e-06
Epoch 168/200

Epoch 00168: val_acc did not improve
 - 24s - loss: 4.2969 - acc: 0.6795 - val_loss: 4.5740 - val_acc: 0.5878
Learning rate:  1e-06
Epoch 169/200

Epoch 00169: val_acc did not improve
 - 24s - loss: 4.2922 - acc: 0.6808 - val_loss: 4.6171 - val_acc: 0.5540
Learning rate:  1e-06
Epoch 170/200

Epoch 00170: val_acc did not improve
 - 24s - loss: 4.2974 - acc: 0.6815 - val_loss: 4.5138 - val_acc: 0.6024
Learning rate:  1e-06
Epoch 171/200

Epoch 00171: val_acc did not improve
 - 24s - loss: 4.2978 - acc: 0.6808 - val_loss: 4.4937 - val_acc: 0.6108
Learning rate:  1e-06
Epoch 172/200

Epoch 00172: val_acc did not improve
 - 24s - loss: 4.2991 - acc: 0.6808 - val_loss: 4.5301 - val_acc: 0.5952
Learning rate:  1e-06
Epoch 173/200

Epoch 00173: val_acc did not improve
 - 24s - loss: 4.3072 - acc: 0.6761 - val_loss: 4.6186 - val_acc: 0.5852
Learning rate:  1e-06
Epoch 174/200

Epoch 00174: val_acc did not improve
 - 24s - loss: 4.3032 - acc: 0.6782 - val_loss: 4.7545 - val_acc: 0.5304
Learning rate:  1e-06
Epoch 175/200

Epoch 00175: val_acc did not improve
 - 24s - loss: 4.3036 - acc: 0.6773 - val_loss: 4.8111 - val_acc: 0.5208
Learning rate:  1e-06
Epoch 176/200

Epoch 00176: val_acc did not improve
 - 24s - loss: 4.2973 - acc: 0.6789 - val_loss: 4.5853 - val_acc: 0.5726
Learning rate:  1e-06
Epoch 177/200

Epoch 00177: val_acc did not improve
 - 24s - loss: 4.3044 - acc: 0.6788 - val_loss: 4.5094 - val_acc: 0.6066
Learning rate:  1e-06
Epoch 178/200

Epoch 00178: val_acc did not improve
 - 24s - loss: 4.3015 - acc: 0.6795 - val_loss: 4.6054 - val_acc: 0.5840
Learning rate:  1e-06
Epoch 179/200

Epoch 00179: val_acc did not improve
 - 24s - loss: 4.3023 - acc: 0.6778 - val_loss: 4.8203 - val_acc: 0.5184
Learning rate:  1e-06
Epoch 180/200

Epoch 00180: val_acc did not improve
 - 24s - loss: 4.3063 - acc: 0.6782 - val_loss: 4.6027 - val_acc: 0.5836
Learning rate:  1e-06
Epoch 181/200

Epoch 00181: val_acc did not improve
 - 24s - loss: 4.3011 - acc: 0.6791 - val_loss: 4.5307 - val_acc: 0.5930
Learning rate:  5e-07
Epoch 182/200

Epoch 00182: val_acc did not improve
 - 24s - loss: 4.2936 - acc: 0.6797 - val_loss: 4.5971 - val_acc: 0.5756
Learning rate:  5e-07
Epoch 183/200

Epoch 00183: val_acc did not improve
 - 24s - loss: 4.2973 - acc: 0.6826 - val_loss: 4.5326 - val_acc: 0.5972
Learning rate:  5e-07
Epoch 184/200

Epoch 00184: val_acc did not improve
 - 24s - loss: 4.3011 - acc: 0.6790 - val_loss: 4.5777 - val_acc: 0.5940
Learning rate:  5e-07
Epoch 185/200

Epoch 00185: val_acc did not improve
 - 24s - loss: 4.3042 - acc: 0.6791 - val_loss: 4.5605 - val_acc: 0.5884
Learning rate:  5e-07
Epoch 186/200

Epoch 00186: val_acc did not improve
 - 24s - loss: 4.2999 - acc: 0.6790 - val_loss: 4.5766 - val_acc: 0.5886
Learning rate:  5e-07
Epoch 187/200

Epoch 00187: val_acc did not improve
 - 24s - loss: 4.3021 - acc: 0.6799 - val_loss: 4.4990 - val_acc: 0.6052
Learning rate:  5e-07
Epoch 188/200

Epoch 00188: val_acc did not improve
 - 24s - loss: 4.2980 - acc: 0.6791 - val_loss: 4.7132 - val_acc: 0.5284
Learning rate:  5e-07
Epoch 189/200

Epoch 00189: val_acc did not improve
 - 24s - loss: 4.2950 - acc: 0.6818 - val_loss: 4.4678 - val_acc: 0.6192
Learning rate:  5e-07
Epoch 190/200

Epoch 00190: val_acc did not improve
 - 24s - loss: 4.3004 - acc: 0.6784 - val_loss: 4.6634 - val_acc: 0.5578
Learning rate:  5e-07
Epoch 191/200

Epoch 00191: val_acc did not improve
 - 24s - loss: 4.2996 - acc: 0.6803 - val_loss: 4.5070 - val_acc: 0.6034
Learning rate:  5e-07
Epoch 192/200

Epoch 00192: val_acc did not improve
 - 24s - loss: 4.2948 - acc: 0.6833 - val_loss: 4.5317 - val_acc: 0.5996
Learning rate:  5e-07
Epoch 193/200

Epoch 00193: val_acc did not improve
 - 24s - loss: 4.3043 - acc: 0.6794 - val_loss: 4.4717 - val_acc: 0.6156
Learning rate:  5e-07
Epoch 194/200

Epoch 00194: val_acc did not improve
 - 24s - loss: 4.2987 - acc: 0.6808 - val_loss: 4.4800 - val_acc: 0.6144
Learning rate:  5e-07
Epoch 195/200

Epoch 00195: val_acc did not improve
 - 24s - loss: 4.2998 - acc: 0.6794 - val_loss: 4.4657 - val_acc: 0.6170
Learning rate:  5e-07
Epoch 196/200

Epoch 00196: val_acc did not improve
 - 24s - loss: 4.3050 - acc: 0.6775 - val_loss: 4.6582 - val_acc: 0.5678
Learning rate:  5e-07
Epoch 197/200

Epoch 00197: val_acc did not improve
 - 24s - loss: 4.3008 - acc: 0.6808 - val_loss: 4.6180 - val_acc: 0.5698
Learning rate:  5e-07
Epoch 198/200

Epoch 00198: val_acc did not improve
 - 24s - loss: 4.3018 - acc: 0.6782 - val_loss: 4.5820 - val_acc: 0.5836
Learning rate:  5e-07
Epoch 199/200

Epoch 00199: val_acc did not improve
 - 24s - loss: 4.3105 - acc: 0.6741 - val_loss: 4.5381 - val_acc: 0.5856
Learning rate:  5e-07
Epoch 200/200

Epoch 00200: val_acc did not improve
 - 24s - loss: 4.3089 - acc: 0.6759 - val_loss: 5.3250 - val_acc: 0.4100
Done

